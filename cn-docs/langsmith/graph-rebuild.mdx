---
title: 运行时重建图
sidebarTitle: Rebuild graph at runtime
---
您可能需要为新的运行使用不同的配置来重建图。例如，根据配置的不同，您可能需要使用不同的图状态或图结构。本指南将展示如何实现这一点。

<Note>
**注意**
在大多数情况下，基于配置自定义行为应由单个图处理，其中每个节点可以读取配置并据此改变其行为。
</Note>

## 前提条件

请确保首先查看[此操作指南](/langsmith/setup-app-requirements-txt)，了解如何为部署设置您的应用程序。

## 定义图

假设您有一个简单的应用程序，它调用一个 LLM 并将响应返回给用户。应用程序文件目录结构如下：

```
my-app/
|-- requirements.txt
|-- .env
|-- openai_agent.py     # 您的图代码
```

其中图定义在 `openai_agent.py` 文件中。

### 无需重建

在标准的 LangGraph API 配置中，服务器使用在 `openai_agent.py` 顶层定义的已编译图实例，其代码如下：

```python
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, MessageGraph

model = ChatOpenAI(temperature=0)

graph_workflow = MessageGraph()

graph_workflow.add_node("agent", model)
graph_workflow.add_edge("agent", END)
graph_workflow.add_edge(START, "agent")

agent = graph_workflow.compile()
```

为了让服务器识别您的图，您需要在 LangGraph API 配置文件 (`langgraph.json`) 中指定包含 @[`CompiledStateGraph`] 实例的变量路径，例如：

```
{
    "dependencies": ["."],
    "graphs": {
        "openai_agent": "./openai_agent.py:agent",
    },
    "env": "./.env"
}
```

### 重建

为了让您的图在每次新运行时根据自定义配置进行重建，您需要重写 `openai_agent.py`，改为提供一个接受配置并返回图（或已编译图）实例的*函数*。假设我们想为用户 ID '1' 返回现有的图，而为其他用户返回一个工具调用代理。我们可以按如下方式修改 `openai_agent.py`：

```python
from typing import Annotated
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, MessageGraph
from langgraph.graph.state import StateGraph
from langgraph.graph.message import add_messages
from langchain.tools import tool
from langgraph.prebuilt import ToolNode
from langchain_core.messages import BaseMessage
from langchain_core.runnables import RunnableConfig


class State(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]


model = ChatOpenAI(temperature=0)

def make_default_graph():
    """Make a simple LLM agent"""
    graph_workflow = StateGraph(State)
    def call_model(state):
        return {"messages": [model.invoke(state["messages"])]}

    graph_workflow.add_node("agent", call_model)
    graph_workflow.add_edge("agent", END)
    graph_workflow.add_edge(START, "agent")

    agent = graph_workflow.compile()
    return agent


def make_alternative_graph():
    """Make a tool-calling agent"""

    @tool
    def add(a: float, b: float):
        """Adds two numbers."""
        return a + b

    tool_node = ToolNode([add])
    model_with_tools = model.bind_tools([add])
    def call_model(state):
        return {"messages": [model_with_tools.invoke(state["messages"])]}

    def should_continue(state: State):
        if state["messages"][-1].tool_calls:
            return "tools"
        else:
            return END

    graph_workflow = StateGraph(State)

    graph_workflow.add_node("agent", call_model)
    graph_workflow.add_node("tools", tool_node)
    graph_workflow.add_edge("tools", "agent")
    graph_workflow.add_edge(START, "agent")
    graph_workflow.add_conditional_edges("agent", should_continue)

    agent = graph_workflow.compile()
    return agent


# this is the graph making function that will decide which graph to
# build based on the provided config
def make_graph(config: RunnableConfig):
    user_id = config.get("configurable", {}).get("user_id")
    # route to different graph state / structure based on the user ID
    if user_id == "1":
        return make_default_graph()
    else:
        return make_alternative_graph()
```

最后，您需要在 `langgraph.json` 中指定您的图构建函数 (`make_graph`) 的路径：

```
{
    "dependencies": ["."],
    "graphs": {
        "openai_agent": "./openai_agent.py:make_graph",
    },
    "env": "./.env"
}
```

有关 LangGraph API 配置文件的更多信息，请参见[此处](/langsmith/cli#configuration-file)。
