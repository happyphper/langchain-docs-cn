---
title: 使用 LangChain 进行追踪（Python 和 JS/TS）
sidebarTitle: LangChain
---
LangSmith 与流行的开源框架 LangChain（Python 和 JavaScript）无缝集成，用于构建 LLM 应用程序。

## 安装

为 Python 和 JS 安装核心库和 OpenAI 集成（下面的代码片段使用了 OpenAI 集成）。

有关可用包的完整列表，请参阅 [LangChain 文档](/oss/integrations/providers/overview)。

<CodeGroup>

```bash pip
pip install langchain_openai langchain_core
```

```bash yarn
yarn add @langchain/openai @langchain/core
```

```bash npm
npm install @langchain/openai @langchain/core
```

```bash pnpm
pnpm add @langchain/openai @langchain/core
```

</CodeGroup>

## 快速开始

### 1. 配置环境

```bash wrap
export LANGSMITH_TRACING=true
export LANGSMITH_API_KEY=<your-api-key>
# 此示例使用 OpenAI，但您可以选择任何 LLM 提供商
export OPENAI_API_KEY=<your-openai-api-key>
# 对于链接到多个工作区的 LangSmith API 密钥，设置 LANGSMITH_WORKSPACE_ID 环境变量以指定要使用的工作区。
export LANGSMITH_WORKSPACE_ID=<your-workspace-id>
```

<Info>
    如果您在非无服务器环境中使用 LangChain.js 和 LangSmith，我们还建议显式设置以下内容以减少延迟：

    `export LANGCHAIN_CALLBACKS_BACKGROUND=true`

    如果您处于无服务器环境中，我们建议设置相反的值，以允许跟踪在函数结束前完成：

    `export LANGCHAIN_CALLBACKS_BACKGROUND=false`
</Info>

### 2. 记录跟踪

无需额外代码即可将跟踪记录到 LangSmith。只需像往常一样运行您的 LangChain 代码。

<CodeGroup>

```python Python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Please respond to the user's request only based on the given context."),
    ("user", "Question: {question}\nContext: {context}")
])

model = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()
chain = prompt | model | output_parser

question = "Can you summarize this morning's meetings?"
context = "During this morning's meeting, we solved all world conflict."

chain.invoke({"question": question, "context": context})
```

```typescript TypeScript
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant. Please respond to the user's request only based on the given context."],
  ["user", "Question: {question}\nContext: {context}"],
]);

const model = new ChatOpenAI({ modelName: "gpt-4o-mini" });
const outputParser = new StringOutputParser();
const chain = prompt.pipe(model).pipe(outputParser);

const question = "Can you summarize this morning's meetings?"
const context = "During this morning's meeting, we solved all world conflict."

await chain.invoke({ question: question, context: context });
```

</CodeGroup>

### 3. 查看您的跟踪

默认情况下，跟踪将记录到名为 `default` 的项目中。使用上述代码记录的跟踪示例已公开，可以在此处查看。

![Langchain trace](/langsmith/images/langchain-trace.png)

## 选择性跟踪

[上一节](#quick-start)展示了如何通过设置单个环境变量来跟踪应用程序中所有 LangChain 可运行对象的调用。虽然这是一种方便的入门方式，但您可能只想跟踪特定的调用或应用程序的某些部分。

在 Python 中有两种方法可以实现：手动将 `LangChainTracer` 实例作为 [回调](https://reference.langchain.com/python/langchain_core/callbacks/) 传入，或者使用 [`tracing_context` 上下文管理器](https://reference.langchain.com/python/langsmith/observability/sdk/run_helpers/#langsmith.run_helpers.tracing_context)。

在 JS/TS 中，您可以将 [`LangChainTracer`](https://reference.langchain.com/javascript/classes/_langchain_core.tracers_tracer_langchain.LangChainTracer.html) 实例作为回调传入。

<CodeGroup>

```python Python
# 您可以选择性地启用特定调用..
import langsmith as ls

with ls.tracing_context(enabled=True):
    chain.invoke({"question": "Am I using a callback?", "context": "I'm using a callback"})

# 这不会被跟踪（假设 LANGSMITH_TRACING 未设置）
chain.invoke({"question": "Am I being traced?", "context": "I'm not being traced"})

# 即使 LANGSMITH_TRACING=true，这也不会被跟踪
with ls.tracing_context(enabled=False):
    chain.invoke({"question": "Am I being traced?", "context": "I'm not being traced"})
```

```typescript TypeScript
// 您可以配置一个 LangChainTracer 实例来跟踪特定的调用。
import { LangChainTracer } from "@langchain/core/tracers/tracer_langchain";

const tracer = new LangChainTracer();
await chain.invoke(
  {
    question: "Am I using a callback?",
    context: "I'm using a callback"
  },
  { callbacks: [tracer] }
);
```

</CodeGroup>

## 记录到特定项目

### 静态设置

如 [跟踪概念指南](/langsmith/observability-concepts) 中所述，LangSmith 使用项目（Project）的概念来对跟踪进行分组。如果未指定，跟踪器项目将设置为 default。您可以设置 `LANGSMITH_PROJECT` 环境变量来为整个应用程序运行配置自定义项目名称。这应在执行应用程序之前完成。

```bash
export LANGSMITH_PROJECT=my-project
```

<Warning>
`LANGSMITH_PROJECT` 标志仅在 JS SDK 版本 >= 0.2.16 中受支持，如果您使用的是旧版本，请改用 `LANGCHAIN_PROJECT`。
</Warning>

### 动态设置

这主要建立在 [上一节](#trace-selectively) 的基础上，允许您为特定的 `LangChainTracer` 实例设置项目名称，或者在 Python 中作为 `tracing_context` 上下文管理器的参数。

<CodeGroup>

```python Python
# 您可以使用 project_name 参数设置项目名称。
import langsmith as ls

with ls.tracing_context(project_name="My Project", enabled=True):
    chain.invoke({"question": "Am I using a context manager?", "context": "I'm using a context manager"})
```

```typescript TypeScript
// 您可以为特定的跟踪器实例设置项目名称：
import { LangChainTracer } from "@langchain/core/tracers/tracer_langchain";

const tracer = new LangChainTracer({ projectName: "My Project" });
await chain.invoke(
  {
    question: "Am I using a callback?",
    context: "I'm using a callback"
  },
  { callbacks: [tracer] }
);
```

</CodeGroup>

## 向跟踪添加元数据和标签

您可以通过在 [`RunnableConfig`](https://reference.langchain.com/python/langchain_core/runnables/?h=runnablecon#langchain_core.runnables.RunnableConfig) 中提供任意元数据和标签来注释您的跟踪。这对于将附加信息（例如执行环境或发起用户）与跟踪关联起来非常有用。有关如何按元数据和标签查询跟踪和运行的信息，请参阅 [本指南](/langsmith/export-traces)

<Note>
当您将元数据或标签附加到可运行对象时（无论是通过 @[`RunnableConfig`] 还是在运行时通过调用参数），它们都会被该可运行对象的所有子可运行对象继承。
</Note>

<CodeGroup>

```python Python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI."),
    ("user", "{input}")
])

# 标签 "model-tag" 和元数据 {"model-key": "model-value"} 将仅附加到 ChatOpenAI 运行
chat_model = ChatOpenAI().with_config({"tags": ["model-tag"], "metadata": {"model-key": "model-value"}})
output_parser = StrOutputParser()

# 可以使用 RunnableConfig 配置标签和元数据
chain = (prompt | chat_model | output_parser).with_config({"tags": ["config-tag"], "metadata": {"config-key": "config-value"}})

# 标签和元数据也可以在运行时传递
chain.invoke({"input": "What is the meaning of life?"}, {"tags": ["invoke-tag"], "metadata": {"invoke-key": "invoke-value"}})
```

```typescript TypeScript
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

const prompt = ChatPromptTemplate.fromMessages([
    ["system", "You are a helpful AI."],
    ["user", "{input}"]
])

// 标签 "model-tag" 和元数据 {"model-key": "model-value"} 将仅附加到 ChatOpenAI 运行
const model = new ChatOpenAI().withConfig({ tags: ["model-tag"], metadata: { "model-key": "model-value" } });
const outputParser = new StringOutputParser();

// 可以使用 RunnableConfig 配置标签和元数据
const chain = (prompt.pipe(model).pipe(outputParser)).withConfig({"tags": ["config-tag"], "metadata": {"config-key": "top-level-value"}});

// 标签和元数据也可以在运行时传递
await chain.invoke({input: "What is the meaning of life?"}, {tags: ["invoke-tag"], metadata: {"invoke-key": "invoke-value"}})
```

</CodeGroup>

## 自定义运行名称

您可以在调用或流式传输 LangChain 代码时，通过在 [Config](https://reference.langchain.com/python/langchain_core/runnables/?h=runnablecon#langchain_core.runnables.RunnableConfig) 中提供自定义名称来定制给定运行的名称。此名称用于在 LangSmith 中标识运行，并可用于过滤和分组运行。该名称也用作 LangSmith UI 中运行的标题。这可以通过在 JS/TS 中在构造时在 @[`RunnableConfig`] 对象中设置 `run_name` 或在调用参数中传递 `run_name` 来完成。

<CodeGroup>

```python Python
# 在 LangChain 中进行跟踪时，运行名称默认为被跟踪对象的类名（例如 'ChatOpenAI'）。
configured_chain = chain.with_config({"run_name": "MyCustomChain"})
configured_chain.invoke({"input": "What is the meaning of life?"})

# 您也可以在调用时配置运行名称，如下所示
chain.invoke({"input": "What is the meaning of life?"}, {"run_name": "MyCustomChain"})
```

```typescript TypeScript
// 在 LangChain 中进行跟踪时，运行名称默认为被跟踪对象的类名（例如 'ChatOpenAI'）。
const configuredChain = chain.withConfig({ runName: "MyCustomChain" });
await configuredChain.invoke({ input: "What is the meaning of life?" });

// 您也可以在调用时配置运行名称，如下所示
await chain.invoke({ input: "What is the meaning of life?" }, {runName: "MyCustomChain"})
```

</CodeGroup>

<Note>
`run_name` 参数仅更改您调用的可运行对象（例如，链、函数）的名称。它不会自动重命名调用 LLM 对象（如 @[`ChatOpenAI`] (`gpt-4o-mini`)）时自动创建的嵌套运行。在示例中，外层运行将在 LangSmith 中显示为 `MyCustomChain`，而嵌套的 LLM 运行仍显示模型的默认名称。

要为 LLM 运行指定更有意义的名称，您可以：

- 将模型包装在另一个可运行对象中，并为该步骤分配一个 `run_name`。
- 使用跟踪装饰器或辅助函数（例如 Python 中的 `@traceable`，或 JS/TS 中来自 `langsmith` 的 `traceable`）围绕模型调用创建自定义运行。
</Note>

## 自定义运行 ID

您可以在调用或流式传输 LangChain 代码时，通过在 [Config](https://reference.langchain.com/python/langchain_core/runnables/?h=runnablecon#langchain_core.runnables.RunnableConfig) 中提供自定义 ID 来定制给定运行的 ID。此 ID 用于在 LangSmith 中唯一标识运行，并可用于查询特定运行。该 ID 对于跨不同系统链接运行或实现自定义跟踪逻辑非常有用。这可以通过在构造时在 @[`RunnableConfig`] 对象中设置 `run_id` 或在调用参数中传递 `run_id` 来完成。

<Note>
此功能目前不直接支持 LLM 对象。
</Note>

<CodeGroup>

```python Python
import uuid

my_uuid = uuid.uuid4()

# 您可以在调用时配置运行 ID：
chain.invoke({"input": "What is the meaning of life?"}, {"run_id": my_uuid})
```

```typescript TypeScript
import { v4 as uuidv4 } from 'uuid';

const myUuid = uuidv4();

// 您可以在调用时配置运行 ID，如下所示
await chain.invoke({ input: "What is the meaning of life?" }, { runId: myUuid });
```

</CodeGroup>

请注意，如果您在跟踪的 **根** 级别（即顶级运行）执行此操作，则该运行 ID 将用作 `trace_id`。

## 访问 LangChain 调用的运行（跨度）ID

当您调用 LangChain 对象时，可以手动指定调用的运行 ID。此运行 ID 可用于在 LangSmith 中查询该运行。

在 JS/TS 中，您可以使用 `RunCollectorCallbackHandler` 实例来访问运行 ID。

<CodeGroup>

```python Python
import uuid

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Please respond to the user's request only based on the given context."),
    ("user", "Question: {question}\n\nContext: {context}")
])
model = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()

chain = prompt | model | output_parser

question = "Can you summarize this morning's meetings?"
context = "During this morning's meeting, we solved all world conflict."
my_uuid = uuid.uuid4()
result = chain.invoke({"question": question, "context": context}, {"run_id": my_uuid})
print(my_uuid)
```

```typescript TypeScript
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { RunCollectorCallbackHandler } from "@langchain/core/tracers/run_collector";

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant. Please respond to the user's request only based on the given context."],
  ["user", "Question: {question}\n\nContext: {context}"],
]);
const model = new ChatOpenAI({ modelName: "gpt-4o-mini" });
const outputParser = new StringOutputParser();

const chain = prompt.pipe(model).pipe(outputParser);
const runCollector = new RunCollectorCallbackHandler();

const question = "Can you summarize this morning's meetings?"
const context = "During this morning's meeting, we solved all world conflict."
await chain.invoke(
    { question: question, context: context },
    { callbacks: [runCollector] }
);
const runId = runCollector.tracedRuns[0].id;
console.log(runId);
```

</CodeGroup>

## 确保在退出前提交所有跟踪

在 LangChain Python 中，LangSmith 的跟踪是在后台线程中完成的，以避免阻塞您的生产应用程序。这意味着您的进程可能在所有跟踪成功发布到 LangSmith 之前就结束了。这在无服务器环境中尤其普遍，您的 VM 可能在您的链或代理完成后立即终止。

您可以通过将 `LANGCHAIN_CALLBACKS_BACKGROUND` 环境变量设置为 `"false"` 来使回调同步。

对于两种语言，LangChain 都提供了在退出应用程序前等待跟踪提交的方法。下面是一个示例：

<CodeGroup>

```python Python
from langchain_openai import ChatOpenAI
from langchain_core.tracers.langchain import wait_for_all_tracers

llm = ChatOpenAI()

try:
  llm.invoke("Hello, World!")
finally:
  wait_for_all_tracers()
```

```typescript TypeScript
import { awaitAllCallbacks } from "@langchain/core/callbacks/promises";

try {
    const llm = new ChatOpenAI();
    const response = await llm.invoke("Hello, World!");
} catch (e) {
    // handle error
} finally {
    await awaitAllCallbacks();
}
```

</CodeGroup>

## 无需设置环境变量进行跟踪

如其他指南所述，以下环境变量允许您配置跟踪启用、API 端点、API 密钥和跟踪项目：

* `LANGSMITH_TRACING`
* `LANGSMITH_API_KEY`
* `LANGSMITH_ENDPOINT`
* `LANGSMITH_PROJECT`

但是，在某些环境中，无法设置环境变量。在这些情况下，您可以通过编程方式设置跟踪配置。

这主要建立在 [上一节](#trace-selectively) 的基础上。

<CodeGroup>

```python Python
import langsmith as ls

# 您可以使用 api 密钥和 api url 创建客户端实例
client = ls.Client(
    api_key="YOUR_API_KEY",  # 可以从密钥管理器获取
    api_url="https://api.smith.langchain.com",  # 对于自托管安装或欧盟区域，请相应更新
)

# 您可以将 client 和 project_name 传递给 tracing_context
with ls.tracing
