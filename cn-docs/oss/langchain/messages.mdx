---
title: 消息
---
{/* TODO: 关于元数据类型（响应和使用）的章节 */}

消息是 LangChain 中模型上下文的基本单元。它们代表模型的输入和输出，承载着与 LLM 交互时表示对话状态所需的内容和元数据。

消息是包含以下内容的对象：

* <Icon icon="user" size={16} /> [**角色**](#message-types) - 标识消息类型（例如 `system`、`user`）
* <Icon icon="folder-closed" size={16} /> [**内容**](#message-content) - 表示消息的实际内容（如文本、图像、音频、文档等）
* <Icon icon="tag" size={16} /> [**元数据**](#message-metadata) - 可选字段，如响应信息、消息 ID 和令牌使用情况

LangChain 提供了一个适用于所有模型提供商的标准消息类型，确保无论调用哪个模型，行为都保持一致。

## 基本用法

使用消息最简单的方法是创建消息对象，并在[调用](/oss/langchain/models#invocation)模型时传递给模型。

:::python
```python
from langchain.chat_models import init_chat_model
from langchain.messages import HumanMessage, AIMessage, SystemMessage

model = init_chat_model("gpt-5-nano")

system_msg = SystemMessage("You are a helpful assistant.")
human_msg = HumanMessage("Hello, how are you?")

# 与聊天模型一起使用
messages = [system_msg, human_msg]
response = model.invoke(messages)  # 返回 AIMessage
```
:::

:::js
```typescript
import { initChatModel, HumanMessage, SystemMessage } from "langchain";

const model = await initChatModel("gpt-5-nano");

const systemMsg = new SystemMessage("You are a helpful assistant.");
const humanMsg = new HumanMessage("Hello, how are you?");

const messages = [systemMsg, humanMsg];
const response = await model.invoke(messages);  // 返回 AIMessage
```
:::

### 文本提示

文本提示是字符串 - 适用于不需要保留对话历史的简单生成任务。

:::python
```python
response = model.invoke("Write a haiku about spring")
```
:::

:::js
```typescript
const response = await model.invoke("Write a haiku about spring");
```
:::

**在以下情况下使用文本提示：**
* 你有一个独立的、单一的请求
* 不需要对话历史
* 希望代码复杂度最低

### 消息提示

或者，你可以通过提供消息对象列表，将消息列表传递给模型。

:::python
```python
from langchain.messages import SystemMessage, HumanMessage, AIMessage

messages = [
    SystemMessage("You are a poetry expert"),
    HumanMessage("Write a haiku about spring"),
    AIMessage("Cherry blossoms bloom...")
]
response = model.invoke(messages)
```
:::

:::js
```typescript
import { SystemMessage, HumanMessage, AIMessage } from "langchain";

const messages = [
  new SystemMessage("You are a poetry expert"),
  new HumanMessage("Write a haiku about spring"),
  new AIMessage("Cherry blossoms bloom..."),
];
const response = await model.invoke(messages);
```
:::

**在以下情况下使用消息提示：**
* 管理多轮对话
* 处理多模态内容（图像、音频、文件）
* 包含系统指令

### 字典格式

你也可以直接以 OpenAI 聊天补全格式指定消息。

:::python
```python
messages = [
    {"role": "system", "content": "You are a poetry expert"},
    {"role": "user", "content": "Write a haiku about spring"},
    {"role": "assistant", "content": "Cherry blossoms bloom..."}
]
response = model.invoke(messages)
```
:::

:::js
```typescript
const messages = [
  { role: "system", content: "You are a poetry expert" },
  { role: "user", content: "Write a haiku about spring" },
  { role: "assistant", content: "Cherry blossoms bloom..." },
];
const response = await model.invoke(messages);
```
:::

## 消息类型

- <Icon icon="gear" size={16} /> [系统消息](#system-message) - 告诉模型如何行为，并为交互提供上下文
- <Icon icon="user" size={16} /> [用户消息](#human-message) - 代表用户输入和与模型的交互
- <Icon icon="robot" size={16} /> [AI 消息](#ai-message) - 模型生成的响应，包括文本内容、工具调用和元数据
- <Icon icon="wrench" size={16} /> [工具消息](#tool-message) - 代表[工具调用](/oss/langchain/models#tool-calling)的输出

### 系统消息

@[`SystemMessage`] 代表一组初始指令，用于引导模型的行为。你可以使用系统消息来设定语气、定义模型的角色，并为响应建立指导原则。

:::python
```python Basic instructions
system_msg = SystemMessage("You are a helpful coding assistant.")

messages = [
    system_msg,
    HumanMessage("How do I create a REST API?")
]
response = model.invoke(messages)
```
:::

:::js
```typescript Basic instructions
import { SystemMessage, HumanMessage, AIMessage } from "langchain";

const systemMsg = new SystemMessage("You are a helpful coding assistant.");

const messages = [
  systemMsg,
  new HumanMessage("How do I create a REST API?"),
];
const response = await model.invoke(messages);
```
:::

:::python
```python Detailed persona
from langchain.messages import SystemMessage, HumanMessage

system_msg = SystemMessage("""
You are a senior Python developer with expertise in web frameworks.
Always provide code examples and explain your reasoning.
Be concise but thorough in your explanations.
""")

messages = [
    system_msg,
    HumanMessage("How do I create a REST API?")
]
response = model.invoke(messages)
```
:::

:::js
```typescript Detailed persona
import { SystemMessage, HumanMessage } from "langchain";

const systemMsg = new SystemMessage(`
You are a senior TypeScript developer with expertise in web frameworks.
Always provide code examples and explain your reasoning.
Be concise but thorough in your explanations.
`);

const messages = [
  systemMsg,
  new HumanMessage("How do I create a REST API?"),
];
const response = await model.invoke(messages);
```
:::

---

### 用户消息

@[`HumanMessage`] 代表用户输入和交互。它们可以包含文本、图像、音频、文件以及任何其他数量的多模态[内容](#message-content)。

#### 文本内容

:::python
<CodeGroup>
    ```python Message object
    response = model.invoke([
      HumanMessage("What is machine learning?")
    ])
    ```

    ```python String shortcut
    # 使用字符串是单个 HumanMessage 的快捷方式
    response = model.invoke("What is machine learning?")
    ```
</CodeGroup>
:::

:::js
```typescript Message object
const response = await model.invoke([
  new HumanMessage("What is machine learning?"),
]);
```

```typescript String shortcut
const response = await model.invoke("What is machine learning?");
```
:::

#### 消息元数据

:::python
```python Add metadata
human_msg = HumanMessage(
    content="Hello!",
    name="alice",  # 可选：标识不同用户
    id="msg_123",  # 可选：用于追踪的唯一标识符
)
```
:::

:::js
```typescript Add metadata
const humanMsg = new HumanMessage({
  content: "Hello!",
  name: "alice",
  id: "msg_123",
});
```
:::

<Note>
    `name` 字段的行为因提供商而异 - 有些将其用于用户识别，有些则忽略它。要确认，请参考模型提供商的[参考文档](https://reference.langchain.com/python/integrations/)。
</Note>

---

### AI 消息

@[`AIMessage`] 代表模型调用的输出。它们可以包含多模态数据、工具调用以及稍后可以访问的特定于提供商的元数据。

:::python
```python
response = model.invoke("Explain AI")
print(type(response))  # <class 'langchain.messages.AIMessage'>
```
:::

:::js
```typescript
const response = await model.invoke("Explain AI");
console.log(typeof response);  // AIMessage
```
:::

@[`AIMessage`] 对象是调用模型时返回的，其中包含响应中的所有关联元数据。

提供商对不同类型消息的权衡/上下文处理方式不同，这意味着有时手动创建一个新的 @[`AIMessage`] 对象并将其插入到消息历史中，就好像它来自模型一样，会很有帮助。

:::python
```python
from langchain.messages import AIMessage, SystemMessage, HumanMessage

# 手动创建 AI 消息（例如，用于对话历史）
ai_msg = AIMessage("I'd be happy to help you with that question!")

# 添加到对话历史
messages = [
    SystemMessage("You are a helpful assistant"),
    HumanMessage("Can you help me?"),
    ai_msg,  # 插入，就好像它来自模型一样
    HumanMessage("Great! What's 2+2?")
]

response = model.invoke(messages)
```
:::

:::js
```typescript
import { AIMessage, SystemMessage, HumanMessage } from "langchain";

const aiMsg = new AIMessage("I'd be happy to help you with that question!");

const messages = [
  new SystemMessage("You are a helpful assistant"),
  new HumanMessage("Can you help me?"),
  aiMsg,  // 插入，就好像它来自模型一样
  new HumanMessage("Great! What's 2+2?")
]

const response = await model.invoke(messages);
```
:::

<Accordion title="属性">
    :::python
    <ParamField path="text" type="string">
        消息的文本内容。
    </ParamField>
    <ParamField path="content" type="string | dict[]">
        消息的原始内容。
    </ParamField>
    <ParamField path="content_blocks" type="ContentBlock[]">
        消息的标准化[内容块](#message-content)。
    </ParamField>
    <ParamField path="tool_calls" type="dict[] | None">
        模型进行的工具调用。

        如果没有调用工具，则为空。
    </ParamField>
    <ParamField path="id" type="string">
        消息的唯一标识符（由 LangChain 自动生成或在提供商响应中返回）
    </ParamField>
    <ParamField path="usage_metadata" type="dict | None">
        消息的使用元数据，在可用时可以包含令牌计数。
    </ParamField>
    <ParamField path="response_metadata" type="ResponseMetadata | None">
        消息的响应元数据。
    </ParamField>
    :::

    :::js
    <ParamField path="text" type="string">
        消息的文本内容。
    </ParamField>
    <ParamField path="content" type="string | ContentBlock[]">
        消息的原始内容。
    </ParamField>
    <ParamField path="content_blocks" type="ContentBlock.Standard[]">
        消息的标准化内容块。（参见[内容](#message-content)）
    </ParamField>
    <ParamField path="tool_calls" type="ToolCall[] | None">
        模型进行的工具调用。

        如果没有调用工具，则为空。
    </ParamField>
    <ParamField path="id" type="string">
        消息的唯一标识符（由 LangChain 自动生成或在提供商响应中返回）
    </ParamField>
    <ParamField path="usage_metadata" type="UsageMetadata | None">
        消息的使用元数据，在可用时可以包含令牌计数。参见 @[`UsageMetadata`]。
    </ParamField>
    <ParamField path="response_metadata" type="ResponseMetadata | None">
        消息的响应元数据。
    </ParamField>
    :::
</Accordion>

#### 工具调用

当模型进行[工具调用](/oss/langchain/models#tool-calling)时，它们会包含在 @[`AIMessage`] 中：

:::python
```python
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-5-nano")

def get_weather(location: str) -> str:
    """Get the weather at a location."""
    ...

model_with_tools = model.bind_tools([get_weather])
response = model_with_tools.invoke("What's the weather in Paris?")

for tool_call in response.tool_calls:
    print(f"Tool: {tool_call['name']}")
    print(f"Args: {tool_call['args']}")
    print(f"ID: {tool_call['id']}")
```
:::

:::js
```typescript
const modelWithTools = model.bindTools([getWeather]);
const response = await modelWithTools.invoke("What's the weather in Paris?");

for (const toolCall of response.tool_calls) {
  console.log(`Tool: ${toolCall.name}`);
  console.log(`Args: ${toolCall.args}`);
  console.log(`ID: ${toolCall.id}`);
}
```
:::

其他结构化数据，如推理或引用，也可能出现在消息[内容](/oss/langchain/messages#message-content)中。

#### 令牌使用情况

@[`AIMessage`] 可以在其 @[`usage_metadata`][UsageMetadata] 字段中保存令牌计数和其他使用元数据：

:::python
```python
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-5-nano")

response = model.invoke("Hello!")
response.usage_metadata
```

```
{'input_tokens': 8,
 'output_tokens': 304,
 'total_tokens': 312,
 'input_token_details': {'audio': 0, 'cache_read': 0},
 'output_token_details': {'audio': 0, 'reasoning': 256}}
```
:::
:::js
```typescript
import { initChatModel } from "langchain";

const model = await initChatModel("gpt-5-nano");

const response = await model.invoke("Hello!");
console.log(response.usage_metadata);
```

```json
{
  "output_tokens": 304,
  "input_tokens": 8,
  "total_tokens": 312,
  "input_token_details": {
    "cache_read": 0
  },
  "output_token_details": {
    "reasoning": 256
  }
}
```
:::

详情参见 @[`UsageMetadata`]。

#### 流式传输和分块

在流式传输期间，你将收到 @[`AIMessageChunk`] 对象，这些对象可以组合成一个完整的消息对象：

:::python
```python
chunks = []
full_message = None
for chunk in model.stream("Hi"):
    chunks.append(chunk)
    print(chunk.text)
    full_message = chunk if full_message is None else full_message + chunk
```
:::

:::js
<CodeGroup>
```typescript
import { AIMessageChunk } from "langchain";

let finalChunk: AIMessageChunk | undefined;
for (const chunk of chunks) {
  finalChunk = finalChunk ? finalChunk.concat(chunk) : chunk;
}
```
</CodeGroup>
:::

<Note>
了解更多：
- [从聊天模型流式传输令牌](/oss/langchain/models#stream)
- [从智能体流式传输令牌和/或步骤](/oss/langchain/streaming)
</Note>

---

### 工具消息

对于支持[工具调用](/oss/langchain/models#tool-calling)的模型，AI 消息可以包含工具调用。工具消息用于将单个工具执行的结果传递回模型。

[工具](/oss/langchain/tools)可以直接生成 @[`ToolMessage`] 对象。下面我们展示一个简单的例子。更多信息请参阅[工具指南](/oss/langchain/tools)。

:::python
```python
from langchain.messages import AIMessage
from langchain.messages import ToolMessage

# 在模型进行工具调用之后
# （这里，为了简洁，我们演示手动创建消息）
ai_message = AIMessage(
    content=[],
    tool_calls=[{
        "name": "get_weather",
        "args": {"location": "San Francisco"},
        "id": "call_123"
    }]
)

# 执行工具并创建结果消息
weather_result = "Sunny, 72°F"
tool_message = ToolMessage(
    content=weather_result,
    tool_call_id="call_123"  # 必须与调用 ID 匹配
)

# 继续对话
messages = [
    HumanMessage("What's the weather in San Francisco?"),
    ai_message,  # 模型的工具调用
    tool_message,  # 工具执行结果
]
response = model.invoke(messages)  # 模型处理结果
```
:::

:::js
```typescript
import { AIMessage, ToolMessage } from "langchain";

const aiMessage = new AIMessage({
  content: [],
  tool_calls: [{
    name: "get_weather",
    args: { location: "San Francisco" },
    id: "call_123"
  }]
});

const toolMessage = new ToolMessage({
  content: "Sunny, 72°F",
  tool_call_id: "call_123"
});

const messages = [
  new HumanMessage("What's the weather in San Francisco?"),
  aiMessage,  // 模型的工具调用
  toolMessage,  // 工具执行结果
];

const response = await model.invoke(messages);  // 模型处理结果
```
:::

<Accordion title="属性">
    <ParamField path="content" type="string" required>
        工具调用的字符串化输出。
    </ParamField>
    <ParamField path="tool_call_id" type="string" required>
        此消息所响应的工具调用的 ID。必须与 @[`AIMessage`] 中工具调用的 ID 匹配。
    </ParamField>
    <ParamField path="name" type="string" required>
        被调用工具的名称。
    </ParamField>
    <ParamField path="artifact" type="dict">
        不会发送给模型但可以通过编程方式访问的额外数据。
    </ParamField>
</Accordion>

<Note>
    `artifact` 字段存储不会发送给模型但可以通过编程方式访问的补充数据。这对于存储原始结果、调试信息或用于下游处理的数据非常有用，而不会使模型的上下文变得混乱。

    <Accordion title="示例：使用 artifact 存储检索元数据">
        例如，一个[检索](/oss/langchain/retrieval)工具可以从文档中检索一段文本供模型参考
