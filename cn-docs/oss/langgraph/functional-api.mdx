---
title: 功能 API 概览
sidebarTitle: Functional API
---
**函数式 API** 允许您以最小的代码改动，为您的应用程序添加 LangGraph 的关键特性——[持久化](/oss/langgraph/persistence)、[记忆](/oss/langgraph/add-memory)、[人机交互](/oss/langgraph/interrupts)和[流式处理](/oss/langgraph/streaming)。

它旨在将这些特性集成到可能使用标准语言原语（如 `if` 语句、`for` 循环和函数调用）进行分支和控制流的现有代码中。与许多需要将代码重构为显式管道或 DAG 的数据编排框架不同，函数式 API 允许您在不强制使用严格执行模型的情况下集成这些功能。

函数式 API 使用两个关键构建块：

:::python
* **`@entrypoint`** – 将一个函数标记为工作流的起点，封装逻辑并管理执行流，包括处理长时间运行的任务和中断。
* **`@task`** – 表示一个离散的工作单元，例如 API 调用或数据处理步骤，可以在入口点内异步执行。任务返回一个类似 future 的对象，可以同步等待或解析。
:::

:::js
* **`entrypoint`** – 入口点封装工作流逻辑并管理执行流，包括处理长时间运行的任务和中断。
* **`task`** – 表示一个离散的工作单元，例如 API 调用或数据处理步骤，可以在入口点内异步执行。任务返回一个类似 future 的对象，可以同步等待或解析。
:::

这为构建具有状态管理和流式处理功能的工作流提供了一个最小的抽象层。

<Tip>
有关如何使用函数式 API 的信息，请参阅[使用函数式 API](/oss/langgraph/use-functional-api)。
</Tip>

## 函数式 API 与图 API 对比

对于更喜欢声明式方法的用户，LangGraph 的[图 API](/oss/langgraph/graph-api) 允许您使用图范式定义工作流。两个 API 共享相同的底层运行时，因此您可以在同一个应用程序中一起使用它们。

以下是一些关键区别：

* **控制流**：函数式 API 不需要考虑图结构。您可以使用标准的 Python 结构来定义工作流。这通常会减少您需要编写的代码量。
* **短期记忆**：**图 API** 需要声明一个[**状态**](/oss/langgraph/graph-api#state)，并且可能需要定义[**归约器**](/oss/langgraph/graph-api#reducers)来管理图状态的更新。`@entrypoint` 和 `@tasks` 不需要显式的状态管理，因为它们的状态作用域限定在函数内，并且不在函数间共享。
* **检查点**：两个 API 都会生成和使用检查点。在**图 API** 中，每个[超步](/oss/langgraph/graph-api)之后都会生成一个新的检查点。在**函数式 API** 中，当任务执行时，它们的结果会保存到与给定入口点关联的现有检查点中，而不是创建新的检查点。
* **可视化**：图 API 可以轻松地将工作流可视化为图，这对于调试、理解工作流和与他人共享非常有用。函数式 API 不支持可视化，因为图是在运行时动态生成的。

## 示例

下面我们演示一个简单的应用程序，它撰写一篇论文并[中断](/oss/langgraph/interrupts)以请求人工审核。

:::python
```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.func import entrypoint, task
from langgraph.types import interrupt

@task
def write_essay(topic: str) -> str:
    """Write an essay about the given topic."""
    time.sleep(1) # A placeholder for a long-running task.
    return f"An essay about topic: {topic}"

@entrypoint(checkpointer=InMemorySaver())
def workflow(topic: str) -> dict:
    """A simple workflow that writes an essay and asks for a review."""
    essay = write_essay("cat").result()
    is_approved = interrupt({
        # Any json-serializable payload provided to interrupt as argument.
        # It will be surfaced on the client side as an Interrupt when streaming data
        # from the workflow.
        "essay": essay, # The essay we want reviewed.
        # We can add any additional information that we need.
        # For example, introduce a key called "action" with some instructions.
        "action": "Please approve/reject the essay",
    })

    return {
        "essay": essay, # The essay that was generated
        "is_approved": is_approved, # Response from HIL
    }
```
:::

:::js
```typescript
import { MemorySaver, entrypoint, task, interrupt } from "@langchain/langgraph";

const writeEssay = task("writeEssay", async (topic: string) => {
  // A placeholder for a long-running task.
  await new Promise((resolve) => setTimeout(resolve, 1000));
  return `An essay about topic: ${topic}`;
});

const workflow = entrypoint(
  { checkpointer: new MemorySaver(), name: "workflow" },
  async (topic: string) => {
    const essay = await writeEssay(topic);
    const isApproved = interrupt({
      // Any json-serializable payload provided to interrupt as argument.
      // It will be surfaced on the client side as an Interrupt when streaming data
      // from the workflow.
      essay, // The essay we want reviewed.
      // We can add any additional information that we need.
      // For example, introduce a key called "action" with some instructions.
      action: "Please approve/reject the essay",
    });

    return {
      essay, // The essay that was generated
      isApproved, // Response from HIL
    };
  }
);
```
:::

<Accordion title="详细解释">
  此工作流将撰写一篇关于“cat”主题的论文，然后暂停以获取人工审核。工作流可以无限期中止，直到提供审核为止。

  当工作流恢复时，它会从头开始执行，但由于 `writeEssay` 任务的结果已经保存，任务结果将从检查点加载，而不是重新计算。

  :::python
  ```python
  import time
  import uuid
  from langgraph.func import entrypoint, task
  from langgraph.types import interrupt
  from langgraph.checkpoint.memory import InMemorySaver


  @task
  def write_essay(topic: str) -> str:
      """Write an essay about the given topic."""
      time.sleep(1)  # This is a placeholder for a long-running task.
      return f"An essay about topic: {topic}"

  @entrypoint(checkpointer=InMemorySaver())
  def workflow(topic: str) -> dict:
      """A simple workflow that writes an essay and asks for a review."""
      essay = write_essay("cat").result()
      is_approved = interrupt(
          {
              # Any json-serializable payload provided to interrupt as argument.
              # It will be surfaced on the client side as an Interrupt when streaming data
              # from the workflow.
              "essay": essay,  # The essay we want reviewed.
              # We can add any additional information that we need.
              # For example, introduce a key called "action" with some instructions.
              "action": "Please approve/reject the essay",
          }
      )
      return {
          "essay": essay,  # The essay that was generated
          "is_approved": is_approved,  # Response from HIL
      }


  thread_id = str(uuid.uuid4())
  config = {"configurable": {"thread_id": thread_id}}
  for item in workflow.stream("cat", config):
      print(item)
  # > {'write_essay': 'An essay about topic: cat'}
  # > {
  # >     '__interrupt__': (
  # >        Interrupt(
  # >            value={
  # >                'essay': 'An essay about topic: cat',
  # >                'action': 'Please approve/reject the essay'
  # >            },
  # >            id='b9b2b9d788f482663ced6dc755c9e981'
  # >        ),
  # >    )
  # > }
  ```

  论文已撰写完成，准备审核。一旦提供审核，我们就可以恢复工作流：

  ```python
  from langgraph.types import Command

  # 从用户处获取审核（例如，通过 UI）
  # 这里我们使用布尔值，但这可以是任何 JSON 可序列化的值。
  human_review = True

  for item in workflow.stream(Command(resume=human_review), config):
      print(item)
  ```

  ```pycon
  {'workflow': {'essay': 'An essay about topic: cat', 'is_approved': False}}
  ```

  工作流已完成，审核已添加到论文中。
  :::

  :::js
  ```typescript
  import { v4 as uuidv4 } from "uuid";
  import { MemorySaver, entrypoint, task, interrupt } from "@langchain/langgraph";

  const writeEssay = task("writeEssay", async (topic: string) => {
    // This is a placeholder for a long-running task.
    await new Promise(resolve => setTimeout(resolve, 1000));
    return `An essay about topic: ${topic}`;
  });

  const workflow = entrypoint(
    { checkpointer: new MemorySaver(), name: "workflow" },
    async (topic: string) => {
      const essay = await writeEssay(topic);
      const isApproved = interrupt({
        // Any json-serializable payload provided to interrupt as argument.
        // It will be surfaced on the client side as an Interrupt when streaming data
        // from the workflow.
        essay, // The essay we want reviewed.
        // We can add any additional information that we need.
        // For example, introduce a key called "action" with some instructions.
        action: "Please approve/reject the essay",
      });

      return {
        essay, // The essay that was generated
        isApproved, // Response from HIL
      };
    }
  );

  const threadId = uuidv4();

  const config = {
    configurable: {
      thread_id: threadId
    }
  };

  for await (const item of workflow.stream("cat", config)) {
    console.log(item);
  }
  ```

  ```console
  { writeEssay: 'An essay about topic: cat' }
  {
    __interrupt__: [{
      value: { essay: 'An essay about topic: cat', action: 'Please approve/reject the essay' },
      resumable: true,
      ns: ['workflow:f7b8508b-21c0-8b4c-5958-4e8de74d2684'],
      when: 'during'
    }]
  }
  ```

  论文已撰写完成，准备审核。一旦提供审核，我们就可以恢复工作流：

  ```typescript
  import { Command } from "@langchain/langgraph";

  // 从用户处获取审核（例如，通过 UI）
  // 这里我们使用布尔值，但这可以是任何 JSON 可序列化的值。
  const humanReview = true;

  for await (const item of workflow.stream(new Command({ resume: humanReview }), config)) {
    console.log(item);
  }
  ```

  ```console
  { workflow: { essay: 'An essay about topic: cat', isApproved: true } }
  ```

  工作流已完成，审核已添加到论文中。
  :::
</Accordion>

## 入口点

:::python
@[`@entrypoint`] 装饰器可用于从函数创建工作流。它封装工作流逻辑并管理执行流，包括处理*长时间运行的任务*和[中断](/oss/langgraph/interrupts)。
:::

:::js
@[`entrypoint`][entrypoint] 函数可用于从函数创建工作流。它封装工作流逻辑并管理执行流，包括处理*长时间运行的任务*和[中断](/oss/langgraph/interrupts)。
:::

### 定义

:::python
**入口点** 通过使用 `@entrypoint` 装饰器装饰一个函数来定义。

该函数**必须接受一个位置参数**，作为工作流的输入。如果需要传递多个数据，请使用字典作为第一个参数的输入类型。

用 `entrypoint` 装饰函数会产生一个 @[`Pregel`][Pregel.stream] 实例，它有助于管理工作流的执行（例如，处理流式传输、恢复和检查点）。

您通常希望将**检查点器**传递给 `@entrypoint` 装饰器，以启用持久化并使用**人机交互**等功能。

<Tabs>
    <Tab title="同步">
    ```python
    from langgraph.func import entrypoint

    @entrypoint(checkpointer=checkpointer)
    def my_workflow(some_input: dict) -> int:
        # some logic that may involve long-running tasks like API calls,
        # and may be interrupted for human-in-the-loop.
        ...
        return result
    ```
    </Tab>
    <Tab title="异步">
    ```python
    from langgraph.func import entrypoint

    @entrypoint(checkpointer=checkpointer)
    async def my_workflow(some_input: dict) -> int:
        # some logic that may involve long-running tasks like API calls,
        # and may be interrupted for human-in-the-loop
        ...
        return result
    ```
    </Tab>
</Tabs>
:::

:::js
**入口点** 通过使用配置和函数调用 `entrypoint` 函数来定义。

该函数**必须接受一个位置参数**，作为工作流的输入。如果需要传递多个数据，请使用对象作为第一个参数的输入类型。

使用函数创建入口点会产生一个工作流实例，它有助于管理工作流的执行（例如，处理流式传输、恢复和检查点）。

您通常希望将**检查点器**传递给 `entrypoint` 函数，以启用持久化并使用**人机交互**等功能。

```typescript
import { entrypoint } from "@langchain/langgraph";

const myWorkflow = entrypoint(
  { checkpointer, name: "workflow" },
  async (someInput: Record<string, any>): Promise<number> => {
    // some logic that may involve long-running tasks like API calls,
    // and may be interrupted for human-in-the-loop
    return result;
  }
);
```
:::

<Warning>
**序列化**
入口点的**输入**和**输出**必须是 JSON 可序列化的，以支持检查点。请参阅[序列化](#serialization)部分了解更多详情。
</Warning>

:::python
### 可注入参数

声明 `entrypoint` 时，您可以请求访问将在运行时自动注入的附加参数。这些参数包括：

| 参数 | 描述 |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **previous** | 访问给定线程的上一个 `checkpoint` 关联的状态。请参阅[短期记忆](#short-term-memory)。 |
| **store** | [BaseStore][langgraph.store.base.BaseStore] 的一个实例。对于[长期记忆](/oss/langgraph/use-functional-api#long-term-memory)很有用。 |
| **writer** | 在使用 Async Python < 3.11 时，用于访问 StreamWriter。有关详细信息，请参阅[使用函数式 API 进行流式处理](/oss/langgraph/use-functional-api#streaming)。 |
| **config** | 用于访问运行时配置。有关信息，请参阅 [RunnableConfig](https://python.langchain.com/docs/concepts/runnables/#runnableconfig)。 |

<Warning>
请使用适当的名称和类型注解声明参数。
</Warning>

<Accordion title="请求可注入参数">
  ```python
  from langchain_core.runnables import RunnableConfig
  from langgraph.func import entrypoint
  from langgraph.store.base import BaseStore
  from langgraph.store.memory import InMemoryStore
  from langgraph.checkpoint.memory import InMemorySaver
  from langgraph.types import StreamWriter

  in_memory_checkpointer = InMemorySaver(...)
  in_memory_store = InMemoryStore(...)  # 用于长期记忆的 InMemoryStore 实例

  @entrypoint(
      checkpointer=in_memory_checkpointer,  # 指定检查点器
      store=in_memory_store  # 指定存储
  )
  def my_workflow(
      some_input: dict,  # 输入（例如，通过 `invoke` 传递）
      *,
      previous: Any = None, # 用于短期记忆
      store: BaseStore,  # 用于长期记忆
      writer: StreamWriter,  # 用于流式传输自定义数据
      config: RunnableConfig  # 用于访问传递给入口点的配置
  ) -> ...:
  ```
</Accordion>
:::

### 执行

:::python
使用 [`@entrypoint`](#entrypoint) 会产生一个 @[`Pregel`][Pregel.stream] 对象，可以使用 `invoke`、`ainvoke`、`stream` 和 `astream` 方法执行。

<Tabs>
    <Tab title="Invoke">
    ```python
    config = {
        "configurable": {
            "thread_id": "some_thread_id"
        }
    }
    my_workflow.invoke(some_input, config)  # 同步等待结果
    ```
    </Tab>
    <Tab title="Async Invoke">
    ```python
    config = {
        "configurable": {
            "thread_id": "some_thread_id"
        }
    }
    await my_workflow.ainvoke(some_input, config)  # 异步等待结果
    ```
    </Tab>
    <Tab title="Stream">
    ```python
    config = {
        "configurable": {
            "thread_id": "some_thread_id"
        }
    }

    for chunk in my_workflow.stream(some_input, config):
        print(chunk)
    ```
    </Tab>
    <Tab title="Async Stream">
    ```python
    config = {
        "configurable": {
            "thread_id": "some_thread_id"
        }
    }

    async for chunk in my_workflow.astream(some_input, config):
        print(chunk)
    ```
    </Tab>
</Tabs>
:::

:::js
使用 [`entrypoint`](#entrypoint) 函数将返回一个可以使用 `invoke` 和 `stream` 方法执行的对象。

<Tabs>
    <Tab title="Invoke">
    ```typescript
    const config = {
      configurable: {
        thread_id: "some_thread_id"
      }
    };
    await myWorkflow.invoke(someInput, config); // 等待结果
    ```
    </Tab>
    <Tab title="Stream">
    ```typescript
    const config = {
      configurable: {
        thread_id: "some_thread_id"
      }
