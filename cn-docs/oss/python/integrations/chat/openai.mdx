---
title: ChatOpenAI
description: '开始使用 LangChain 中的 OpenAI [聊天模型](/oss/langchain/models)。'
---
你可以在 [OpenAI Platform](https://platform.openai.com) 文档中找到关于 OpenAI 最新模型、成本、上下文窗口和支持的输入类型的信息。

<Tip>
    **API 参考**

    有关所有功能和配置选项的详细文档，请查阅 @[`ChatOpenAI`] API 参考。
</Tip>

<Note>
    **Chat Completions API 兼容性**

    `ChatOpenAI` 与 OpenAI 的 [Chat Completions API](https://platform.openai.com/docs/api-reference/chat) 完全兼容。如果你想连接到其他支持 Chat Completions API 的模型提供商，也可以实现——请参阅[说明](/oss/integrations/chat#chat-completions-api)。
</Note>

## 概述

### 集成详情

| 类 | 包 | 可序列化 | JS/TS 支持 | 下载量 | 最新版本 |
| :--- | :--- | :---: |  :---: | :---: | :---: |
| @[`ChatOpenAI`] | @[`langchain-openai`] | beta | ✅ [(npm)](https://js.langchain.com/docs/integrations/chat/openai) | <a href="https://pypi.org/project/langchain-openai/" target="_blank"><img src="https://static.pepy.tech/badge/langchain-openai/month" alt="Downloads per month" noZoom height="100" class="rounded" /></a> | <a href="https://pypi.org/project/langchain-openai/" target="_blank"><img src="https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20&color=orange" alt="PyPI - Latest version" noZoom height="100" class="rounded" /></a> |

### 模型特性

| [工具调用](/oss/langchain/tools) | [结构化输出](/oss/langchain/structured-output) | 图像输入 | 音频输入 | 视频输入 | [令牌级流式传输](/oss/langchain/streaming/) | 原生异步 | [令牌使用量](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ❌ | ✅ | ✅ | ✅ | ✅ |

## 设置

要访问 OpenAI 模型，你需要安装 `langchain-openai` 集成包并获取一个 [OpenAI Platform](https://platform.openai.com) API 密钥。

### 安装

<CodeGroup>
    ```bash pip
    pip install -U langchain-openai
    ```
    ```bash uv
    uv add langchain-openai
    ```
</CodeGroup>

### 凭证

前往 [OpenAI Platform](https://platform.openai.com/docs/api-reference/authentication) 注册并生成一个 API 密钥。完成后，在你的环境中设置 `OPENAI_API_KEY` 环境变量：

```python
import getpass
import os

if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
```

如果你想自动追踪模型调用，也可以设置你的 [LangSmith](/langsmith/home) API 密钥：

```python
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

## 实例化

现在我们可以实例化模型对象并生成响应：

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-5-nano",
    # stream_usage=True,
    # temperature=None,
    # max_tokens=None,
    # timeout=None,
    # reasoning_effort="low",
    # max_retries=2,
    # api_key="...",  # 如果你希望直接传入 api key
    # base_url="...",
    # organization="...",
    # other params...
)
```

完整的可用模型参数集，请参阅 @[`ChatOpenAI`] API 参考。

<Note>
    **令牌参数弃用**

    OpenAI 于 2024 年 9 月弃用了 `max_tokens`，转而支持 `max_completion_tokens`。虽然为了向后兼容，`max_tokens` 仍然受支持，但它会在内部自动转换为 `max_completion_tokens`。
</Note>

---

## 调用

```python
messages = [
    (
        "system",
        "You are a helpful assistant that translates English to French. Translate the user sentence.",
    ),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```text
AIMessage(content="J'adore la programmation.", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None}, id='run-63219b22-03e3-4561-8cc4-78b7c7c3a3ca-0', usage_metadata={'input_tokens': 31, 'output_tokens': 5, 'total_tokens': 36})
```

```python
print(ai_msg.text)
```

```text
J'adore la programmation.
```

---

## 流式传输使用元数据

OpenAI 的 Chat Completions API 默认不流式传输令牌使用统计信息（参见 API 参考[此处](https://platform.openai.com/docs/api-reference/completions/create#completions-create-stream_options)）。

要在使用 @[`ChatOpenAI`] 或 `AzureChatOpenAI` 进行流式传输时恢复令牌计数，请将 `stream_usage=True` 设置为初始化参数或在调用时设置：

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4.1-mini", stream_usage=True)  # [!code highlight]
```

---

## 与 Azure OpenAI 一起使用

<Info>
    **Azure OpenAI v1 API 支持**

    从 `langchain-openai>=1.0.1` 开始，`ChatOpenAI` 可以直接使用新的 [v1 API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle?tabs=python#next-generation-api-1) 与 Azure OpenAI 端点一起使用。这提供了一种统一的方式来使用 OpenAI 模型，无论它们托管在 OpenAI 还是 Azure 上。

    对于传统的 Azure 特定实现，请继续使用 [`AzureChatOpenAI`](/oss/integrations/chat/azure_chat_openai/)。
</Info>

<Accordion title="使用 API 密钥与 Azure OpenAI v1 API">

要使用 `ChatOpenAI` 与 Azure OpenAI，请将 `base_url` 设置为你的 Azure 端点，并附加 `/openai/v1/`：

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-5-mini",  # 你的 Azure 部署名称
    base_url="https://{your-resource-name}.openai.azure.com/openai/v1/",
    api_key="your-azure-api-key"
)

response = llm.invoke("Hello, how are you?")
print(response.content)
```
</Accordion>

<Accordion title="使用 Microsoft Entra ID 与 Azure OpenAI">

v1 API 新增了对 [Microsoft Entra ID](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/managed-identity)（原 Azure AD）身份验证的原生支持，并支持自动令牌刷新。将一个令牌提供者可调用对象传递给 `api_key` 参数：

```python
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from langchain_openai import ChatOpenAI

# 创建一个处理自动刷新的令牌提供者
token_provider = get_bearer_token_provider(
    DefaultAzureCredential(),
    "https://cognitiveservices.azure.com/.default"
)

llm = ChatOpenAI(
    model="gpt-5-mini",  # 你的 Azure 部署名称
    base_url="https://{your-resource-name}.openai.azure.com/openai/v1/",
    api_key=token_provider  # 处理令牌刷新的可调用对象
)

# 正常使用模型
messages = [
    ("system", "You are a helpful assistant."),
    ("human", "Translate 'I love programming' to French.")
]
response = llm.invoke(messages)
print(response.content)
```

令牌提供者是一个可调用对象，它会自动检索和刷新身份验证令牌，无需手动管理令牌过期。

<Tip>
**安装要求**

要使用 Microsoft Entra ID 身份验证，请安装 Azure Identity 库：

```bash
pip install azure-identity
```

</Tip>

你也可以在使用异步函数时将令牌提供者可调用对象传递给 `api_key` 参数。你必须从 `azure.identity.aio` 导入 DefaultAzureCredential：

```python
from azure.identity.aio import DefaultAzureCredential
from langchain_openai import ChatOpenAI

credential = DefaultAzureCredential()

llm_async = ChatOpenAI(
    model="gpt-5-nano",
    api_key=credential
)

# 使用异步可调用对象时，使用异步方法
response = await llm_async.ainvoke("Hello!")
```

<Note>
当使用异步可调用对象作为 API 密钥时，你必须使用异步方法（`ainvoke`、`astream` 等）。同步方法会引发错误。
</Note>

</Accordion>

---

## 工具调用

OpenAI 有一个[工具调用](https://platform.openai.com/docs/guides/function-calling) API（我们在这里交替使用“工具调用”和“函数调用”），它允许你描述工具及其参数，并让模型返回一个 JSON 对象，其中包含要调用的工具和该工具的输入。工具调用对于构建使用工具的链和智能体，以及更普遍地从模型获取结构化输出非常有用。

### 绑定工具

使用 `ChatOpenAI.bind_tools`，我们可以轻松地将 Pydantic 类、字典模式、LangChain 工具甚至函数作为工具传递给模型。在底层，这些会被转换为 OpenAI 工具模式，看起来像：

```
{
    "name": "...",
    "description": "...",
    "parameters": {...}  # JSONSchema
}
```

...并在每次模型调用时传入。

```python
from pydantic import BaseModel, Field


class GetWeather(BaseModel):
    """Get the current weather in a given location"""

    location: str = Field(..., description="The city and state, e.g. San Francisco, CA")


llm_with_tools = llm.bind_tools([GetWeather])
```

```python
ai_msg = llm_with_tools.invoke(
    "what is the weather like in San Francisco",
)
ai_msg
```

```text
AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 68, 'total_tokens': 85}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1617c9b2-dda5-4120-996b-0333ed5992e2-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_o9udf3EVOWiV4Iupktpbpofk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 68, 'output_tokens': 17, 'total_tokens': 85})
```

### 严格模式

<Info>
    **需要 `langchain-openai>=0.1.21`**
</Info>

自 2024 年 8 月 6 日起，OpenAI 在调用工具时支持 `strict` 参数，该参数将强制模型遵守工具参数模式。[了解更多](https://platform.openai.com/docs/guides/function-calling)。

<Note>
    如果 `strict=True`，工具定义也将被验证，并且只接受 JSON 模式的一个子集。关键是，模式不能有可选参数（那些有默认值的参数）。

    阅读[完整文档](https://platform.openai.com/docs/guides/structured-outputs/supported-schemas)，了解支持哪些类型的模式。
</Note>

```python
llm_with_tools = llm.bind_tools([GetWeather], strict=True)
ai_msg = llm_with_tools.invoke(
    "what is the weather like in San Francisco",
)
ai_msg
```

```text
AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jUqhd8wzAIzInTJl72Rla8ht', 'function': {'arguments': '{"location":"San Francisco, CA"}', 'name': 'GetWeather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 68, 'total_tokens': 85}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5e3356a9-132d-4623-8e73-dd5a898cf4a6-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_jUqhd8wzAIzInTJl72Rla8ht', 'type': 'tool_call'}], usage_metadata={'input_tokens': 68, 'output_tokens': 17, 'total_tokens': 85})
```

### 工具调用

注意，AIMessage 有一个 `tool_calls` 属性。它包含一个标准化的 ToolCall 格式，该格式与模型提供商无关。

```python
ai_msg.tool_calls
```

```text
[{'name': 'GetWeather',
  'args': {'location': 'San Francisco, CA'},
  'id': 'call_jUqhd8wzAIzInTJl72Rla8ht',
  'type': 'tool_call'}]
```

有关绑定工具和工具调用输出的更多信息，请参阅[工具调用](/oss/langchain/tools)文档。

### 结构化输出和工具调用

OpenAI 的[结构化输出](https://platform.openai.com/docs/guides/structured-outputs)功能可以与工具调用同时使用。模型将生成工具调用或符合所需模式的响应。参见下面的示例：

```python
from langchain_openai import ChatOpenAI
from pydantic import BaseModel


def get_weather(location: str) -> None:
    """Get weather at a location."""
    return "It's sunny."


class OutputSchema(BaseModel):
    """Schema for response."""

    answer: str
    justification: str


llm = ChatOpenAI(model="gpt-4.1")

structured_llm = llm.bind_tools(
    [get_weather],
    response_format=OutputSchema,
    strict=True,
)

# 响应包含工具调用：
tool_call_response = structured_llm.invoke("What is the weather in SF?")

# structured_response.additional_kwargs["parsed"] 包含解析后的输出
structured_response = structured_llm.invoke(
    "What weighs more, a pound of feathers or a pound of gold?"
)
```

### 自定义工具

<Info>
**需要 `langchain-openai>=0.3.29`**
</Info>

[自定义工具](https://platform.openai.com/docs/guides/function-calling#custom-tools)支持具有任意字符串输入的工具。当你期望字符串参数很长或很复杂时，它们可能特别有用。

```python
from langchain_openai import ChatOpenAI, custom_tool
from langchain.agents import create_agent


@custom_tool
def execute_code(code: str) -> str:
    """Execute python code."""
    return "27"


llm = ChatOpenAI(model="gpt-5", use_responses_api=True)

agent = create_agent(llm, [execute_code])

input_message = {"role": "user", "content": "Use the tool to calculate 3^3."}
for step in agent.stream(
    {"messages": [input_message]},
    stream_mode="values",
):
    step["messages"][-1].pretty_print()
```

```text
================================ Human Message =================================

Use the tool to calculate 3^3.
================================== Ai Message ==================================

[{'id': 'rs_68b7336cb72081a080da70bf5e980e4e0d6082d28f91357a', 'summary': [], 'type': 'reasoning'}, {'call_id': 'call_qyKsJ4XlGRudbIJDrXVA2nQa', 'input': 'print(3**3)', 'name': 'execute_code', 'type': 'custom_tool_call', 'id': 'ctc_68b7336f718481a0b39584cd35fbaa5d0d6082d28f91357a', 'status': 'completed'}]
Tool Calls:
  execute_code (call_qyKsJ4XlGRudbIJDrXVA2nQa)
 Call ID: call_qyKsJ4XlGRudbIJDrXVA2nQa
  Args:
    __arg1: print(3**3)
================================= Tool Message =================================
Name: execute_code

[{'type': 'custom_tool_call_output', 'output': '27'}]
================================== Ai Message ==================================

[{'type': 'text', 'text': '27', 'annotations': [], 'id': 'msg_68b73371e9e081a0927f54f88f2cd7a20d6082d28f91357a'}]
```

<Accordion
