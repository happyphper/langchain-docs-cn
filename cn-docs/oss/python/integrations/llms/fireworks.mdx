---
title: Fireworks
---
<Warning>
**您当前正在查看的是关于将 Fireworks 模型用作文本补全模型的文档页面。许多流行的 Fireworks 模型是 [聊天补全模型](/oss/langchain/models)。**

您可能想查看 [这个页面](/oss/integrations/chat/fireworks/)。
</Warning>

>[Fireworks](https://app.fireworks.ai/) 通过创建一个创新的 AI 实验和生产平台，加速生成式 AI 的产品开发。

本示例将介绍如何使用 LangChain 与 `Fireworks` 模型进行交互。

## 概述

### 集成详情

| 类 | 包 | 本地 | 可序列化 | [JS 支持](https://js.langchain.com/v0.1/docs/integrations/llms/fireworks/) | 下载量 | 版本 |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`Fireworks`](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [`langchain-fireworks`](https://pypi.org/project/langchain-fireworks/) | ❌ | ❌ | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_fireworks?style=flat-square&label=%20) |

## 设置

### 凭证

登录 [Fireworks AI](http://fireworks.ai) 获取访问我们模型的 API 密钥，并确保将其设置为 `FIREWORKS_API_KEY` 环境变量。
3. 使用模型 ID 设置您的模型。如果未设置模型，默认模型为 fireworks-llama-v2-7b-chat。请在 [fireworks.ai](https://app.fireworks.ai/models) 上查看完整且最新的模型列表。

```python
import getpass
import os

if "FIREWORKS_API_KEY" not in os.environ:
    os.environ["FIREWORKS_API_KEY"] = getpass.getpass("Fireworks API Key:")
```

### 安装

您需要安装 `langchain-fireworks` Python 包才能使本笔记本的其余部分正常工作。

```python
pip install -qU langchain-fireworks
```

## 实例化

```python
from langchain_fireworks import Fireworks

# 初始化一个 Fireworks 模型
llm = Fireworks(
    model="accounts/fireworks/models/llama-v3p1-8b-instruct", # 模型库位于: https://app.fireworks.ai/models
    base_url="https://api.fireworks.ai/inference/v1/completions",
)
```

## 调用

您可以直接使用字符串提示调用模型以获得补全结果。

```python
output = llm.invoke("Who's the best quarterback in the NFL?")
print(output)
```

```text
  That's an easy one. It's Aaron Rodgers. Rodgers has consistently been one
```

### 使用多个提示调用

```python
# 调用多个提示
output = llm.generate(
    [
        "Who's the best cricket player in 2016?",
        "Who's the best basketball player in the league?",
    ]
)
print(output.generations)
```

```text
[[Generation(text=' You could choose one of the top performers in 2016, such as Vir')], [Generation(text=' -- Keith Jackson\nA: LeBron James, Chris Paul and Kobe Bryant are the')]]
```

### 使用附加参数调用

```python
# 设置附加参数：temperature, max_tokens, top_p
llm = Fireworks(
    model="accounts/fireworks/models/llama-v3p1-8b-instruct",
    temperature=0.7,
    max_tokens=15,
    top_p=1.0,
)
print(llm.invoke("What's the weather like in Kansas City in December?"))
```

```text
December is a cold month in Kansas City, with temperatures of
```

## 链式调用

您可以使用 LangChain 表达式语言（LangChain Expression Language）与非聊天模型创建一个简单的链。

```python
from langchain_core.prompts import PromptTemplate
from langchain_fireworks import Fireworks

llm = Fireworks(
    model="accounts/fireworks/models/llama-v3p1-8b-instruct",
    temperature=0.7,
    max_tokens=15,
    top_p=1.0,
)
prompt = PromptTemplate.from_template("Tell me a joke about {topic}?")
chain = prompt | llm

print(chain.invoke({"topic": "bears"}))
```

```text
 What do you call a bear with no teeth? A gummy bear!
```

## 流式输出

如果需要，您可以流式输出结果。

```python
for token in chain.stream({"topic": "bears"}):
    print(token, end="", flush=True)
```

```text
 Why do bears hate shoes so much? They like to run around in their
```

---

## API 参考

有关 `Fireworks` LLM 所有功能和配置的详细文档，请前往 [API 参考](https://reference.langchain.com/python/integrations/langchain_fireworks/)
