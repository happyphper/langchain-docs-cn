---
title: OpenAIEmbeddings
---
本文将帮助您开始使用 LangChain 的 OpenAI 嵌入模型。有关 `OpenAIEmbeddings` 功能和配置选项的详细文档，请参阅 [API 参考](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)。

## 概述

### 集成详情

<ItemTable category="text_embedding" item="OpenAI" />

## 设置

要访问 OpenAI 嵌入模型，您需要创建一个 OpenAI 账户，获取 API 密钥，并安装 `langchain-openai` 集成包。

### 凭证

前往 [platform.openai.com](https://platform.openai.com) 注册 OpenAI 并生成 API 密钥。完成后，设置 `OPENAI_API_KEY` 环境变量：

```python
import getpass
import os

if not os.getenv("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
```

要启用模型调用的自动追踪，请设置您的 [LangSmith](https://docs.langchain.com/langsmith/home) API 密钥：

```python
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
```

### 安装

LangChain OpenAI 集成位于 `langchain-openai` 包中：

```python
pip install -qU langchain-openai
```

## 实例化

现在我们可以实例化模型对象并生成嵌入：

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    # 对于 `text-embedding-3` 系列的模型，
    # 您可以指定希望返回的嵌入向量维度。
    # dimensions=1024
)
```

<Info>
    **Azure OpenAI v1 API 支持**

    自 `langchain-openai>=1.0.1` 起，`OpenAIEmbeddings` 可以直接与使用新版 [v1 API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle?tabs=python#next-generation-api-1) 的 Azure OpenAI 端点一起使用，包括支持 Microsoft Entra ID 身份验证。详情请参阅下面的 [与 Azure OpenAI 一起使用](#using-with-azure-openai) 部分。
</Info>

## 索引与检索

嵌入模型通常用于检索增强生成 (RAG) 流程中，既用于索引数据，也用于后续检索。更详细的说明，请参阅我们的 [RAG 教程](/oss/langchain/rag)。

下面，我们将展示如何使用上面初始化的 `embeddings` 对象来索引和检索数据。在这个例子中，我们将在 `InMemoryVectorStore` 中索引和检索一个示例文档。

```python
# 使用示例文本创建向量存储
from langchain_core.vectorstores import InMemoryVectorStore

text = "LangChain is the framework for building context-aware reasoning applications"

vectorstore = InMemoryVectorStore.from_texts(
    [text],
    embedding=embeddings,
)

# 将向量存储用作检索器
retriever = vectorstore.as_retriever()

# 检索最相似的文本
retrieved_documents = retriever.invoke("What is LangChain?")

# 显示检索到的文档内容
retrieved_documents[0].page_content
```

```text
'LangChain is the framework for building context-aware reasoning applications'
```

## 直接使用

在底层，向量存储和检索器的实现分别调用 `embeddings.embed_documents(...)` 和 `embeddings.embed_query(...)` 来为 `from_texts` 中使用的文本和检索 `invoke` 操作创建嵌入。

您可以直接调用这些方法来获取嵌入，以满足您自己的用例。

### 嵌入单个文本

您可以使用 `embed_query` 嵌入单个文本或文档：

```python
single_vector = embeddings.embed_query(text)
print(str(single_vector)[:100])  # 显示向量的前 100 个字符
```

```text
[-0.019276829436421394, 0.0037708976306021214, -0.03294256329536438, 0.0037671267054975033, 0.008175
```

### 嵌入多个文本

您可以使用 `embed_documents` 嵌入多个文本：

```python
text2 = (
    "LangGraph is a library for building stateful, multi-actor applications with LLMs"
)
two_vectors = embeddings.embed_documents([text, text2])
for vector in two_vectors:
    print(str(vector)[:100])  # 显示向量的前 100 个字符
```

```text
[-0.019260549917817116, 0.0037612367887049913, -0.03291035071015358, 0.003757466096431017, 0.0082049
[-0.010181212797760963, 0.023419594392180443, -0.04215526953339577, -0.001532090245746076, -0.023573
```

## 与 Azure OpenAI 一起使用

<Info>
    **Azure OpenAI v1 API 支持**

    自 `langchain-openai>=1.0.1` 起，`OpenAIEmbeddings` 可以直接与使用新版 [v1 API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle?tabs=python#next-generation-api-1) 的 Azure OpenAI 端点一起使用。这为使用 OpenAI 嵌入提供了一种统一的方式，无论其托管在 OpenAI 还是 Azure 上。

    对于传统的 Azure 特定实现，请继续使用 [`AzureOpenAIEmbeddings`](/oss/integrations/text_embedding/azure_openai)。
</Info>

### 使用 API 密钥配合 Azure OpenAI v1 API

要将 `OpenAIEmbeddings` 与 Azure OpenAI 一起使用，请将 `base_url` 设置为您的 Azure 端点，并附加 `/openai/v1/`：

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",  # 您的 Azure 部署名称
    base_url="https://{your-resource-name}.openai.azure.com/openai/v1/",
    api_key="your-azure-api-key"
)

# 正常使用
vector = embeddings.embed_query("Hello world")
```

### 使用 Microsoft Entra ID 配合 Azure OpenAI

v1 API 新增了对 [Microsoft Entra ID](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/managed-identity) 身份验证的原生支持，并支持自动令牌刷新。将一个令牌提供者可调用对象传递给 `api_key` 参数：

```python
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from langchain_openai import OpenAIEmbeddings

# 创建一个处理自动刷新的令牌提供者
token_provider = get_bearer_token_provider(
    DefaultAzureCredential(),
    "https://cognitiveservices.azure.com/.default"
)

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",  # 您的 Azure 部署名称
    base_url="https://{your-resource-name}.openai.azure.com/openai/v1/",
    api_key=token_provider  # 处理令牌刷新的可调用对象
)

# 正常使用
vectors = embeddings.embed_documents(["Hello", "World"])
```

<Tip>
**安装要求**

要使用 Microsoft Entra ID 身份验证，请安装 Azure Identity 库：

```bash
pip install azure-identity
```

</Tip>

您也可以在使用异步函数时将令牌提供者可调用对象传递给 `api_key` 参数。您必须从 `azure.identity.aio` 导入 DefaultAzureCredential：

:::python

```python
from azure.identity.aio import DefaultAzureCredential
from langchain_openai import OpenAIEmbeddings

credential = DefaultAzureCredential()

embeddings_async = OpenAIEmbeddings(
    model="text-embedding-3-large",
    api_key=credential
)

# 使用异步可调用对象时，使用异步方法
vectors = await embeddings_async.aembed_documents(["Hello", "World"])

```

:::

<Note>
    当为 API 密钥使用异步可调用对象时，您必须使用异步方法 (`aembed_query`, `aembed_documents`)。同步方法将引发错误。
</Note>

---

## API 参考

有关 `OpenAIEmbeddings` 功能和配置选项的详细文档，请参阅 [API 参考](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)。
