---
title: Activeloop Deep Lake
---
>[Activeloop Deep Lake](https://docs.deeplake.ai/) 是一个多模态向量存储，可以存储嵌入向量及其元数据，包括文本、JSON、图像、音频、视频等。它可以将数据保存在本地、您的云端或 Activeloop 存储中。它支持混合搜索，包括嵌入向量及其属性。

本笔记本展示了与 `Activeloop Deep Lake` 相关的基本功能。虽然 `Deep Lake` 可以存储嵌入向量，但它也能够存储任何类型的数据。它是一个无服务器数据湖，具有版本控制、查询引擎和流向深度学习框架的流式数据加载器。

更多信息，请参阅 Deep Lake [文档](https://docs.deeplake.ai/)

## 环境设置

```python
pip install -qU  langchain-openai langchain-deeplake tiktoken
```

## Activeloop 提供的示例

[与 LangChain 的集成](https://docs.activeloop.ai/tutorials/vector-store/deep-lake-vector-store-in-langchain)。

## 本地运行 Deep Lake

```python
from langchain_deeplake.vectorstores import DeeplakeVectorStore
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
```

```python
import getpass
import os

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")

if "ACTIVELOOP_TOKEN" not in os.environ:
    os.environ["ACTIVELOOP_TOKEN"] = getpass.getpass("activeloop token:")
```

```python
from langchain_community.document_loaders import TextLoader

loader = TextLoader("../../how_to/state_of_the_union.txt")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
```

### 创建本地数据集

在 `./my_deeplake/` 路径下本地创建一个数据集，然后运行相似性搜索。DeepLake+LangChain 集成在底层使用 Deep Lake 数据集，因此 `dataset` 和 `vector store` 可以互换使用。要在您自己的云端或 Deep Lake 存储中创建数据集，请[相应调整路径](https://docs.deeplake.ai/latest/getting-started/storage-and-creds/storage-options/)。

```python
db = DeeplakeVectorStore(
    dataset_path="./my_deeplake/", embedding_function=embeddings, overwrite=True
)
db.add_documents(docs)
# 或者更简洁的写法
# db = DeepLake.from_documents(docs, dataset_path="./my_deeplake/", embedding_function=embeddings, overwrite=True)
```

### 查询数据集

```python
query = "What did the president say about Ketanji Brown Jackson"
docs = db.similarity_search(query)
```

```python
print(docs[0].page_content)
```

之后，您可以重新加载数据集而无需重新计算嵌入向量

```python
db = DeeplakeVectorStore(
    dataset_path="./my_deeplake/", embedding_function=embeddings, read_only=True
)
docs = db.similarity_search(query)
```

设置 `read_only=True` 可以在不需要更新时防止意外修改向量存储。这确保数据除非明确意图，否则保持不变。通常，指定此参数以避免意外更新是一个良好的实践。

### 检索式问答

```python
from langchain_classic.chains import RetrievalQA
from langchain_openai import ChatOpenAI

qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    chain_type="stuff",
    retriever=db.as_retriever(),
)
```

```python
query = "What did the president say about Ketanji Brown Jackson"
qa.run(query)
```

### 元数据中基于属性的过滤

让我们创建另一个包含文档创建年份元数据的向量存储。

```python
import random

for d in docs:
    d.metadata["year"] = random.randint(2012, 2014)

db = DeeplakeVectorStore.from_documents(
    docs, embeddings, dataset_path="./my_deeplake/", overwrite=True
)
```

```python
db.similarity_search(
    "What did the president say about Ketanji Brown Jackson",
    filter={"metadata": {"year": 2013}},
)
```

### 选择距离函数

距离函数 `L2` 用于欧几里得距离，`cos` 用于余弦相似度

```python
db.similarity_search(
    "What did the president say about Ketanji Brown Jackson?", distance_metric="l2"
)
```

### 最大边际相关性

使用最大边际相关性

```python
db.max_marginal_relevance_search(
    "What did the president say about Ketanji Brown Jackson?"
)
```

### 删除数据集

```python
db.delete_dataset()
```

## 云端（Activeloop、AWS、GCS 等）或内存中的 Deep Lake 数据集

默认情况下，Deep Lake 数据集存储在本地。要将它们存储在内存中、Deep Lake 托管数据库或任何对象存储中，您可以在创建向量存储时提供[相应的路径和凭据](https://docs.deeplake.ai/latest/getting-started/storage-and-creds/storage-options/)。某些路径需要在 Activeloop 注册并创建 API 令牌，可以[在此处获取](https://app.activeloop.ai/)

```python
os.environ["ACTIVELOOP_TOKEN"] = activeloop_token
```

```python
# 嵌入并存储文本
username = "<USERNAME_OR_ORG>"  # 您在 app.activeloop.ai 上的用户名
dataset_path = f"hub://{username}/langchain_testing_python"  # 也可以是 ./local/path（本地更快）、s3://bucket/path/to/dataset、gcs://path/to/dataset 等。

docs = text_splitter.split_documents(documents)

embedding = OpenAIEmbeddings()
db = DeeplakeVectorStore(
    dataset_path=dataset_path, embedding_function=embeddings, overwrite=True
)
ids = db.add_documents(docs)
```

```python
query = "What did the president say about Ketanji Brown Jackson"
docs = db.similarity_search(query)
print(docs[0].page_content)
```

```python
# 嵌入并存储文本
username = "<USERNAME_OR_ORG>"  # 您在 app.activeloop.ai 上的用户名
dataset_path = f"hub://{username}/langchain_testing"

docs = text_splitter.split_documents(documents)

embedding = OpenAIEmbeddings()
db = DeeplakeVectorStore(
    dataset_path=dataset_path,
    embedding_function=embeddings,
    overwrite=True,
)
ids = db.add_documents(docs)
```

### TQL 搜索

此外，`similarity_search` 方法也支持执行查询，其中可以使用 Deep Lake 的张量查询语言 (TQL) 来指定查询。

```python
search_id = db.dataset["ids"][0]
```

```python
docs = db.similarity_search(
    query=None,
    tql=f"SELECT * WHERE ids == '{search_id}'",
)
```

```python
db.dataset.summary()
```

### 在 AWS S3 上创建向量存储

```python
dataset_path = "s3://BUCKET/langchain_test"  # 也可以是 ./local/path（本地更快）、hub://bucket/path/to/dataset、gcs://path/to/dataset 等。

embedding = OpenAIEmbeddings()
db = DeeplakeVectorStore.from_documents(
    docs,
    dataset_path=dataset_path,
    embedding=embeddings,
    overwrite=True,
    creds={
        "aws_access_key_id": os.environ["AWS_ACCESS_KEY_ID"],
        "aws_secret_access_key": os.environ["AWS_SECRET_ACCESS_KEY"],
        "aws_session_token": os.environ["AWS_SESSION_TOKEN"],  # 可选
    },
)
```

## Deep Lake API

您可以通过 `db.vectorstore` 访问 Deep Lake 数据集

```python
# 获取数据集结构
db.dataset.summary()
```

```python
# 获取嵌入向量 numpy 数组
embeds = db.dataset["embeddings"][:]
```

### 将本地数据集传输到云端

将已创建的数据集复制到云端。您也可以从云端传输到本地。

```python
import deeplake

username = "<USERNAME_OR_ORG>"  # 您在 app.activeloop.ai 上的用户名
source = f"hub://{username}/langchain_testing"  # 可以是本地、s3、gcs 等。
destination = f"hub://{username}/langchain_test_copy"  # 可以是本地、s3、gcs 等。


deeplake.copy(src=source, dst=destination)
```

```python
db = DeeplakeVectorStore(dataset_path=destination, embedding_function=embeddings)
db.add_documents(docs)
```
