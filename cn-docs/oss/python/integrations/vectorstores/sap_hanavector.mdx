---
title: SAP HANA Cloud 向量引擎
---
>[SAP HANA Cloud Vector Engine](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/sap-hana-cloud-sap-hana-database-vector-engine-guide) 是一个完全集成到 `SAP HANA Cloud` 数据库中的向量存储。

## 设置

安装 `langchain-hana` 外部集成包，以及本笔记本中使用的其他包。

```python
pip install -qU langchain-hana
```

### 凭证

确保您的 SAP HANA 实例正在运行。从环境变量加载您的凭证并创建连接：

```python
import os

from dotenv import load_dotenv
from hdbcli import dbapi

load_dotenv()
# 使用环境变量中的连接设置
connection = dbapi.connect(
    address=os.environ.get("HANA_DB_ADDRESS"),
    port=os.environ.get("HANA_DB_PORT"),
    user=os.environ.get("HANA_DB_USER"),
    password=os.environ.get("HANA_DB_PASSWORD"),
    autocommit=True,
    sslValidateCertificate=False,
)
```

在 [什么是 SAP HANA？](https://www.sap.com/products/data-cloud/hana/what-is-sap-hana.html) 中了解更多关于 SAP HANA 的信息。

### 初始化

要初始化一个 `HanaDB` 向量存储，您需要一个数据库连接和一个嵌入实例。SAP HANA Cloud Vector Engine 支持外部和内部嵌入。

- #### 使用外部嵌入

<EmbeddingTabs/>

```python
# | output: false
# | echo: false
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
```

- #### 使用内部嵌入

或者，您可以使用 SAP HANA 原生的 `VECTOR_EMBEDDING()` 函数直接在 SAP HANA 中计算嵌入。要启用此功能，请使用您的内部模型 ID 创建一个 `HanaInternalEmbeddings` 实例，并将其传递给 `HanaDB`。请注意，`HanaInternalEmbeddings` 实例专门设计用于与 `HanaDB` 一起使用，不适用于其他向量存储实现。有关内部嵌入的更多信息，请参阅 [SAP HANA VECTOR_EMBEDDING 函数](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/vector-embedding-function-vector)。

> **注意：** 确保您的 SAP HANA Cloud 实例中已启用 NLP。

```python
from langchain_hana import HanaInternalEmbeddings

embeddings = HanaInternalEmbeddings(internal_embedding_model_id="SAP_NEB.20240715")
```

一旦您有了连接和嵌入实例，通过将它们与用于存储向量的表名一起传递给 `HanaDB` 来创建向量存储：

```python
from langchain_hana import HanaDB

db = HanaDB(
    embedding=embeddings, connection=connection, table_name="STATE_OF_THE_UNION"
)
```

## 示例

加载示例文档 "state_of_the_union.txt" 并从中创建分块。

```python
from langchain_community.document_loaders import TextLoader
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter

text_documents = TextLoader(
    "../../how_to/state_of_the_union.txt", encoding="UTF-8"
).load()
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
text_chunks = text_splitter.split_documents(text_documents)
print(f"Number of document chunks: {len(text_chunks)}")
```

```text
Number of document chunks: 88
```

将加载的文档分块添加到表中。对于此示例，我们删除表中可能存在的来自先前运行的任何先前内容。

```python
# 从表中删除已存在的文档
db.delete(filter={})

# 添加加载的文档分块
db.add_documents(text_chunks)
```

```text
[]
```

执行查询以从上一步添加的文档分块中获取两个最佳匹配的文档分块。
默认情况下，搜索使用 "余弦相似度"。

```python
query = "What did the president say about Ketanji Brown Jackson"
docs = db.similarity_search(query, k=2)

for doc in docs:
    print("-" * 80)
    print(doc.page_content)
```

```text
--------------------------------------------------------------------------------
One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.
--------------------------------------------------------------------------------
As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential.

While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.
```

使用 "欧几里得距离" 查询相同内容。结果应与 "余弦相似度" 相同。

```python
from langchain_hana.utils import DistanceStrategy

db = HanaDB(
    embedding=embeddings,
    connection=connection,
    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,
    table_name="STATE_OF_THE_UNION",
)

query = "What did the president say about Ketanji Brown Jackson"
docs = db.similarity_search(query, k=2)
for doc in docs:
    print("-" * 80)
    print(doc.page_content)
```

```text
--------------------------------------------------------------------------------
One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.
--------------------------------------------------------------------------------
As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential.

While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.
```

## 最大边际相关性搜索 (MMR)

`最大边际相关性` 优化了与查询的相似性以及所选文档之间的多样性。前 20 个 (fetch_k) 项目将从数据库中检索。然后 MMR 算法将找到最佳的 2 个 (k) 匹配项。

```python
docs = db.max_marginal_relevance_search(query, k=2, fetch_k=20)
for doc in docs:
    print("-" * 80)
    print(doc.page_content)
```

```text
--------------------------------------------------------------------------------
One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.
--------------------------------------------------------------------------------
Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.

In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight.

Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.
```

## 创建 HNSW 向量索引

向量索引可以显著加快向量的 top-k 最近邻查询。用户可以使用 `create_hnsw_index` 函数创建分层可导航小世界 (HNSW) 向量索引。

有关在数据库级别创建索引的更多信息，请参阅 [官方文档](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/create-vector-index-statement-data-definition)。

```python
# HanaDB 实例默认使用余弦相似度：
db_cosine = HanaDB(
    embedding=embeddings, connection=connection, table_name="STATE_OF_THE_UNION"
)

# 尝试使用默认参数创建 HNSW 索引
db_cosine.create_hnsw_index()  # 如果未指定其他参数，将使用默认值
# 默认值：m=64, ef_construction=128, ef_search=200
# 默认索引名称将为：STATE_OF_THE_UNION_COSINE_SIMILARITY_IDX (在 HanaDB 类中验证此命名模式)


# 创建一个使用 L2 距离作为相似度函数并定义了值的 HanaDB 实例
db_l2 = HanaDB(
    embedding=embeddings,
    connection=connection,
    table_name="STATE_OF_THE_UNION",
    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,  # 指定 L2 距离
)

# 这将基于 L2 距离策略创建一个索引。
db_l2.create_hnsw_index(
    index_name="STATE_OF_THE_UNION_L2_index",
    m=100,  # 每个图节点的最大邻居数 (有效范围：4 到 1000)
    ef_construction=200,  # 图构建期间的最大候选数 (有效范围：1 到 100000)
    ef_search=500,  # 搜索期间的最小候选数 (有效范围：1 到 100000)
)

# 使用 L2 索引执行 MMR
docs = db_l2.max_marginal_relevance_search(query, k=2, fetch_k=20)
for doc in docs:
    print("-" * 80)
    print(doc.page_content)
```

```text
--------------------------------------------------------------------------------
One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.
--------------------------------------------------------------------------------
Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.

In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight.

Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.
```

**关键点**：

- **相似度函数**：索引的相似度函数默认为 **余弦相似度**。如果您想使用不同的相似度函数（例如，`L2` 距离），需要在初始化 `HanaDB` 实例时指定。
- **默认参数**：在 `create_hnsw_index` 函数中，如果用户没有为 `m`、`ef_construction` 或 `ef_search` 等参数提供自定义值，将自动使用默认值（例如，`m=64`、`ef_construction=128`、`ef_search=200`）。这些值确保索引以合理的性能创建，无需用户干预。

## 基本向量存储操作

```python
db = HanaDB(
    connection=connection, embedding=embeddings, table_name="LANGCHAIN_DEMO_BASIC"
)

# 从表中删除已存在的文档
db.delete(filter={})
```

```text
True
```

我们可以将简单的文本文档添加到现有表中。

```python
docs = [Document(page_content="Some text"), Document(page_content="Other docs")]
db.add_documents(docs)
```

```text
[]
```

添加带有元数据的文档。

```python
docs = [
    Document(
        page_content="foo",
        metadata={"start": 100, "end": 150, "doc_name": "foo.txt", "quality": "bad"},
    ),
    Document(
        page_content="bar",
        metadata={"start": 200, "end": 250, "doc_name": "bar.txt", "quality": "good"},
    ),
]
db.add_documents(docs)
```

```text
[]
```

查询具有特定元数据的文档。

```python
docs = db.similarity_search("foobar", k=2, filter={"quality": "bad"})
# 在 "quality"=="bad" 上进行过滤后，应只返回一个文档
for doc in docs:
    print("-" * 80)
    print(doc.page_content)
    print(doc.metadata)
```

```python
--------------------------------------------------------------------------------
foo
{'start': 100, 'end': 150, 'doc_name': 'foo.txt', 'quality': 'bad'}
```

删除具有特定元数据的文档。

```python
db.delete(filter={"quality": "bad"})

# 现在使用相同过滤器的相似度搜索将不返回任何结果
docs = db.similarity_search("foobar", k=2, filter={"quality": "bad"})
print(len(docs))
```

```text
0
```

## 高级过滤

除了基本的基于值的过滤功能外，还可以使用更高级的过滤。
下表显示了可用的过滤运算符。

| 运算符     | 语义                     |
|----------|-------------------------|
| `$eq`    | 相等 (==)               |
| `$ne`    | 不相等 (!=)             |
| `$lt`    | 小于 (&lt;)               |
| `$lte`   | 小于或等于 (&lt;=)         |
| `$gt`    | 大于 (>)                |
| `$gte`   | 大于或等于 (>=)          |
| `$in`    | 包含在给定值集合中 (in)    |
| `$nin`   | 不包含在给定值集合中 (not in) |
| `$between` | 在两个边界值范围内         |
| `$like`  | 基于 SQL 中 "LIKE" 语义的文本相等性 (使用 "%" 作为通配符) |
| `$contains` | 过滤包含特定关键字的文档     |
| `$and`   | 逻辑 "与"，支持两个或更多操作数 |
| `$or`    | 逻辑 "或"，支持两个或更多操作数 |

```python
# 准备一些测试文档
docs = [
    Document(
        page_content="First",
        metadata={"name": "Adam Smith", "is_active": True, "id": 1, "height": 10.0},
    ),
    Document(
        page_content="Second",
        metadata={"name": "Bob Johnson", "is_active": False, "id": 2, "height": 5.7},
    ),
    Document(
        page_content="Third",
        metadata={"name": "Jane Doe", "is_active": True, "id": 3, "height": 2.4},
    ),
]

db = HanaDB(
    connection=connection,
    embedding=embeddings,
    table_name="LANGCHAIN_DEMO_ADVANCED_FILTER",
)

# 从表中删除已存在的文档
db.delete(filter={})
db.add_documents(docs)


# 用于打印过滤结果的辅助函数
def print_filter_result(result):
    if len(result) == 0:
        print("<empty result>")
    for doc in result:
        print(doc.metadata)
```

使用 `$ne`、`$gt`、`$gte`、`$lt`、`$lte` 进行过滤

```python
advanced_filter = {"id": {"$ne": 1}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"id": {"$gt": 1}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"id": {"$gte": 1}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"id": {"$lt": 1}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"id": {"$lte": 1}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))
```

```python
Filter: {'id': {'$ne': 1}}
{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}
{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}
Filter: {'id': {'$gt': 1}}
{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}
{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}
Filter: {'id': {'$gte': 1}}
{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}
{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}
{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}
Filter: {'id': {'$lt': 1}}
<empty result>
Filter: {'id': {'$lte': 1}}
{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}
```

使用 `$between`、`$in`、`$nin` 进行过滤

```python
advanced_filter = {"id": {"$between": (1, 2)}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"name": {"$in": ["Adam Smith", "Bob Johnson"]}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))

advanced_filter = {"name": {"$nin": ["Adam Smith", "Bob Johnson"]}}
print(f"Filter: {advanced_filter}")
print_filter_result(db.similarity_search("just testing", k=5, filter=advanced_filter))
```

```python
Filter: {'id': {'$between': (
