---
title: 防止在跟踪记录中记录敏感数据
sidebarTitle: Prevent logging of sensitive data in traces
---
在使用 LangSmith 跟踪时，您可能需要防止敏感信息被记录，以维护隐私并满足安全要求。LangSmith 提供了多种方法，可在数据发送到后端之前对其进行保护：

- 使用环境变量或 @[Client] 配置[完全隐藏输入和输出](#hide-inputs-and-outputs)。
- [隐藏元数据](#hide-metadata)以移除或转换运行元数据。
- 使用正则表达式模式或匿名化库[对输入和输出进行基于规则的掩码处理](#rule-based-masking-of-inputs-and-outputs)，以选择性地编辑敏感信息。
- 通过函数级自定义[处理单个函数的输入和输出](#processing-inputs-&-outputs-for-a-single-function)。
- 使用 Microsoft Presidio 和 Amazon Comprehend 等[第三方匿名化工具](#examples)进行高级 PII 检测。

## 隐藏输入和输出

如果您想完全隐藏跟踪的输入和输出，可以在运行应用程序时设置以下环境变量：

```bash
LANGSMITH_HIDE_INPUTS=true
LANGSMITH_HIDE_OUTPUTS=true
```

这适用于 LangSmith SDK（Python 和 TypeScript）以及 LangChain。

您还可以为给定的 @[Client] 实例自定义和覆盖此行为。这可以通过在 @[Client] 对象上设置 `hide_inputs` 和 `hide_outputs` 参数来实现（在 TypeScript 中为 `hideInputs` 和 `hideOutputs`）。

以下示例为 `hide_inputs` 和 `hide_outputs` 返回一个空对象，但您可以根据需要进行自定义：

<CodeGroup>

```python Python
import openai
from langsmith import Client
from langsmith.wrappers import wrap_openai

openai_client = wrap_openai(openai.Client())
langsmith_client = Client(
    hide_inputs=lambda inputs: {}, hide_outputs=lambda outputs: {}
)

# 生成的跟踪将包含其元数据，但输入将被隐藏
openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"},
    ],
    langsmith_extra={"client": langsmith_client},
)

# 生成的跟踪将不会隐藏输入和输出
openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"},
    ],
)
```

```typescript TypeScript
import OpenAI from "openai";
import { Client } from "langsmith";
import { wrapOpenAI } from "langsmith/wrappers";

const langsmithClient = new Client({
    hideInputs: (inputs) => ({}),
    hideOutputs: (outputs) => ({}),
});

// 生成的跟踪将包含其元数据，但输入将被隐藏
const filteredOAIClient = wrapOpenAI(new OpenAI(), {
    client: langsmithClient,
});
await filteredOAIClient.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: "Hello!" },
    ],
});

const openaiClient = wrapOpenAI(new OpenAI());
// 生成的跟踪将不会隐藏输入和输出
await openaiClient.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: "Hello!" },
    ],
});
```

</CodeGroup>

## 隐藏元数据

`hide_metadata` 参数允许您在使用 LangSmith Python SDK 进行跟踪时控制是否隐藏或转换运行元数据。元数据在创建运行时通过 `extra` 参数传递（例如，`extra={"metadata": {...}}`）。`hide_metadata` 对于移除敏感信息、满足隐私要求或减少发送到 LangSmith 的数据量非常有用。您可以通过两种方式配置元数据隐藏：

- 使用 SDK：

    ```python
    from langsmith import Client

    client = Client(hide_metadata=True)
    ```

- 使用环境变量：

    ```bash
    export LANGSMITH_HIDE_METADATA=true
    ```

`hide_metadata` 参数接受三种类型的值：

- `True`：完全移除所有元数据（发送空字典）。
- `False` 或 `None`：按原样保留元数据（默认行为）。
- `Callable`：一个自定义函数，用于转换元数据字典。

设置此参数后，它将影响由 @[Client] 创建或更新的所有运行（包括通过 `@traceable` 装饰器或 LangChain 集成创建的运行）的 `extra` 参数中的 `metadata` 字段。

### 隐藏所有元数据

设置 `hide_metadata=True` 以完全移除发送到 LangSmith 的运行中的所有元数据：

```python
from langsmith import Client

# 完全隐藏所有元数据
client = Client(hide_metadata=True)

# 现在当你创建运行时，元数据将为空
client.create_run(
    "my_run",
    inputs={"question": "What is 2+2?"},
    run_type="llm",
    extra={"metadata": {"user_id": "123", "session": "abc"}}
)
# 发送到 LangSmith 的元数据将是 {}，而不是提供的元数据
```

### 自定义转换

使用可调用函数在元数据发送到 LangSmith 之前，有选择地过滤、编辑或修改元数据：

```python
# 移除敏感键
def hide_sensitive_metadata(metadata: dict) -> dict:
    return {k: v for k, v in metadata.items() if not k.startswith("_private")}

client = Client(hide_metadata=hide_sensitive_metadata)

# 编辑特定值
def redact_emails(metadata: dict) -> dict:
    import re
    result = {}
    for k, v in metadata.items():
        if isinstance(v, str) and "@" in v:
            result[k] = "[REDACTED_EMAIL]"
        else:
            result[k] = v
    return result

client = Client(hide_metadata=redact_emails)

# 添加转换标记
def add_marker(metadata: dict) -> dict:
    return {**metadata, "transformed": True}

client = Client(hide_metadata=add_marker)
```

## 基于规则的输入和输出掩码

<Info>
此功能在以下 LangSmith SDK 版本中可用：

* Python: 0.1.81 及以上
* TypeScript: 0.1.33 及以上
</Info>

要对输入和输出中的特定数据进行掩码处理，您可以使用 `create_anonymizer` / `createAnonymizer` 函数，并在实例化 @[Client] 时传递新创建的匿名器。匿名器可以通过正则表达式模式列表和替换值构建，也可以通过接受并返回字符串值的函数构建。

如果 `LANGSMITH_HIDE_INPUTS = true`，则匿名器将跳过输入处理。对于输出，如果 `LANGSMITH_HIDE_OUTPUTS = true`，同样适用。

但是，如果输入或输出要发送到 @[Client]，`anonymizer` 方法将优先于 `hide_inputs` 和 `hide_outputs` 中找到的函数。默认情况下，`create_anonymizer` 最多只查看 10 层嵌套深度，这可以通过 `max_depth` 参数进行配置。

<CodeGroup>

```python Python
from langsmith.anonymizer import create_anonymizer
from langsmith import Client, traceable
import re

# 从正则表达式模式列表和替换值创建匿名器
anonymizer = create_anonymizer([
    { "pattern": r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}", "replace": "<email-address>" },
    { "pattern": r"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}", "replace": "<UUID>" }
])

# 或者从函数创建匿名器
email_pattern = re.compile(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}")
uuid_pattern = re.compile(r"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}")
anonymizer = create_anonymizer(
    lambda text: email_pattern.sub("<email-address>", uuid_pattern.sub("<UUID>", text))
)

client = Client(anonymizer=anonymizer)

@traceable(client=client)
def main(inputs: dict) -> dict:
    ...
```

```typescript TypeScript
import { createAnonymizer } from "langsmith/anonymizer"
import { traceable } from "langsmith/traceable"
import { Client } from "langsmith"

// 根据正则表达式模式和替换值列表创建匿名化器
const anonymizer = createAnonymizer([
    { pattern: /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}/g, replace: "<email>" },
    { pattern: /[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}/g, replace: "<uuid>" }
])

// 或者通过函数创建匿名化器
const anonymizer = createAnonymizer((value) => value.replace("...", "<value>"))

const client = new Client({ anonymizer })

const main = traceable(async (inputs: any) => {
    // ...
}, { client })
```

</CodeGroup>

请注意，使用匿名化器可能会因复杂的正则表达式或大型负载而导致性能下降，因为匿名化器在处理前会将负载序列化为 JSON。

<Note>
改进 `anonymizer` API 的性能已在我们的路线图中！如果您遇到性能问题，请通过 [support.langchain.com](https://support.langchain.com) 联系支持团队。
</Note>

![隐藏输入输出](/langsmith/images/hide-inputs-outputs.png)

旧版本的 LangSmith SDK 可以使用 `hide_inputs` 和 `hide_outputs` 参数来实现相同的效果。您也可以使用这些参数来更高效地处理输入和输出。

<CodeGroup>

```python Python
import re
from langsmith import Client, traceable

# 定义电子邮件地址和 UUID 的正则表达式模式
EMAIL_REGEX = r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}"
UUID_REGEX = r"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}"

def replace_sensitive_data(data, depth=10):
    if depth == 0:
        return data
    if isinstance(data, dict):
        return {k: replace_sensitive_data(v, depth-1) for k, v in data.items()}
    elif isinstance(data, list):
        return [replace_sensitive_data(item, depth-1) for item in data]
    elif isinstance(data, str):
        data = re.sub(EMAIL_REGEX, "<email-address>", data)
        data = re.sub(UUID_REGEX, "<UUID>", data)
        return data
    else:
        return data

client = Client(
    hide_inputs=lambda inputs: replace_sensitive_data(inputs),
    hide_outputs=lambda outputs: replace_sensitive_data(outputs)
)

inputs = {"role": "user", "content": "Hello! My email is user@example.com and my ID is 123e4567-e89b-12d3-a456-426614174000."}
outputs = {"role": "assistant", "content": "Hi! I've noted your email as user@example.com and your ID as 123e4567-e89b-12d3-a456-426614174000."}

@traceable(client=client)
def child(inputs: dict) -> dict:
    return outputs

@traceable(client=client)
def parent(inputs: dict) -> dict:
    child_outputs = child(inputs)
    return child_outputs

parent(inputs)
```

```typescript TypeScript
import { Client } from "langsmith";
import { traceable } from "langsmith/traceable";

// 定义电子邮件地址和 UUID 的正则表达式模式
const EMAIL_REGEX = /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}/g;
const UUID_REGEX = /[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}/g;

function replaceSensitiveData(data: any, depth: number = 10): any {
    if (depth === 0) return data;
    if (typeof data === "object" && !Array.isArray(data)) {
        const result: Record<string, any> = {};
        for (const [key, value] of Object.entries(data)) {
            result[key] = replaceSensitiveData(value, depth - 1);
        }
        return result;
    } else if (Array.isArray(data)) {
        return data.map(item => replaceSensitiveData(item, depth - 1));
    } else if (typeof data === "string") {
        return data.replace(EMAIL_REGEX, "<email-address>").replace(UUID_REGEX, "<UUID>");
    } else {
        return data;
    }
}

const langsmithClient = new Client({
    hideInputs: (inputs) => replaceSensitiveData(inputs),
    hideOutputs: (outputs) => replaceSensitiveData(outputs)
});

```javascript
const inputs = {
    role: "user",
    content: "Hello! My email is user@example.com and my ID is 123e4567-e89b-12d3-a456-426614174000."
};
const outputs = {
    role: "assistant",
    content: "Hi! I've noted your email as <email-address> and your ID as <UUID>."
};

const child = traceable(async (inputs: any) => {
    return outputs;
}, { name: "child", client: langsmithClient });

const parent = traceable(async (inputs: any) => {
    const childOutputs = await child(inputs);
    return childOutputs;
}, { name: "parent", client: langsmithClient });

await parent(inputs);
```

</CodeGroup>

## 处理单个函数的输入和输出

<Info>
Python 的 LangSmith SDK 版本 0.1.98 及以上提供了 `process_outputs` 参数。
</Info>

除了 @[Client] 级别的输入和输出处理，LangSmith 还通过 `@traceable` 装饰器的 `process_inputs` 和 `process_outputs` 参数提供了函数级别的处理。

这些参数接受函数，允许你在特定函数的输入和输出被记录到 LangSmith 之前对其进行转换。这对于减少负载大小、移除敏感信息，或者为特定函数自定义对象在 LangSmith 中应如何序列化和表示非常有用。

以下是如何使用 `process_inputs` 和 `process_outputs` 的示例：

```python
from langsmith import traceable

def process_inputs(inputs: dict) -> dict:
    # inputs 是一个字典，其中键是参数名，值是提供的参数
    # 返回一个包含处理后输入的新字典
    return {
        "processed_key": inputs.get("my_cool_key", "default"),
        "length": len(inputs.get("my_cool_key", ""))
    }

def process_outputs(output: Any) -> dict:
    # output 是函数的直接返回值
    # 将输出转换为字典
    # 在这个例子中，"output" 将是一个整数
    return {"processed_output": str(output)}

@traceable(process_inputs=process_inputs, process_outputs=process_outputs)
def my_function(my_cool_key: str) -> int:
    # 函数实现
    return len(my_cool_key)

result = my_function("example")
```

在这个例子中，`process_inputs` 创建了一个包含处理后输入数据的新字典，而 `process_outputs` 在记录到 LangSmith 之前将输出转换为特定格式。

<Warning>
建议避免在处理器函数中修改源对象。相反，应创建并返回包含处理后数据的新对象。
</Warning>

对于异步函数，用法类似：

```python
@traceable(process_inputs=process_inputs, process_outputs=process_outputs)
async def async_function(key: str) -> int:
    # 异步实现
    return len(key)
```

当同时定义了函数级别处理器和 @[Client] 级别处理器（`hide_inputs` 和 `hide_outputs`）时，函数级别处理器具有优先权。

## 示例

你可以将基于规则的掩码与各种匿名化工具结合使用，以清理输入和输出中的敏感信息。以下示例将涵盖使用正则表达式、Microsoft Presidio 和 Amazon Comprehend。

### 正则表达式

<Info>
下面的实现并不详尽，可能会遗漏某些格式或边缘情况。在生产环境中使用任何实现之前，请进行彻底测试。
</Info>

你可以使用正则表达式在输入和输出发送到 LangSmith 之前对其进行掩码。下面的实现掩码了电子邮件地址、电话号码、全名、信用卡号码和社会安全号码。

```python
import re
import openai
from langsmith import Client
from langsmith.wrappers import wrap_openai

# 为各种 PII 定义正则表达式模式
SSN_PATTERN = re.compile(r'\b\d{3}-\d{2}-\d{4}\b')
CREDIT_CARD_PATTERN = re.compile(r'\b(?:\d[ -]*?){13,16}\b')
EMAIL_PATTERN = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,7}\b')
PHONE_PATTERN = re.compile(r'\b(?:\+?1[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}\b')
FULL_NAME_PATTERN = re.compile(r'\b([A-Z][a-z]*\s[A-Z][a-z]*)\b')
```

def regex_anonymize(text):
    """
    使用正则表达式模式对文本中的敏感信息进行匿名化处理。
    Args:
        text (str): 待匿名化的输入文本。
    Returns:
        str: 匿名化后的文本。
    """
    # 使用占位符替换敏感信息
    text = SSN_PATTERN.sub('[REDACTED SSN]', text)
    text = CREDIT_CARD_PATTERN.sub('[REDACTED CREDIT CARD]', text)
    text = EMAIL_PATTERN.sub('[REDACTED EMAIL]', text)
    text = PHONE_PATTERN.sub('[REDACTED PHONE]', text)
    text = FULL_NAME_PATTERN.sub('[REDACTED NAME]', text)
    return text

def recursive_anonymize(data, depth=10):
    """
    递归遍历数据结构并对敏感信息进行匿名化处理。
    Args:
        data (any): 待匿名化的输入数据。
        depth (int): 当前递归深度，用于防止过度递归。
    Returns:
        any: 匿名化后的数据。
    """
    if depth == 0:
        return data
    if isinstance(data, dict):
        anonymized_dict = {}
        for k, v in data.items():
            anonymized_value = recursive_anonymize(v, depth - 1)
            anonymized_dict[k] = anonymized_value
        return anonymized_dict
    elif isinstance(data, list):
        anonymized_list = []
        for item in data:
            anonymized_item = recursive_anonymize(item, depth - 1)
            anonymized_list.append(anonymized_item)
        return anonymized_list
    elif isinstance(data, str):
        anonymized_data = regex_anonymize(data)
        return anonymized_data
    else:
        return data

openai_client = wrap_openai(openai.Client())

# 使用匿名化函数初始化 LangSmith @[Client]
langsmith_client = Client(
    hide_inputs=recursive_anonymize, hide_outputs=recursive_anonymize
)

# 生成的追踪记录将包含其元数据，但输入和输出将被匿名化
response_with_anonymization = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "My name is John Doe, my SSN is 123-45-6789, my credit card number is 4111 1111 1111 1111, my email is john.doe@example.com, and my phone number is (123) 456-7890."},
    ],
    langsmith_extra={"client": langsmith_client},
)

# 生成的追踪记录将不会对输入和输出进行匿名化
response_without_anonymization = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "My name is John Doe, my SSN is 123-45-6789, my credit card number is 4111 1111 1111 1111, my email is john.doe@example.com, and my phone number is (123) 456-7890."},
    ],
)
```

在 LangSmith 中，匿名化后的运行记录将如下所示：![Anonymized run](/langsmith/images/regex-anonymized.png)

在 LangSmith 中，未匿名化的运行记录将如下所示：![Non-anonymized run](/langsmith/images/regex-not-anonymized.png)

### Microsoft Presidio

<Info>
以下实现提供了一个通用示例，展示了如何对用户与 LLM 之间交换的消息中的敏感信息进行匿名化处理。它并非详尽无遗，也未涵盖所有情况。在生产环境中使用任何实现之前，请务必进行彻底测试。
</Info>

Microsoft Presidio 是一个数据保护和去标识化 SDK。以下实现使用 Presidio 在将输入和输出发送到 LangSmith 之前对其进行匿名化处理。有关最新信息，请参阅 Presidio 的[官方文档](https://microsoft.github.io/presidio/)。

要使用 Presidio 及其 spaCy 模型，请安装以下内容：

<CodeGroup>
```bash pip
pip install presidio-analyzer
pip install presidio-anonymizer
python -m spacy download en_core_web_lg
```

```bash uv
uv add presidio-analyzer
uv add presidio-anonymizer
python -m spacy download en_core_web_lg
```
</CodeGroup>

同时，安装 OpenAI：

<CodeGroup>
```bash pip
pip install openai
```

```bash uv
uv add openai
```
</CodeGroup>

```python
import openai
from langsmith import Client
from langsmith.wrappers import wrap_openai
from presidio_anonymizer import AnonymizerEngine
from presidio_analyzer import AnalyzerEngine

anonymizer = AnonymizerEngine()
analyzer = AnalyzerEngine()

def presidio_anonymize(data):
    """
    对用户发送或模型返回的敏感信息进行匿名化处理。
    参数:
        data (any): 待匿名化的数据。
    返回:
        any: 匿名化后的数据。
    """
    message_list = (
        data.get('messages') or [data.get('choices', [{}])[0].get('message')]
    )
    if not message_list or not all(isinstance(msg, dict) and msg for msg in message_list):
        return data

    for message in message_list:
        content = message.get('content', '')
        if not content.strip():
            print("检测到空内容。跳过匿名化。")
            continue

        results = analyzer.analyze(
            text=content,
            entities=["PERSON", "PHONE_NUMBER", "EMAIL_ADDRESS", "US_SSN"],
            language='en'
        )
        anonymized_result = anonymizer.anonymize(
            text=content,
            analyzer_results=results
        )
        message['content'] = anonymized_result.text

    return data

openai_client = wrap_openai(openai.Client())

# 使用匿名化函数初始化 langsmith @[Client]
langsmith_client = Client(
  hide_inputs=presidio_anonymize, hide_outputs=presidio_anonymize
)

# 生成的追踪记录将包含其元数据，但输入和输出将被匿名化
response_with_anonymization = openai_client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"},
  ],
  langsmith_extra={"client": langsmith_client},
)

# 生成的追踪记录将不会对输入和输出进行匿名化
response_without_anonymization = openai_client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"},
  ],
)
```

在 LangSmith 中，匿名化后的运行记录将如下所示：![匿名化运行记录](/langsmith/images/presidio-anonymized.png)

在 LangSmith 中，未匿名化的运行记录将如下所示：![未匿名化运行记录](/langsmith/images/presidio-not-anonymized.png)

### Amazon Comprehend

<Info>
下面的实现提供了一个通用示例，展示了如何对用户与 LLM 之间交换的消息中的敏感信息进行匿名化处理。它并不详尽，也没有涵盖所有情况。在生产环境中使用任何实现之前，请务必进行彻底测试。
</Info>

Comprehend 是一项自然语言处理服务，可以检测个人身份信息。下面的实现使用 Comprehend 在将输入和输出发送到 LangSmith 之前对其进行匿名化处理。有关最新信息，请参阅 Comprehend 的[官方文档](https://docs.aws.amazon.com/comprehend/latest/APIReference/API_DetectPiiEntities.html)。

要使用 Comprehend，请安装 [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html)：

<CodeGroup>
```bash pip
pip install boto3
```

```bash uv
uv add boto3
```
</CodeGroup>

同时，安装 OpenAI：

<CodeGroup>
```bash pip
pip install openai
```

```bash uv
uv add openai
```
</CodeGroup>

您需要在 AWS 中设置凭证并使用 AWS CLI 进行身份验证。请按照[此处](https://docs.aws.amazon.com/comprehend/latest/dg/setting-up.html)的说明操作。

```python
import openai
import boto3
from langsmith import Client
from langsmith.wrappers import wrap_openai

comprehend = boto3.client('comprehend', region_name='us-east-1')

def redact_pii_entities(text, entities):
    """
    根据检测到的实体，对文本中的PII实体进行脱敏处理。
    参数:
        text (str): 包含PII的原始文本。
        entities (list): 检测到的PII实体列表。
    返回:
        str: 经过PII实体脱敏处理的文本。
    """
    sorted_entities = sorted(entities, key=lambda x: x['BeginOffset'], reverse=True)
    redacted_text = text
    for entity in sorted_entities:
        begin = entity['BeginOffset']
        end = entity['EndOffset']
        entity_type = entity['Type']
        # 根据实体类型定义脱敏占位符
        placeholder = f"[{entity_type}]"
        # 用占位符替换文本中的PII
        redacted_text = redacted_text[:begin] + placeholder + redacted_text[end:]
    return redacted_text

def detect_pii(text):
    """
    使用AWS Comprehend检测给定文本中的PII实体。
    参数:
        text (str): 要分析的文本。
    返回:
        list: 检测到的PII实体列表。
    """
    try:
        response = comprehend.detect_pii_entities(
            Text=text,
            LanguageCode='en',
        )
        entities = response.get('Entities', [])
        return entities
    except Exception as e:
        print(f"检测PII时出错: {e}")
        return []

def comprehend_anonymize(data):
    """
    对用户发送或模型返回的敏感信息进行匿名化处理。
    参数:
        data (any): 要匿名化的输入数据。
    返回:
        any: 匿名化后的数据。
    """
    message_list = (
        data.get('messages') or [data.get('choices', [{}])[0].get('message')]
    )
    if not message_list or not all(isinstance(msg, dict) and msg for msg in message_list):
        return data

    for message in message_list:
        content = message.get('content', '')
        if not content.strip():
            print("检测到空内容。跳过匿名化。")
            continue

        entities = detect_pii(content)
        if entities:
            anonymized_text = redact_pii_entities(content, entities)
            message['content'] = anonymized_text
        else:
            print("未检测到PII。内容保持不变。")

    return data

openai_client = wrap_openai(openai.Client())

# 使用匿名化函数初始化langsmith @[Client]
langsmith_client = Client(
  hide_inputs=comprehend_anonymize, hide_outputs=comprehend_anonymize
)

# 生成的追踪记录将包含其元数据，但输入和输出将被匿名化
response_with_anonymization = openai_client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"},
  ],
  langsmith_extra={"client": langsmith_client},
)

# 生成的追踪记录将不会对输入和输出进行匿名化
response_without_anonymization = openai_client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "My name is Slim Shady, call me at 313-666-7440 or email me at real.slim.shady@gmail.com"},
  ],
)
```

在LangSmith中，匿名化后的运行记录将如下所示：![Anonymized run](/langsmith/images/aws-comprehend-anonymized.png)

在LangSmith中，未匿名化的运行记录将如下所示：![Non-anonymized run](/langsmith/images/aws-comprehend-not-anonymized.png)
