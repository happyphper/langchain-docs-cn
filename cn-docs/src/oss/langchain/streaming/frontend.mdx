---
title: å‰ç«¯
description: åˆ©ç”¨ LangChain æ™ºèƒ½ä½“ï¼ˆagentï¼‰ã€LangGraph å›¾ï¼ˆgraphï¼‰å’Œè‡ªå®šä¹‰ API çš„å®æ—¶æµå¼ä¼ è¾“ï¼Œæ„å»ºç”Ÿæˆå¼ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰ã€‚
---
`useStream` React é’©å­æä¾›äº†ä¸ LangGraph æµå¼å¤„ç†èƒ½åŠ›çš„æ— ç¼é›†æˆã€‚å®ƒå¤„ç†äº†æµå¼å¤„ç†ã€çŠ¶æ€ç®¡ç†å’Œåˆ†æ”¯é€»è¾‘çš„æ‰€æœ‰å¤æ‚æ€§ï¼Œè®©ä½ å¯ä»¥ä¸“æ³¨äºæ„å»ºå‡ºè‰²çš„ç”Ÿæˆå¼ UI ä½“éªŒã€‚

ä¸»è¦ç‰¹æ€§ï¼š

* <Icon icon="messages" size={16} /> **æ¶ˆæ¯æµå¼å¤„ç†** â€” å¤„ç†æ¶ˆæ¯å—æµä»¥å½¢æˆå®Œæ•´çš„æ¶ˆæ¯
* <Icon icon="arrows-rotate" size={16} /> **è‡ªåŠ¨çŠ¶æ€ç®¡ç†** â€” ç”¨äºæ¶ˆæ¯ã€ä¸­æ–­ã€åŠ è½½çŠ¶æ€å’Œé”™è¯¯
* <Icon icon="code-branch" size={16} /> **å¯¹è¯åˆ†æ”¯** â€” ä»èŠå¤©å†å²ä¸­çš„ä»»æ„ç‚¹åˆ›å»ºæ›¿ä»£å¯¹è¯è·¯å¾„
* <Icon icon="palette" size={16} /> **UI æ— å…³è®¾è®¡** â€” ä½¿ç”¨ä½ è‡ªå·±çš„ç»„ä»¶å’Œæ ·å¼

## å®‰è£…

å®‰è£… LangGraph SDK ä»¥åœ¨ä½ çš„ React åº”ç”¨ä¸­ä½¿ç”¨ `useStream` é’©å­ï¼š

:::js
```bash
npm install @langchain/langgraph-sdk
```
:::

## åŸºæœ¬ç”¨æ³•

`useStream` é’©å­å¯ä»¥è¿æ¥åˆ°ä»»ä½• LangGraph å›¾ï¼Œæ— è®ºæ˜¯ä»ä½ è‡ªå·±çš„ç«¯ç‚¹è¿è¡Œï¼Œè¿˜æ˜¯ä½¿ç”¨ [LangSmith éƒ¨ç½²](/langsmith/deployments) éƒ¨ç½²çš„ã€‚

```tsx
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const stream = useStream({
    assistantId: "agent",
    // æœ¬åœ°å¼€å‘
    apiUrl: "http://localhost:2024",
    // ç”Ÿäº§éƒ¨ç½²ï¼ˆLangSmith æ‰˜ç®¡ï¼‰
    // apiUrl: "https://your-deployment.us.langgraph.app"
  });

  const handleSubmit = (message: string) => {
    stream.submit({
      messages: [
        { content: message, type: "human" }
      ],
    });
  };

  return (
    <div>
      {stream.messages.map((message, idx) => (
        <div key={message.id ?? idx}>
          {message.type}: {message.content}
        </div>
      ))}

      {stream.isLoading && <div>Loading...</div>}
      {stream.error && <div>Error: {stream.error.message}</div>}
    </div>
  );
}
```

<Tip>
äº†è§£å¦‚ä½• [å°†ä½ çš„æ™ºèƒ½ä½“éƒ¨ç½²åˆ° LangSmith](/oss/langchain/deploy)ï¼Œä»¥è·å¾—å…·å¤‡å†…ç½®å¯è§‚æµ‹æ€§ã€èº«ä»½éªŒè¯å’Œæ‰©å±•èƒ½åŠ›çš„ç”Ÿäº§å°±ç»ªæ‰˜ç®¡æœåŠ¡ã€‚
</Tip>

<Accordion title="`useStream` å‚æ•°">

<ParamField body="assistantId" type="string" required>
    è¦è¿æ¥çš„æ™ºèƒ½ä½“ IDã€‚ä½¿ç”¨ LangSmith éƒ¨ç½²æ—¶ï¼Œæ­¤ ID å¿…é¡»ä¸éƒ¨ç½²ä»ªè¡¨æ¿ä¸­æ˜¾ç¤ºçš„æ™ºèƒ½ä½“ ID åŒ¹é…ã€‚å¯¹äºè‡ªå®šä¹‰ API éƒ¨ç½²æˆ–æœ¬åœ°å¼€å‘ï¼Œè¿™å¯ä»¥æ˜¯ä½ çš„æœåŠ¡å™¨ç”¨äºæ ‡è¯†æ™ºèƒ½ä½“çš„ä»»ä½•å­—ç¬¦ä¸²ã€‚
</ParamField>

<ParamField body="apiUrl" type="string">
    LangGraph æœåŠ¡å™¨çš„ URLã€‚æœ¬åœ°å¼€å‘æ—¶é»˜è®¤ä¸º `http://localhost:2024`ã€‚
</ParamField>

<ParamField body="apiKey" type="string">
    ç”¨äºèº«ä»½éªŒè¯çš„ API å¯†é’¥ã€‚è¿æ¥åˆ° LangSmith ä¸Šå·²éƒ¨ç½²çš„æ™ºèƒ½ä½“æ—¶éœ€è¦ã€‚
</ParamField>

<ParamField body="threadId" type="string">
    è¿æ¥åˆ°ç°æœ‰çº¿ç¨‹è€Œä¸æ˜¯åˆ›å»ºæ–°çº¿ç¨‹ã€‚å¯¹äºæ¢å¤å¯¹è¯å¾ˆæœ‰ç”¨ã€‚
</ParamField>

<ParamField body="onThreadId" type="(id: string) => void">
    åˆ›å»ºæ–°çº¿ç¨‹æ—¶è°ƒç”¨çš„å›è°ƒå‡½æ•°ã€‚ä½¿ç”¨æ­¤å‡½æ•°æ¥æŒä¹…åŒ–çº¿ç¨‹ ID ä»¥ä¾›åç»­ä½¿ç”¨ã€‚
</ParamField>

<ParamField body="reconnectOnMount" type="boolean | (() => Storage)">
    åœ¨ç»„ä»¶æŒ‚è½½æ—¶è‡ªåŠ¨æ¢å¤æ­£åœ¨è¿›è¡Œçš„è¿è¡Œã€‚è®¾ç½®ä¸º `true` ä»¥ä½¿ç”¨ä¼šè¯å­˜å‚¨ï¼Œæˆ–æä¾›è‡ªå®šä¹‰å­˜å‚¨å‡½æ•°ã€‚
</ParamField>

<ParamField body="onCreated" type="(run: Run) => void">
    åˆ›å»ºæ–°è¿è¡Œæ—¶è°ƒç”¨çš„å›è°ƒå‡½æ•°ã€‚å¯¹äºæŒä¹…åŒ–è¿è¡Œå…ƒæ•°æ®ä»¥ä¾¿æ¢å¤å¾ˆæœ‰ç”¨ã€‚
</ParamField>

<ParamField body="onError" type="(error: Error) => void">
    æµå¼å¤„ç†æœŸé—´å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨çš„å›è°ƒå‡½æ•°ã€‚
</ParamField>

<ParamField body="onFinish" type="(state: StateType, run?: Run) => void">
    æµæˆåŠŸå®Œæˆå¹¶è¿”å›æœ€ç»ˆçŠ¶æ€æ—¶è°ƒç”¨çš„å›è°ƒå‡½æ•°ã€‚
</ParamField>

<ParamField body="onCustomEvent" type="(data: unknown, context: { mutate }) => void">
    ä½¿ç”¨ `writer` å¤„ç†ä»ä½ çš„æ™ºèƒ½ä½“å‘å‡ºçš„è‡ªå®šä¹‰äº‹ä»¶ã€‚è¯·å‚é˜… [è‡ªå®šä¹‰æµå¼å¤„ç†äº‹ä»¶](#custom-streaming-events)ã€‚
</ParamField>

<ParamField body="onUpdateEvent" type="(data: unknown, context: { mutate }) => void">
    å¤„ç†æ¯ä¸ªå›¾æ­¥éª¤åçš„çŠ¶æ€æ›´æ–°äº‹ä»¶ã€‚
</ParamField>

<ParamField body="onMetadataEvent" type="(metadata: { run_id, thread_id }) => void">
    å¤„ç†åŒ…å«è¿è¡Œå’Œçº¿ç¨‹ä¿¡æ¯çš„å…ƒæ•°æ®äº‹ä»¶ã€‚
</ParamField>

<ParamField body="messagesKey" type="string" default="messages">
    å›¾çŠ¶æ€ä¸­åŒ…å«æ¶ˆæ¯æ•°ç»„çš„é”®ã€‚
</ParamField>

<ParamField body="throttle" type="boolean" default="true">
    æ‰¹é‡å¤„ç†çŠ¶æ€æ›´æ–°ä»¥è·å¾—æ›´å¥½çš„æ¸²æŸ“æ€§èƒ½ã€‚ç¦ç”¨æ­¤é€‰é¡¹å¯ç«‹å³æ›´æ–°ã€‚
</ParamField>

<ParamField body="initialValues" type="StateType | null">
    åœ¨ç¬¬ä¸€ä¸ªæµåŠ è½½æ—¶æ˜¾ç¤ºçš„åˆå§‹çŠ¶æ€å€¼ã€‚å¯¹äºç«‹å³æ˜¾ç¤ºç¼“å­˜çš„çº¿ç¨‹æ•°æ®å¾ˆæœ‰ç”¨ã€‚
</ParamField>

</Accordion>

<Accordion title="`useStream` è¿”å›å€¼">

<ParamField body="messages" type="Message[]">
    å½“å‰çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼ŒåŒ…æ‹¬äººç±»å’Œ AI æ¶ˆæ¯ã€‚
</ParamField>

<ParamField body="values" type="StateType">
    å½“å‰çš„å›¾çŠ¶æ€å€¼ã€‚ç±»å‹ä»æ™ºèƒ½ä½“æˆ–å›¾ç±»å‹å‚æ•°æ¨æ–­ã€‚
</ParamField>

<ParamField body="isLoading" type="boolean">
    å½“å‰æ˜¯å¦æœ‰æµæ­£åœ¨è¿›è¡Œã€‚ä½¿ç”¨æ­¤å€¼æ¥æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨ã€‚
</ParamField>

<ParamField body="error" type="Error | null">
    æµå¼ä¼ è¾“æœŸé—´å‘ç”Ÿçš„ä»»ä½•é”™è¯¯ã€‚æ— é”™è¯¯æ—¶ä¸º `null`ã€‚
</ParamField>

<ParamField body="interrupt" type="Interrupt | undefined">
    å½“å‰éœ€è¦ç”¨æˆ·è¾“å…¥çš„ä¸­æ–­ï¼Œä¾‹å¦‚äººæœºååŒï¼ˆhuman-in-the-loopï¼‰çš„æ‰¹å‡†è¯·æ±‚ã€‚
</ParamField>

<ParamField body="toolCalls" type="ToolCallWithResult[]">
    æ‰€æœ‰æ¶ˆæ¯ä¸­çš„æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ŒåŒ…å«å…¶ç»“æœå’ŒçŠ¶æ€ï¼ˆ`pending`ã€`completed` æˆ– `error`ï¼‰ã€‚
</ParamField>

<ParamField body="submit" type="(input, options?) => Promise<void>">
    å‘æ™ºèƒ½ä½“æäº¤æ–°çš„è¾“å…¥ã€‚å½“ä»ä¸­æ–­æ¢å¤å¹¶å¸¦æœ‰å‘½ä»¤æ—¶ï¼Œå°† `null` ä½œä¸ºè¾“å…¥ä¼ é€’ã€‚é€‰é¡¹åŒ…æ‹¬ç”¨äºåˆ†æ”¯çš„ `checkpoint`ã€ç”¨äºä¹è§‚æ›´æ–°çš„ `optimisticValues` ä»¥åŠç”¨äºä¹è§‚çº¿ç¨‹åˆ›å»ºçš„ `threadId`ã€‚
</ParamField>

<ParamField body="stop" type="() => void">
    ç«‹å³åœæ­¢å½“å‰æµã€‚
</ParamField>

<ParamField body="joinStream" type="(runId: string) => void">
    é€šè¿‡è¿è¡Œ ID æ¢å¤ç°æœ‰çš„æµã€‚ä¸ `onCreated` ä¸€èµ·ä½¿ç”¨ä»¥æ‰‹åŠ¨æ¢å¤æµã€‚
</ParamField>

<ParamField body="setBranch" type="(branch: string) => void">
    åˆ‡æ¢åˆ°å¯¹è¯å†å²ä¸­çš„ä¸åŒåˆ†æ”¯ã€‚
</ParamField>

<ParamField body="getToolCalls" type="(message) => ToolCall[]">
    è·å–ç‰¹å®š AI æ¶ˆæ¯çš„æ‰€æœ‰å·¥å…·è°ƒç”¨ã€‚
</ParamField>

<ParamField body="getMessagesMetadata" type="(message) => MessageMetadata">
    è·å–æ¶ˆæ¯çš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æµä¿¡æ¯ï¼Œä¾‹å¦‚ç”¨äºè¯†åˆ«æºèŠ‚ç‚¹çš„ `langgraph_node`ï¼Œä»¥åŠç”¨äºåˆ†æ”¯çš„ `firstSeenState`ã€‚
</ParamField>

<ParamField body="experimental_branchTree" type="BranchTree">
    çº¿ç¨‹çš„æ ‘çŠ¶è¡¨ç¤ºï¼Œç”¨äºåœ¨éåŸºäºæ¶ˆæ¯çš„å›¾ä¸­è¿›è¡Œé«˜çº§åˆ†æ”¯æ§åˆ¶ã€‚
</ParamField>

</Accordion>

## çº¿ç¨‹ç®¡ç†

é€šè¿‡å†…ç½®çš„çº¿ç¨‹ç®¡ç†æ¥è·Ÿè¸ªå¯¹è¯ã€‚æ‚¨å¯ä»¥è®¿é—®å½“å‰çº¿ç¨‹ IDï¼Œå¹¶åœ¨æ–°çº¿ç¨‹åˆ›å»ºæ—¶æ”¶åˆ°é€šçŸ¥ï¼š

```tsx
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const [threadId, setThreadId] = useState<string | null>(null);

  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId: threadId,
    onThreadId: setThreadId,
  });

  // threadId åœ¨æ–°çº¿ç¨‹åˆ›å»ºæ—¶æ›´æ–°
  // å°†å…¶å­˜å‚¨åœ¨ URL å‚æ•°æˆ– localStorage ä¸­ä»¥å®ç°æŒä¹…åŒ–
}
```

æˆ‘ä»¬å»ºè®®å­˜å‚¨ `threadId`ï¼Œä»¥ä¾¿ç”¨æˆ·åœ¨é¡µé¢åˆ·æ–°åèƒ½å¤Ÿæ¢å¤å¯¹è¯ã€‚

### é¡µé¢åˆ·æ–°åæ¢å¤

`useStream` é’©å­å¯ä»¥é€šè¿‡è®¾ç½® `reconnectOnMount: true` åœ¨æŒ‚è½½æ—¶è‡ªåŠ¨æ¢å¤æ­£åœ¨è¿›è¡Œçš„è¿è¡Œã€‚è¿™å¯¹äºåœ¨é¡µé¢åˆ·æ–°åç»§ç»­æµå¼ä¼ è¾“éå¸¸æœ‰ç”¨ï¼Œç¡®ä¿åœ¨åœæœºæœŸé—´ç”Ÿæˆçš„æ¶ˆæ¯å’Œäº‹ä»¶ä¸ä¼šä¸¢å¤±ã€‚

```tsx
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  reconnectOnMount: true,
});
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„è¿è¡Œ ID å­˜å‚¨åœ¨ `window.sessionStorage` ä¸­ï¼Œå¯ä»¥é€šè¿‡ä¼ é€’è‡ªå®šä¹‰å­˜å‚¨å‡½æ•°æ¥æ›¿æ¢ï¼š

```tsx
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
  reconnectOnMount: () => window.localStorage,
});
```

è¦æ‰‹åŠ¨æ§åˆ¶æ¢å¤è¿‡ç¨‹ï¼Œè¯·ä½¿ç”¨è¿è¡Œå›è°ƒæ¥æŒä¹…åŒ–å…ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨ `joinStream` æ¥æ¢å¤ï¼š

```tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import { useEffect, useRef } from "react";

function Chat({ threadId }: { threadId: string | null }) {
  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    onCreated: (run) => {
      // æµå¼€å§‹æ—¶æŒä¹…åŒ–è¿è¡Œ ID
      window.sessionStorage.setItem(`resume:${run.thread_id}`, run.run_id);
    },
    onFinish: (_, run) => {
      // æµå®Œæˆæ—¶æ¸…ç†
      window.sessionStorage.removeItem(`resume:${run?.thread_id}`);
    },
  });

  // å¦‚æœå­˜åœ¨å­˜å‚¨çš„è¿è¡Œ IDï¼Œåˆ™åœ¨æŒ‚è½½æ—¶æ¢å¤æµ
  const joinedThreadId = useRef<string | null>(null);
  useEffect(() => {
    if (!threadId) return;
    const runId = window.sessionStorage.getItem(`resume:${threadId}`);
    if (runId && joinedThreadId.current !== threadId) {
      stream.joinStream(runId);
      joinedThreadId.current = threadId;
    }
  }, [threadId]);

  const handleSubmit = (text: string) => {
    // ä½¿ç”¨ streamResumable ç¡®ä¿äº‹ä»¶ä¸ä¼šä¸¢å¤±
    stream.submit(
      { messages: [{ type: "human", content: text }] },
      { streamResumable: true }
    );
  };
}
```

<Card title="å°è¯•ä¼šè¯æŒä¹…åŒ–ç¤ºä¾‹" icon="rotate" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/session-persistence">
  åœ¨ `session-persistence` ç¤ºä¾‹ä¸­æŸ¥çœ‹ä½¿ç”¨ `reconnectOnMount` å’Œçº¿ç¨‹æŒä¹…åŒ–å®ç°æµæ¢å¤çš„å®Œæ•´å®ç°ã€‚
</Card>

## ä¹è§‚æ›´æ–°

æ‚¨å¯ä»¥åœ¨æ‰§è¡Œç½‘ç»œè¯·æ±‚ä¹‹å‰ä¹è§‚åœ°æ›´æ–°å®¢æˆ·ç«¯çŠ¶æ€ï¼Œä¸ºç”¨æˆ·æä¾›å³æ—¶åé¦ˆï¼š

```tsx
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});

const handleSubmit = (text: string) => {
  const newMessage = { type: "human" as const, content: text };

  stream.submit(
    { messages: [newMessage] },
    {
      optimisticValues(prev) {
        const prevMessages = prev.messages ?? [];
        return { ...prev, messages: [...prevMessages, newMessage] };
      },
    }
  );
};
```

### ä¹è§‚çº¿ç¨‹åˆ›å»º

åœ¨ `submit` ä¸­ä½¿ç”¨ `threadId` é€‰é¡¹ï¼Œä»¥å®ç°åœ¨çº¿ç¨‹åˆ›å»ºä¹‹å‰éœ€è¦çŸ¥é“çº¿ç¨‹ ID çš„ä¹è§‚ UI æ¨¡å¼ï¼š

```tsx
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";

function Chat() {
  const [threadId, setThreadId] = useState<string | null>(null);
  const [optimisticThreadId] = useState(() => crypto.randomUUID());

  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    onThreadId: setThreadId,
  });

  const handleSubmit = (text: string) => {
    // ç«‹å³å¯¼èˆªï¼Œæ— éœ€ç­‰å¾…çº¿ç¨‹åˆ›å»º
    window.history.pushState({}, "", `/threads/${optimisticThreadId}`);

    // ä½¿ç”¨é¢„å®šçš„ ID åˆ›å»ºçº¿ç¨‹
    stream.submit(
      { messages: [{ type: "human", content: text }] },
      { threadId: optimisticThreadId }
    );
  };
}
```

### ç¼“å­˜çº¿ç¨‹æ˜¾ç¤º

ä½¿ç”¨ `initialValues` é€‰é¡¹åœ¨ä»æœåŠ¡å™¨åŠ è½½å†å²è®°å½•æ—¶ç«‹å³æ˜¾ç¤ºç¼“å­˜çš„çº¿ç¨‹æ•°æ®ï¼š

```tsx
function Chat({ threadId, cachedData }) {
  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
    threadId,
    initialValues: cachedData?.values,
  });

  // ç«‹å³æ˜¾ç¤ºç¼“å­˜çš„æ¶ˆæ¯ï¼Œç„¶ååœ¨æœåŠ¡å™¨å“åº”æ—¶æ›´æ–°
}
```

## åˆ†æ”¯

é€šè¿‡ç¼–è¾‘å…ˆå‰çš„æ¶ˆæ¯æˆ–é‡æ–°ç”Ÿæˆ AI å“åº”ï¼Œå¯ä»¥åˆ›å»ºæ›¿ä»£çš„å¯¹è¯è·¯å¾„ã€‚ä½¿ç”¨ `getMessagesMetadata()` æ¥è®¿é—®ç”¨äºåˆ†æ”¯çš„æ£€æŸ¥ç‚¹ä¿¡æ¯ï¼š

<CodeGroup>

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import { BranchSwitcher } from "./BranchSwitcher";

function Chat() {
  const stream = useStream({
    apiUrl: "http://localhost:2024",
    assistantId: "agent",
  });

  return (
    <div>
      {stream.messages.map((message) => {
        const meta = stream.getMessagesMetadata(message);
        const parentCheckpoint = meta?.firstSeenState?.parent_checkpoint;

        return (
          <div key={message.id}>
            <div>{message.content as string}</div>

            {/* ç¼–è¾‘äººç±»æ¶ˆæ¯ */}
            {message.type === "human" && (
              <button
                onClick={() => {
                  const newContent = prompt("ç¼–è¾‘æ¶ˆæ¯:", message.content as string);
                  if (newContent) {
                    stream.submit(
                      { messages: [{ type: "human", content: newContent }] },
                      { checkpoint: parentCheckpoint }
                    );
                  }
                }}
              >
                ç¼–è¾‘
              </button>
            )}

            {/* é‡æ–°ç”Ÿæˆ AI æ¶ˆæ¯ */}
            {message.type === "ai" && (
              <button
                onClick={() => stream.submit(undefined, { checkpoint: parentCheckpoint })}
              >
                é‡æ–°ç”Ÿæˆ
              </button>
            )}

            {/* åœ¨åˆ†æ”¯ä¹‹é—´åˆ‡æ¢ */}
            <BranchSwitcher
              branch={meta?.branch}
              branchOptions={meta?.branchOptions}
              onSelect={(branch) => stream.setBranch(branch)}
            />
          </div>
        );
      })}
    </div>
  );
}
```

```tsx BranchSwitcher.tsx
/**
 * ç”¨äºåœ¨å¯¹è¯åˆ†æ”¯ä¹‹é—´å¯¼èˆªçš„ç»„ä»¶ã€‚
 * æ˜¾ç¤ºå½“å‰åˆ†æ”¯ä½ç½®å¹¶å…è®¸åœ¨å¤‡é€‰åˆ†æ”¯ä¹‹é—´åˆ‡æ¢ã€‚
 */
export function BranchSwitcher({
  branch,
  branchOptions,
  onSelect,
}: {
  branch: string | undefined;
  branchOptions: string[] | undefined;
  onSelect: (branch: string) => void;
}) {
  if (!branchOptions || !branch) return null;
  const index = branchOptions.indexOf(branch);

  return (
    <div className="flex items-center gap-2">
      <button
        type="button"
        disabled={index <= 0}
        onClick={() => onSelect(branchOptions[index - 1])}
      >
        â†
      </button>
      <span>{index + 1} / {branchOptions.length}</span>
      <button
        type="button"
        disabled={index >= branchOptions.length - 1}
        onClick={() => onSelect(branchOptions[index + 1])}
      >
        â†’
      </button>
    </div>
  );
}
```

</CodeGroup>

å¯¹äºé«˜çº§ç”¨ä¾‹ï¼Œä½¿ç”¨ `experimental_branchTree` å±æ€§æ¥è·å–çº¿ç¨‹çš„æ ‘å½¢è¡¨ç¤ºï¼Œé€‚ç”¨äºéåŸºäºæ¶ˆæ¯çš„å›¾ã€‚

<Card title="å°è¯•åˆ†æ”¯ç¤ºä¾‹" icon="code-branch" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/branching-chat">
  åœ¨ `branching-chat` ç¤ºä¾‹ä¸­æŸ¥çœ‹å¯¹è¯åˆ†æ”¯çš„å®Œæ•´å®ç°ï¼ŒåŒ…æ‹¬ç¼–è¾‘ã€é‡æ–°ç”Ÿæˆå’Œåˆ†æ”¯åˆ‡æ¢åŠŸèƒ½ã€‚
</Card>

## ç±»å‹å®‰å…¨çš„æµå¼å¤„ç†

å½“ä¸é€šè¿‡ @[`createAgent`] åˆ›å»ºçš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰æˆ–ä½¿ç”¨ @[`StateGraph`] åˆ›å»ºçš„å›¾ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œ`useStream` é’©å­æ”¯æŒå®Œæ•´çš„ç±»å‹æ¨æ–­ã€‚å°† `typeof agent` æˆ– `typeof graph` ä½œä¸ºç±»å‹å‚æ•°ä¼ é€’ï¼Œä»¥è‡ªåŠ¨æ¨æ–­å·¥å…·è°ƒç”¨ç±»å‹ã€‚

### ä½¿ç”¨ `createAgent`

å½“ä½¿ç”¨ @[`createAgent`] æ—¶ï¼Œå·¥å…·è°ƒç”¨ç±»å‹ä¼šæ ¹æ®ä½ æ³¨å†Œåˆ°æ™ºèƒ½ä½“ï¼ˆagentï¼‰çš„å·¥å…·è‡ªåŠ¨æ¨æ–­ï¼š

:::python
<CodeGroup>

```python agent.py
from langchain import create_agent, tool

@tool
def get_weather(location: str) -> str:
    """Get weather for a location."""
    return f"Weather in {location}: Sunny, 72Â°F"

agent = create_agent(
    model="openai:gpt-4o-mini",
    tools=[get_weather],
)
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState } from "./types";

function Chat() {
  // ä½¿ç”¨æ‰‹åŠ¨å®šä¹‰çš„çŠ¶æ€ç±»å‹
  const stream = useStream<AgentState>({
    assistantId: "agent",
    apiUrl: "http://localhost:2024",
  });

  // stream.toolCalls[0].call.name çš„ç±»å‹ä¸º "get_weather"
  // stream.toolCalls[0].call.args çš„ç±»å‹ä¸º { location: string }
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// å®šä¹‰å·¥å…·è°ƒç”¨ç±»å‹ä»¥åŒ¹é…ä½ çš„ Python æ™ºèƒ½ä½“
export type GetWeatherToolCall = {
  name: "get_weather";
  args: { location: string };
  id?: string;
};

export type AgentToolCalls = GetWeatherToolCall;

export interface AgentState {
  messages: Message<AgentToolCalls>[];
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```typescript agent.ts
import { createAgent, tool } from "langchain";
import { z } from "zod";

const getWeather = tool(
  async ({ location }) => `Weather in ${location}: Sunny, 72Â°F`,
  {
    name: "get_weather",
    description: "Get weather for a location",
    schema: z.object({
      location: z.string().describe("The city to get weather for"),
    }),
  }
);

export const agent = createAgent({
  model: "openai:gpt-4o-mini",
  tools: [getWeather],
});
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { agent } from "./agent";

function Chat() {
  // å·¥å…·è°ƒç”¨ç±»å‹ä¼šè‡ªåŠ¨ä»æ™ºèƒ½ä½“çš„å·¥å…·ä¸­æ¨æ–­å‡ºæ¥
  const stream = useStream<typeof agent>({
    assistantId: "agent",
    apiUrl: "http://localhost:2024",
  });

  // stream.toolCalls[0].call.name çš„ç±»å‹ä¸º "get_weather"
  // stream.toolCalls[0].call.args çš„ç±»å‹ä¸º { location: string }
}
```

</CodeGroup>
:::

### ä½¿ç”¨ `StateGraph`

å¯¹äºè‡ªå®šä¹‰çš„ @[`StateGraph`] åº”ç”¨ç¨‹åºï¼ŒçŠ¶æ€ç±»å‹æ˜¯ä»å›¾çš„æ³¨è§£ä¸­æ¨æ–­å‡ºæ¥çš„ï¼š

:::python
<CodeGroup>

```python graph.py
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from typing import TypedDict, Annotated

class State(TypedDict):
    messages: Annotated[list, add_messages]

model = ChatOpenAI(model="gpt-4o-mini")

async def agent(state: State) -> dict:
    response = await model.ainvoke(state["messages"])
    return {"messages": [response]}

workflow = StateGraph(State)
workflow.add_node("agent", agent)
workflow.add_edge(START, "agent")
workflow.add_edge("agent", END)

graph = workflow.compile()
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { GraphState } from "./types";

function Chat() {
  // ä½¿ç”¨æ‰‹åŠ¨å®šä¹‰çš„çŠ¶æ€ç±»å‹
  const stream = useStream<GraphState>({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.values çš„ç±»å‹åŸºäºä½ å®šä¹‰çš„çŠ¶æ€
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// å®šä¹‰çŠ¶æ€ä»¥åŒ¹é…ä½ çš„ Python å›¾çš„ State TypedDict
export interface GraphState {
  messages: Message[];
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```typescript graph.ts
import { StateGraph, MessagesAnnotation, START, END } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({ model: "gpt-4o-mini" });

const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", async (state) => {
    const response = await model.invoke(state.messages);
    return { messages: [response] };
  })
  .addEdge(START, "agent")
  .addEdge("agent", END);

export const graph = workflow.compile();
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { graph } from "./graph";

function Chat() {
  // çŠ¶æ€ç±»å‹ä¼šæ ¹æ®å›¾è‡ªåŠ¨æ¨æ–­
  const stream = useStream<typeof graph>({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.values çš„ç±»å‹åŸºäºå›¾çš„ state æ³¨è§£
}
```

</CodeGroup>
:::

### ä½¿ç”¨æ³¨è§£ç±»å‹

å¦‚æœä½ åœ¨ä½¿ç”¨ LangGraph.jsï¼Œå¯ä»¥å¤ç”¨ä½ å›¾çš„æ³¨è§£ç±»å‹ã€‚è¯·ç¡®ä¿åªå¯¼å…¥ç±»å‹ï¼Œä»¥é¿å…å¯¼å…¥æ•´ä¸ª LangGraph.js è¿è¡Œæ—¶ï¼š

:::js
```tsx
import {
  Annotation,
  MessagesAnnotation,
  type StateType,
  type UpdateType,
} from "@langchain/langgraph/web";

const AgentState = Annotation.Root({
  ...MessagesAnnotation.spec,
  context: Annotation<string>(),
});

const stream = useStream<
  StateType<typeof AgentState.spec>,
  { UpdateType: UpdateType<typeof AgentState.spec> }
>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});
```
:::

### é«˜çº§ç±»å‹é…ç½®

ä½ å¯ä»¥ä¸ºä¸­æ–­ã€è‡ªå®šä¹‰äº‹ä»¶å’Œå¯é…ç½®é€‰é¡¹æŒ‡å®šé¢å¤–çš„ç±»å‹å‚æ•°ï¼š

:::js
```tsx
import type { Message } from "@langchain/langgraph-sdk";

type State = { messages: Message[]; context?: string };

const stream = useStream<
  State,
  {
    UpdateType: { messages: Message[] | Message; context?: string };
    InterruptType: string;
    CustomEventType: { type: "progress" | "debug"; payload: unknown };
    ConfigurableType: { model: string };
  }
>({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",
});

// stream.interrupt çš„ç±»å‹ä¸º string | undefined
// onCustomEvent æ¥æ”¶ç±»å‹åŒ–çš„äº‹ä»¶
```
:::

## æ¸²æŸ“å·¥å…·è°ƒç”¨

ä½¿ç”¨ `getToolCalls` ä» AI æ¶ˆæ¯ä¸­æå–å¹¶æ¸²æŸ“å·¥å…·è°ƒç”¨ã€‚å·¥å…·è°ƒç”¨åŒ…æ‹¬è°ƒç”¨è¯¦æƒ…ã€ç»“æœï¼ˆå¦‚æœå·²å®Œæˆï¼‰å’ŒçŠ¶æ€ã€‚

:::python
<CodeGroup>

```python agent.py
from langchain import create_agent, tool

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šåœ°ç‚¹çš„å½“å‰å¤©æ°”ã€‚"""
    return f'{{"status": "success", "content": "Weather in {location}: Sunny, 72Â°F"}}'

agent = create_agent(
    model="openai:gpt-4o-mini",
    tools=[get_weather],
)
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState, AgentToolCalls } from "./types";
import { ToolCallCard } from "./ToolCallCard";
import { MessageBubble } from "./MessageBubble";

function Chat() {
  const stream = useStream<AgentState>({
    assistantId: "agent",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type === "ai") {
          const toolCalls = stream.getToolCalls(message);

          if (toolCalls.length > 0) {
            return (
              <div key={message.id ?? idx} className="flex flex-col gap-2">
                {toolCalls.map((toolCall) => (
                  <ToolCallCard key={toolCall.id} toolCall={toolCall} />
                ))}
              </div>
            );
          }
        }

        return <MessageBubble key={message.id ?? idx} message={message} />;
      })}
    </div>
  );
}
```

```tsx ToolCallCard.tsx
import type { ToolCallWithResult, ToolCallState } from "@langchain/langgraph-sdk/react";
import type { ToolMessage } from "@langchain/langgraph-sdk";
import type { AgentToolCalls, GetWeatherToolCall } from "./types";
import { parseToolResult } from "./utils";
import { WeatherCard } from "./WeatherCard";
import { GenericToolCallCard } from "./GenericToolCallCard";

export function ToolCallCard({
  toolCall,
}: {
  toolCall: ToolCallWithResult<AgentToolCalls>;
}) {
  const { call, result, state } = toolCall;

  if (call.name === "get_weather") {
    return <WeatherCard call={call} result={result} state={state} />;
  }

  return <GenericToolCallCard call={call} result={result} state={state} />;
}
```

```tsx WeatherCard.tsx
import type { ToolCallState } from "@langchain/langgraph-sdk/react";
import type { ToolMessage } from "@langchain/langgraph-sdk";
import type { GetWeatherToolCall } from "./types";
import { parseToolResult } from "./utils";

export function WeatherCard({
  call,
  result,
  state,
}: {
  call: GetWeatherToolCall;
  result?: ToolMessage;
  state: ToolCallState;
}) {
  const isLoading = state === "pending";
  const parsedResult = parseToolResult(result);

  return (
    <div className="relative overflow-hidden rounded-xl">
      <div className="absolute inset-0 bg-gradient-to-br from-sky-600 to-indigo-600" />
      <div className="relative p-4">
        <div className="flex items-center gap-2 text-white/80 text-xs mb-3">
          <span className="font-medium">{call.args.location}</span>
          {isLoading && <span className="ml-auto">Loading...</span>}
        </div>
        {parsedResult.status === "error" ? (
          <div className="bg-red-500/20 rounded-lg p-3 text-red-200 text-sm">
            {parsedResult.content}
          </div>
        ) : (
          <div className="text-white text-lg font-medium">
            {parsedResult.content || "Fetching weather..."}
          </div>
        )}
      </div>
    </div>
  );
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// å®šä¹‰å·¥å…·è°ƒç”¨ç±»å‹ä»¥åŒ¹é…ä½ çš„ Python æ™ºèƒ½ä½“çš„å·¥å…·
export type GetWeatherToolCall = {
  name: "get_weather";
  args: { location: string };
  id?: string;
};

// ä½ çš„æ™ºèƒ½ä½“ä¸­æ‰€æœ‰å·¥å…·è°ƒç”¨çš„è”åˆç±»å‹
export type AgentToolCalls = GetWeatherToolCall;

// ä½¿ç”¨ä½ çš„å·¥å…·è°ƒç”¨å®šä¹‰çŠ¶æ€ç±»å‹
export interface AgentState {
  messages: Message<AgentToolCalls>[];
}
```

```typescript utils.ts
import type { ToolMessage } from "@langchain/langgraph-sdk";

export function parseToolResult(result?: ToolMessage): {
  status: string;
  content: string;
} {
  if (!result) return { status: "pending", content: "" };
  try {
    return JSON.parse(result.content as string);
  } catch {
    return { status: "success", content: result.content as string };
  }
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { agent } from "./agent";
import { ToolCallCard } from "./ToolCallCard";
import { MessageBubble } from "./MessageBubble";

function Chat() {
  const stream = useStream<typeof agent>({
    assistantId: "agent",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type === "ai") {
          const toolCalls = stream.getToolCalls(message);

          if (toolCalls.length > 0) {
            return (
              <div key={message.id ?? idx} className="flex flex-col gap-2">
                {toolCalls.map((toolCall) => (
                  <ToolCallCard key={toolCall.id} toolCall={toolCall} />
                ))}
              </div>
            );
          }
        }

        return <MessageBubble key={message.id ?? idx} message={message} />;
      })}
    </div>
  );
}
```

```tsx ToolCallCard.tsx
import type {
  ToolCallWithResult,
  ToolCallFromTool,
  ToolCallState,
  InferAgentToolCalls,
} from "@langchain/langgraph-sdk/react";
import type { ToolMessage } from "@langchain/langgraph-sdk";
import type { agent } from "./agent";
import type { getWeather } from "./tools";
import { parseToolResult } from "./utils";
import { WeatherCard } from "./WeatherCard";

/**
 * ä¸ºæ­¤ç»„ä»¶å®šä¹‰å·¥å…·è°ƒç”¨ç±»å‹ã€‚
 * å¯¹äºæ™ºèƒ½ä½“ä½¿ç”¨ InferAgentToolCallsï¼Œå¯¹äºå•ä¸ªå·¥å…·ä½¿ç”¨ ToolCallFromToolã€‚
 */
type AgentToolCalls = InferAgentToolCalls<typeof agent>;

/**
 * æ¸²æŸ“å·¥å…·è°ƒç”¨åŠå…¶ç»“æœçš„ç»„ä»¶ã€‚
 * ä½¿ç”¨ç±»å‹åŒ–çš„ ToolCallWithResult è¿›è¡Œå¯è¾¨è¯†è”åˆç±»å‹æ”¶çª„ã€‚
 */
export function ToolCallCard({
  toolCall,
}: {
  toolCall: ToolCallWithResult<AgentToolCalls>;
}) {
  const { call, result, state } = toolCall;

// å½“ call.name æ˜¯å­—é¢é‡ç±»å‹æ—¶ï¼Œç±»å‹æ”¶çª„ç”Ÿæ•ˆ
  if (call.name === "get_weather") {
    return <WeatherCard call={call} result={result} state={state} />;
  }

  // å…¶ä»–å·¥å…·çš„å…œåº•å¤„ç†
  return <GenericToolCallCard call={call} result={result} state={state} />;
}
```

```tsx GenericToolCallCard.tsx
import type { ToolCallState } from "@langchain/langgraph-sdk/react";
import type { ToolMessage } from "@langchain/langgraph-sdk";
import { parseToolResult } from "./utils";

/**
 * ç”¨äºæœªçŸ¥æˆ–æœªå¤„ç†å·¥å…·çš„é€šç”¨å…œåº•ç»„ä»¶ã€‚
 * ä½¿ç”¨ä¸€ä¸ªé€‚ç”¨äºä»»ä½•å·¥å…·è°ƒç”¨çš„ç®€å•ç±»å‹ã€‚
 */
export function GenericToolCallCard({
  call,
  result,
  state,
}: {
  call: { name: string; args: Record<string, unknown> };
  result?: ToolMessage;
  state: ToolCallState;
}) {
  const isLoading = state === "pending";
  const parsedResult = parseToolResult(result);

  return (
    <div className="bg-neutral-900 rounded-lg p-4 border border-neutral-800">
      <div className="flex items-center gap-3 mb-3">
        <div className="flex-1">
          <div className="text-sm font-medium text-white font-mono">
            {call.name}
          </div>
          <div className="text-xs text-neutral-500">
            {isLoading ? "å¤„ç†ä¸­..." : "å·²å®Œæˆ"}
          </div>
        </div>
      </div>
      <pre className="text-xs bg-black rounded p-2 mb-2 overflow-x-auto">
        {JSON.stringify(call.args, null, 2)}
      </pre>
      {result && (
        <div className="text-sm rounded-lg p-3 bg-black text-neutral-300">
          {parsedResult.content}
        </div>
      )}
    </div>
  );
}
```

```tsx WeatherCard.tsx
import type { ToolCallFromTool, ToolCallState } from "@langchain/langgraph-sdk/react";
import type { ToolMessage } from "@langchain/langgraph-sdk";
import type { getWeather } from "./tools";
import { parseToolResult } from "./utils";

// ç›´æ¥ä»å·¥å…·å®šä¹‰æ¨æ–­å·¥å…·è°ƒç”¨ç±»å‹
type GetWeatherToolCall = ToolCallFromTool<typeof getWeather>;

/**
 * å¤©æ°”ä¸“ç”¨çš„å·¥å…·å¡ç‰‡ï¼Œå…·æœ‰ä¸°å¯Œçš„ UIã€‚
 * ä½¿ç”¨ ToolCallFromTool ä»å·¥å…·æ¨¡å¼æ¨æ–­ args ç±»å‹ã€‚
 */
export function WeatherCard({
  call,
  result,
  state,
}: {
  call: GetWeatherToolCall;
  result?: ToolMessage;
  state: ToolCallState;
}) {
  const isLoading = state === "pending";
  const parsedResult = parseToolResult(result);

  return (
    <div className="relative overflow-hidden rounded-xl">
      {/* å¤©ç©ºæ¸å˜èƒŒæ™¯ */}
      <div className="absolute inset-0 bg-gradient-to-br from-sky-600 to-indigo-600" />

      <div className="relative p-4">
        <div className="flex items-center gap-2 text-white/80 text-xs mb-3">
          {/* call.args æ ¹æ®å·¥å…·æ¨¡å¼è¢«ç±»å‹åŒ–ä¸º { location: string } */}
          <span className="font-medium">{call.args.location}</span>
          {isLoading && <span className="ml-auto">åŠ è½½ä¸­...</span>}
        </div>

        {parsedResult.status === "error" ? (
          <div className="bg-red-500/20 rounded-lg p-3 text-red-200 text-sm">
            {parsedResult.content}
          </div>
        ) : (
          <div className="text-white text-lg font-medium">
            {parsedResult.content || "æ­£åœ¨è·å–å¤©æ°”..."}
          </div>
        )}
      </div>
    </div>
  );
}
```

```typescript tools.ts
import { tool } from "@langchain/core/tools";
import { z } from "zod";

// ä½¿ç”¨ Zod æ¨¡å¼å®šä¹‰å¤©æ°”å·¥å…·
export const getWeather = tool(
  async ({ location }) => {
    // å·¥å…·å®ç°
    return JSON.stringify({ status: "success", content: `Weather in ${location}: Sunny, 72Â°F` });
  },
  {
    name: "get_weather",
    description: "è·å–æŒ‡å®šä½ç½®çš„å½“å‰å¤©æ°”",
    schema: z.object({
      location: z.string().describe("åŸå¸‚å’Œå·ï¼Œä¾‹å¦‚ï¼šSan Francisco, CA"),
    }),
  }
);
```

```typescript utils.ts
import type { ToolMessage } from "@langchain/langgraph-sdk";

/**
 * å®‰å…¨è§£æå·¥å…·ç»“æœçš„è¾…åŠ©å‡½æ•°ã€‚
 * å·¥å…·ç»“æœå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ–çº¯æ–‡æœ¬ã€‚
 */
export function parseToolResult(result?: ToolMessage): {
  status: string;
  content: string;
} {
  if (!result) return { status: "pending", content: "" };
  try {
    return JSON.parse(result.content as string);
  } catch {
    return { status: "success", content: result.content as string };
  }
}
```

</CodeGroup>
:::

<Card title="å°è¯•å·¥å…·è°ƒç”¨ç¤ºä¾‹" icon="hammer" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/tool-calling-agent">
  åœ¨ `tool-calling-agent` ç¤ºä¾‹ä¸­æŸ¥çœ‹åŒ…å«å¤©æ°”ã€è®¡ç®—å™¨å’Œç¬”è®°å·¥å…·çš„å®Œæ•´å·¥å…·è°ƒç”¨æ¸²æŸ“å®ç°ã€‚
</Card>

## è‡ªå®šä¹‰æµå¼äº‹ä»¶

ä½¿ç”¨å·¥å…·æˆ–èŠ‚ç‚¹ä¸­çš„ `writer` ä»æ‚¨çš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰æµå¼ä¼ è¾“è‡ªå®šä¹‰æ•°æ®ã€‚åœ¨ UI ä¸­ä½¿ç”¨ `onCustomEvent` å›è°ƒå¤„ç†è¿™äº›äº‹ä»¶ã€‚

:::python
<CodeGroup>

```python agent.py
import asyncio
import time
from langchain import create_agent, tool
from langchain.types import ToolRuntime

@tool
async def analyze_data(data_source: str, *, config: ToolRuntime) -> str:
    """åˆ†ææ•°æ®å¹¶æ›´æ–°è¿›åº¦ã€‚"""
    steps = ["è¿æ¥ä¸­...", "è·å–ä¸­...", "å¤„ç†ä¸­...", "å®Œæˆï¼"]

    for i, step in enumerate(steps):
        # åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å‘å‡ºè¿›åº¦äº‹ä»¶
        if config.writer:
            config.writer({
                "type": "progress",
                "id": f"analysis-{int(time.time() * 1000)}",
                "message": step,
                "progress": ((i + 1) / len(steps)) * 100,
            })
        await asyncio.sleep(0.5)

    return '{"result": "åˆ†æå®Œæˆ"}'

agent = create_agent(
    model="openai:gpt-4o-mini",
    tools=[analyze_data],
)
```

```tsx Chat.tsx
import { useState, useCallback } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState } from "./types";

interface ProgressData {
  type: "progress";
  id: string;
  message: string;
  progress: number;
}

function isProgressData(data: unknown): data is ProgressData {
  return (
    typeof data === "object" &&
    data !== null &&
    "type" in data &&
    (data as ProgressData).type === "progress"
  );
}

function CustomStreamingUI() {
  const [progressData, setProgressData] = useState<Map<string, ProgressData>>(
    new Map()
  );

  const handleCustomEvent = useCallback((data: unknown) => {
    if (isProgressData(data)) {
      setProgressData((prev) => {
        const updated = new Map(prev);
        updated.set(data.id, data);
        return updated;
      });
    }
  }, []);

  const stream = useStream<AgentState>({
    assistantId: "custom-streaming",
    apiUrl: "http://localhost:2024",
    onCustomEvent: handleCustomEvent,
  });

  return (
    <div>
      {Array.from(progressData.values()).map((data) => (
        <div key={data.id} className="bg-neutral-800 rounded-lg p-4 mb-4">
          <div className="flex justify-between mb-2">
            <span className="text-sm text-white">{data.message}</span>
            <span className="text-xs text-neutral-400">{data.progress}%</span>
          </div>
          <div className="w-full bg-neutral-700 rounded-full h-2">
            <div
              className="bg-blue-500 h-2 rounded-full transition-all"
              style={{ width: `${data.progress}%` }}
            />
          </div>
        </div>
      ))}
    </div>
  );
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// å®šä¹‰å·¥å…·è°ƒç”¨ä»¥åŒ¹é…æ‚¨çš„ Python æ™ºèƒ½ä½“ï¼ˆagentï¼‰
export type AnalyzeDataToolCall = {
  name: "analyze_data";
  args: { data_source: string };
  id?: string;
};

export type AgentToolCalls = AnalyzeDataToolCall;

export interface AgentState {
  messages: Message<AgentToolCalls>[];
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```typescript agent.ts
import { tool, type ToolRuntime } from "langchain";
import { z } from "zod";

// å®šä¹‰è‡ªå®šä¹‰äº‹ä»¶ç±»å‹
interface ProgressData {
  type: "progress";
  id: string;
  message: string;
  progress: number;
}

const analyzeDataTool = tool(
  async ({ dataSource }, config: ToolRuntime) => {
    const steps = ["Connecting...", "Fetching...", "Processing...", "Done!"];

    for (let i = 0; i < steps.length; i++) {
      // åœ¨æ‰§è¡ŒæœŸé—´å‘å‡ºè¿›åº¦äº‹ä»¶
      config.writer?.({
        type: "progress",
        id: `analysis-${Date.now()}`,
        message: steps[i],
        progress: ((i + 1) / steps.length) * 100,
      } satisfies ProgressData);

      await new Promise((resolve) => setTimeout(resolve, 500));
    }

    return JSON.stringify({ result: "Analysis complete" });
  },
  {
    name: "analyze_data",
    description: "Analyze data with progress updates",
    schema: z.object({
      dataSource: z.string().describe("Data source to analyze"),
    }),
  }
);
```

```tsx Chat.tsx
import { useState, useCallback } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";
import type { agent } from "./agent";

interface ProgressData {
  type: "progress";
  id: string;
  message: string;
  progress: number;
}

function isProgressData(data: unknown): data is ProgressData {
  return (
    typeof data === "object" &&
    data !== null &&
    "type" in data &&
    (data as ProgressData).type === "progress"
  );
}

function CustomStreamingUI() {
  const [progressData, setProgressData] = useState<Map<string, ProgressData>>(
    new Map()
  );

  const handleCustomEvent = useCallback((data: unknown) => {
    if (isProgressData(data)) {
      setProgressData((prev) => {
        const updated = new Map(prev);
        updated.set(data.id, data);
        return updated;
      });
    }
  }, []);

  const stream = useStream<typeof agent>({
    assistantId: "custom-streaming",
    apiUrl: "http://localhost:2024",
    onCustomEvent: handleCustomEvent,
  });

  return (
    <div>
      {/* æ¸²æŸ“è¿›åº¦å¡ç‰‡ */}
      {Array.from(progressData.values()).map((data) => (
        <div key={data.id} className="bg-neutral-800 rounded-lg p-4 mb-4">
          <div className="flex justify-between mb-2">
            <span className="text-sm text-white">{data.message}</span>
            <span className="text-xs text-neutral-400">{data.progress}%</span>
          </div>
          <div className="w-full bg-neutral-700 rounded-full h-2">
            <div
              className="bg-blue-500 h-2 rounded-full transition-all"
              style={{ width: `${data.progress}%` }}
            />
          </div>
        </div>
      ))}
    </div>
  );
}
```

</CodeGroup>
:::

<Card title="å°è¯•è‡ªå®šä¹‰æµå¼å¤„ç†ç¤ºä¾‹" icon="bolt" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/custom-streaming">
  åœ¨ `custom-streaming` ç¤ºä¾‹ä¸­æŸ¥çœ‹åŒ…å«è¿›åº¦æ¡ã€çŠ¶æ€å¾½ç« å’Œæ–‡ä»¶æ“ä½œå¡ç‰‡çš„è‡ªå®šä¹‰äº‹ä»¶çš„å®Œæ•´å®ç°ã€‚
</Card>

## äº‹ä»¶å¤„ç†

`useStream` é’©å­æä¾›äº†å›è°ƒé€‰é¡¹ï¼Œè®©ä½ å¯ä»¥è®¿é—®ä¸åŒç±»å‹çš„æµå¼äº‹ä»¶ã€‚ä½ æ— éœ€æ˜¾å¼é…ç½®æµæ¨¡å¼â€”â€”åªéœ€ä¸ºä½ æƒ³è¦å¤„ç†çš„äº‹ä»¶ç±»å‹ä¼ é€’å›è°ƒå‡½æ•°ï¼š

:::js
```tsx
const stream = useStream({
  apiUrl: "http://localhost:2024",
  assistantId: "agent",

  // åœ¨æ¯ä¸ªå›¾æ­¥éª¤åå¤„ç†çŠ¶æ€æ›´æ–°
  onUpdateEvent: (update, options) => {
    console.log("Graph update:", update);
  },

  // å¤„ç†ä»ä½ çš„å›¾æµå¼ä¼ è¾“çš„è‡ªå®šä¹‰äº‹ä»¶
  onCustomEvent: (event, options) => {
    console.log("Custom event:", event);
  },

  // å¤„ç†åŒ…å«è¿è¡Œ/çº¿ç¨‹ä¿¡æ¯çš„å…ƒæ•°æ®äº‹ä»¶
  onMetadataEvent: (metadata) => {
    console.log("Run ID:", metadata.run_id);
    console.log("Thread ID:", metadata.thread_id);
  },

  onError: (error) => {
    console.error("Stream error:", error);
  },

  onFinish: (state, options) => {
    console.log("Stream finished with final state:", state);
  },
});
```
:::

### å¯ç”¨çš„å›è°ƒ

| å›è°ƒå‡½æ•° | æè¿° | æµæ¨¡å¼ |
|----------|-------------|-------------|
| `onUpdateEvent` | åœ¨æ¯ä¸ªå›¾æ­¥éª¤åæ¥æ”¶åˆ°çŠ¶æ€æ›´æ–°æ—¶è°ƒç”¨ | `updates` |
| `onCustomEvent` | ä»ä½ çš„å›¾ä¸­æ¥æ”¶åˆ°è‡ªå®šä¹‰äº‹ä»¶æ—¶è°ƒç”¨ | `custom` |
| `onMetadataEvent` | æ¥æ”¶åˆ°è¿è¡Œå’Œçº¿ç¨‹å…ƒæ•°æ®æ—¶è°ƒç”¨ | `metadata` |
| `onError` | å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨ | - |
| `onFinish` | æµå®Œæˆæ—¶è°ƒç”¨ | - |

## å¤šæ™ºèƒ½ä½“æµå¼å¤„ç†

åœ¨å¤„ç†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæˆ–å…·æœ‰å¤šä¸ªèŠ‚ç‚¹çš„å›¾æ—¶ï¼Œä½¿ç”¨æ¶ˆæ¯å…ƒæ•°æ®æ¥è¯†åˆ«æ¯æ¡æ¶ˆæ¯æ˜¯ç”±å“ªä¸ªèŠ‚ç‚¹ç”Ÿæˆçš„ã€‚å½“å¤šä¸ª LLM å¹¶è¡Œè¿è¡Œï¼Œå¹¶ä¸”ä½ å¸Œæœ›ä»¥ä¸åŒçš„è§†è§‰æ ·å¼æ˜¾ç¤ºå®ƒä»¬çš„è¾“å‡ºæ—¶ï¼Œè¿™å°¤å…¶æœ‰ç”¨ã€‚

:::python
<CodeGroup>

```python agent.py
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END, Send
from langgraph.graph.state import CompiledStateGraph
from langchain.messages import BaseMessage, AIMessage
from typing import TypedDict, Annotated
import operator

# ä½¿ç”¨ä¸åŒçš„æ¨¡å‹å®ä¾‹ä»¥å¢åŠ å¤šæ ·æ€§
analytical_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
creative_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.9)
practical_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

class State(TypedDict):
    messages: Annotated[list[BaseMessage], operator.add]
    topic: str
    analytical_research: str
    creative_research: str
    practical_research: str

def fan_out_to_researchers(state: State) -> list[Send]:
    return [
        Send("researcher_analytical", state),
        Send("researcher_creative", state),
        Send("researcher_practical", state),
    ]

def dispatcher(state: State) -> dict:
    last_message = state["messages"][-1] if state["messages"] else None
    topic = last_message.content if last_message else ""
    return {"topic": topic}

async def researcher_analytical(state: State) -> dict:
    response = await analytical_model.ainvoke([
        {"role": "system", "content": "You are an analytical research expert."},
        {"role": "user", "content": f"Research: {state['topic']}"},
    ])
    return {
        "analytical_research": response.content,
        "messages": [AIMessage(content=response.content, name="researcher_analytical")],
    }

# ä¸ºåˆ›æ„å‹å’Œå®ç”¨å‹ç ”ç©¶å‘˜å®šä¹‰ç±»ä¼¼çš„èŠ‚ç‚¹...

workflow = StateGraph(State)
workflow.add_node("dispatcher", dispatcher)
workflow.add_node("researcher_analytical", researcher_analytical)
workflow.add_node("researcher_creative", researcher_creative)
workflow.add_node("researcher_practical", researcher_practical)
workflow.add_edge(START, "dispatcher")
workflow.add_conditional_edges("dispatcher", fan_out_to_researchers)
workflow.add_edge("researcher_analytical", END)
workflow.add_edge("researcher_creative", END)
workflow.add_edge("researcher_practical", END)

agent: CompiledStateGraph = workflow.compile()
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState } from "./types";
import { MessageBubble } from "./MessageBubble";

// ç”¨äºè§†è§‰æ˜¾ç¤ºçš„èŠ‚ç‚¹é…ç½®
const NODE_CONFIG: Record<string, { label: string; color: string }> = {
  researcher_analytical: { label: "Analytical Research", color: "cyan" },
  researcher_creative: { label: "Creative Research", color: "purple" },
  researcher_practical: { label: "Practical Research", color: "emerald" },
};

function MultiAgentChat() {
  const stream = useStream<AgentState>({
    assistantId: "parallel-research",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type !== "ai") {
          return <MessageBubble key={message.id ?? idx} message={message} />;
        }

        const metadata = stream.getMessagesMetadata?.(message);
        const nodeName =
          (metadata?.streamMetadata?.langgraph_node as string) ||
          (message as { name?: string }).name;

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// çŠ¶æ€ä¸ä½ çš„ Python æ™ºèƒ½ä½“çš„ State TypedDict åŒ¹é…
export interface AgentState {
  messages: Message[];
  topic: string;
  analytical_research: string;
  creative_research: string;
  practical_research: string;
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { agent } from "./agent";
import { MessageBubble } from "./MessageBubble";

// ç”¨äºè§†è§‰æ˜¾ç¤ºçš„èŠ‚ç‚¹é…ç½®
const NODE_CONFIG: Record<string, { label: string; color: string }> = {
  researcher_analytical: { label: "åˆ†æç ”ç©¶", color: "cyan" },
  researcher_creative: { label: "åˆ›æ„ç ”ç©¶", color: "purple" },
  researcher_practical: { label: "å®ç”¨ç ”ç©¶", color: "emerald" },
};

function MultiAgentChat() {
  const stream = useStream<typeof agent>({
    assistantId: "parallel-research",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type !== "ai") {
          return <MessageBubble key={message.id ?? idx} message={message} />;
        }

        // è·å–æµå¼å…ƒæ•°æ®ä»¥è¯†åˆ«æºèŠ‚ç‚¹
        const metadata = stream.getMessagesMetadata?.(message);
        const nodeName =
          (metadata?.streamMetadata?.langgraph_node as string) ||
          (message as { name?: string }).name;

        const config = nodeName ? NODE_CONFIG[nodeName] : null;

        if (!config) {
          return <MessageBubble key={message.id ?? idx} message={message} />;
        }

        return (
          <div
            key={message.id ?? idx}
            className={`bg-${config.color}-950/30 border border-${config.color}-500/30 rounded-xl p-4`}
          >
            <div className={`text-sm font-semibold text-${config.color}-400 mb-2`}>
              {config.label}
            </div>
            <div className="text-neutral-200 whitespace-pre-wrap">
              {typeof message.content === "string" ? message.content : ""}
            </div>
          </div>
        );
      })}
    </div>
  );
}
```

```typescript agent.ts
import { ChatOpenAI } from "@langchain/openai";
import { StateGraph, START, END, Send } from "@langchain/langgraph";
import { withLangGraph } from "@langchain/langgraph/zod";
import { BaseMessage, AIMessage } from "@langchain/core/messages";
import { z } from "zod";

// ä½¿ç”¨ä¸åŒçš„æ¨¡å‹å®ä¾‹ä»¥è·å¾—å¤šæ ·æ€§
const analyticalModel = new ChatOpenAI({ model: "gpt-4o-mini", temperature: 0.3 });
const creativeModel = new ChatOpenAI({ model: "gpt-4o-mini", temperature: 0.9 });
const practicalModel = new ChatOpenAI({ model: "gpt-4o-mini", temperature: 0.5 });

// å®šä¹‰çŠ¶æ€æ¨¡å¼
const StateAnnotation = z.object({
  messages: withLangGraph(z.custom<BaseMessage[]>(), {
    reducer: {
      fn: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) =>
        Array.isArray(right) ? left.concat(right) : left.concat([right]),
    },
    default: () => [],
  }),
  topic: z.string().default(""),
  analyticalResearch: z.string().default(""),
  creativeResearch: z.string().default(""),
  practicalResearch: z.string().default(""),
});

type State = z.infer<typeof StateAnnotation>;

// æ‰‡å‡ºåˆ°å¹¶è¡Œç ”ç©¶äººå‘˜
function fanOutToResearchers(state: State): Send[] {
  return [
    new Send("researcher_analytical", state),
    new Send("researcher_creative", state),
    new Send("researcher_practical", state),
  ];
}

async function dispatcherNode(state: State): Promise<Partial<State>> {
  const lastMessage = state.messages.at(-1);
  const topic = typeof lastMessage?.content === "string" ? lastMessage.content : "";
  return { topic };
}

async function analyticalResearcherNode(state: State): Promise<Partial<State>> {
  const response = await analyticalModel.invoke([
    { role: "system", content: "ä½ æ˜¯ä¸€ä½åˆ†æç ”ç©¶ä¸“å®¶ã€‚ä¸“æ³¨äºæ•°æ®å’Œè¯æ®ã€‚" },
    { role: "user", content: `ç ”ç©¶ä¸»é¢˜: ${state.topic}` },
  ]);
  return {
    analyticalResearch: response.content as string,
    messages: [new AIMessage({ content: response.content as string, name: "researcher_analytical" })],
  };
}

// åˆ›æ„å‹å’Œå®ç”¨å‹ç ”ç©¶äººå‘˜çš„ç±»ä¼¼èŠ‚ç‚¹...

// æ„å»ºæ”¯æŒå¹¶è¡Œæ‰§è¡Œçš„å›¾
const workflow = new StateGraph(StateAnnotation)
  .addNode("dispatcher", dispatcherNode)
  .addNode("researcher_analytical", analyticalResearcherNode)
  .addNode("researcher_creative", creativeResearcherNode)
  .addNode("researcher_practical", practicalResearcherNode)
  .addEdge(START, "dispatcher")
  .addConditionalEdges("dispatcher", fanOutToResearchers)
  .addEdge("researcher_analytical", END)
  .addEdge("researcher_creative", END)
  .addEdge("researcher_practical", END);

export const agent = workflow.compile();
```

</CodeGroup>
:::

<Card title="å°è¯•å¹¶è¡Œç ”ç©¶ç¤ºä¾‹" icon="users" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/parallel-research">
  åœ¨ `parallel-research` ç¤ºä¾‹ä¸­æŸ¥çœ‹ä¸€ä¸ªå®Œæ•´çš„å¤šæ™ºèƒ½ä½“æµå¼å¤„ç†å®ç°ï¼ŒåŒ…å«ä¸‰ä¸ªå¹¶è¡Œç ”ç©¶äººå‘˜å’Œç‹¬ç‰¹çš„è§†è§‰æ ·å¼ã€‚
</Card>

## äººæœºååŒï¼ˆHuman-in-the-loopï¼‰

å½“æ™ºèƒ½ä½“éœ€è¦äººå·¥æ‰¹å‡†æ‰èƒ½æ‰§è¡Œå·¥å…·æ—¶ï¼Œå¤„ç†ä¸­æ–­ã€‚åœ¨[å¦‚ä½•å¤„ç†ä¸­æ–­](/oss/langgraph/interrupts#pause-using-interrupt)æŒ‡å—ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚

:::python
<CodeGroup>

```python agent.py
from langchain import create_agent, tool, human_in_the_loop_middleware
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver

model = ChatOpenAI(model="gpt-4o-mini")

@tool
def send_email(to: str, subject: str, body: str) -> dict:
    """å‘é€ç”µå­é‚®ä»¶ã€‚éœ€è¦äººå·¥æ‰¹å‡†ã€‚"""
    return {
        "status": "success",
        "content": f'å·²å‘ {to} å‘é€ä¸»é¢˜ä¸º "{subject}" çš„é‚®ä»¶',
    }

@tool
def delete_file(path: str) -> dict:
    """åˆ é™¤æ–‡ä»¶ã€‚éœ€è¦äººå·¥æ‰¹å‡†ã€‚"""
    return {"status": "success", "content": f'æ–‡ä»¶ "{path}" å·²åˆ é™¤'}

@tool
def read_file(path: str) -> dict:
    """è¯»å–æ–‡ä»¶å†…å®¹ã€‚æ— éœ€æ‰¹å‡†ã€‚"""
    return {"status": "success", "content": f"{path} çš„å†…å®¹..."}

agent = create_agent(
    model=model,
    tools=[send_email, delete_file, read_file],
    middleware=[
        human_in_the_loop_middleware(
            interrupt_on={
                "send_email": {
                    "allowed_decisions": ["approve", "edit", "reject"],
                    "description": "ğŸ“§ å‘é€å‰å®¡æ ¸é‚®ä»¶",
                },
                "delete_file": {
                    "allowed_decisions": ["approve", "reject"],
                    "description": "ğŸ—‘ï¸ ç¡®è®¤æ–‡ä»¶åˆ é™¤",
                },
                "read_file": False,  // å®‰å…¨ - è‡ªåŠ¨æ‰¹å‡†
            }
        ),
    ],
    checkpointer=MemorySaver(),
)
```

```tsx Chat.tsx
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState, HITLRequest, HITLResponse } from "./types";
import { MessageBubble } from "./MessageBubble";

function HumanInTheLoopChat() {
  const stream = useStream<AgentState, { InterruptType: HITLRequest }>({
    assistantId: "human-in-the-loop",
    apiUrl: "http://localhost:2024",
  });

  const [isProcessing, setIsProcessing] = useState(false);
  const hitlRequest = stream.interrupt?.value as HITLRequest | undefined;

  const handleApprove = async (index: number) => {
    if (!hitlRequest) return;
    setIsProcessing(true);

    try {
      const decisions: HITLResponse["decisions"] =
        hitlRequest.actionRequests.map((_, i) =>
          i === index ? { type: "approve" } : { type: "approve" }
        );

      await stream.submit(null, {
        command: { resume: { decisions } as HITLResponse },
      });
    } finally {
      setIsProcessing(false);
    }
  };

  const handleReject = async (index: number, reason: string) => {
    if (!hitlRequest) return;
    setIsProcessing(true);

    try {
      const decisions: HITLResponse["decisions"] =
        hitlRequest.actionRequests.map((_, i) =>
          i === index
            ? { type: "reject", message: reason }
            : { type: "reject", message: "Rejected along with other actions" }
        );

      await stream.submit(null, {
        command: { resume: { decisions } as HITLResponse },
      });
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div>
      {stream.messages.map((message, idx) => (
        <MessageBubble key={message.id ?? idx} message={message} />
      ))}

      {hitlRequest && hitlRequest.actionRequests.length > 0 && (
        <div className="bg-amber-900/20 border border-amber-500/30 rounded-xl p-4 mt-4">
          <h3 className="text-amber-400 font-semibold mb-4">
            æ“ä½œéœ€è¦æ‰¹å‡†
          </h3>

          {hitlRequest.actionRequests.map((action, idx) => (
            <div key={idx} className="bg-neutral-900 rounded-lg p-4 mb-4 last:mb-0">
              <div className="text-sm font-mono text-white mb-2">{action.name}</div>
              <pre className="text-xs bg-black rounded p-2 mb-3 overflow-x-auto">
                {JSON.stringify(action.args, null, 2)}
              </pre>
              <div className="flex gap-2">
                <button
                  onClick={() => handleApprove(idx)}
                  disabled={isProcessing}
                  className="px-3 py-1.5 bg-green-600 hover:bg-green-500 text-white text-sm rounded-lg"
                >
                  æ‰¹å‡†
                </button>
                <button
                  onClick={() => handleReject(idx, "ç”¨æˆ·å·²æ‹’ç»")}
                  disabled={isProcessing}
                  className="px-3 py-1.5 bg-red-600 hover:bg-red-500 text-white text-sm rounded-lg"
                >
                  æ‹’ç»
                </button>
              </div>
            </div>
          ))}
        </div>
      )}
    </div>
  );
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

// ä¸æ‚¨çš„ Python æ™ºèƒ½ä½“åŒ¹é…çš„å·¥å…·è°ƒç”¨ç±»å‹
export type SendEmailToolCall = {
  name: "send_email";
  args: { to: string; subject: string; body: string };
  id?: string;
};

export type DeleteFileToolCall = {
  name: "delete_file";
  args: { path: string };
  id?: string;
};

export type ReadFileToolCall = {
  name: "read_file";
  args: { path: string };
  id?: string;
};

export type AgentToolCalls = SendEmailToolCall | DeleteFileToolCall | ReadFileToolCall;

export interface AgentState {
  messages: Message<AgentToolCalls>[];
}

// äººæœºååŒï¼ˆHITLï¼‰ç±»å‹
export interface HITLRequest {
  actionRequests: Array<{
    name: string;
    args: Record<string, unknown>;
  }>;
}

export interface HITLResponse {
  decisions: Array<
    | { type: "approve" }
    | { type: "reject"; message: string }
    | { type: "edit"; newArgs: Record<string, unknown> }
  >;
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```tsx Chat.tsx
import { useState } from "react";
import { useStream } from "@langchain/langgraph-sdk/react";
import type { HITLRequest, HITLResponse } from "langchain";
import type { agent } from "./agent";
import { MessageBubble } from "./MessageBubble";

function HumanInTheLoopChat() {
  const stream = useStream<typeof agent, { InterruptType: HITLRequest }>({
    assistantId: "human-in-the-loop",
    apiUrl: "http://localhost:2024",
  });

  const [isProcessing, setIsProcessing] = useState(false);

  // å¯¹ä¸­æ–­å€¼çš„ç±»å‹æ–­è¨€
  const hitlRequest = stream.interrupt?.value as HITLRequest | undefined;

  const handleApprove = async (index: number) => {
    if (!hitlRequest) return;
    setIsProcessing(true);

    try {
      const decisions: HITLResponse["decisions"] =
        hitlRequest.actionRequests.map((_, i) =>
          i === index ? { type: "approve" } : { type: "approve" }
        );

      await stream.submit(null, {
        command: {
          resume: { decisions } as HITLResponse,
        },
      });
    } finally {
      setIsProcessing(false);
    }
  };

  const handleReject = async (index: number, reason: string) => {
    if (!hitlRequest) return;
    setIsProcessing(true);

    try {
      const decisions: HITLResponse["decisions"] =
        hitlRequest.actionRequests.map((_, i) =>
          i === index
            ? { type: "reject", message: reason }
            : { type: "reject", message: "Rejected along with other actions" }
        );

      await stream.submit(null, {
        command: {
          resume: { decisions } as HITLResponse,
        },
      });
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div>
      {/* æ¸²æŸ“æ¶ˆæ¯ */}
      {stream.messages.map((message, idx) => (
        <MessageBubble key={message.id ?? idx} message={message} />
      ))}

      {/* ä¸­æ–­æ—¶æ¸²æŸ“å®¡æ‰¹ç•Œé¢ */}
      {hitlRequest && hitlRequest.actionRequests.length > 0 && (
        <div className="bg-amber-900/20 border border-amber-500/30 rounded-xl p-4 mt-4">
          <h3 className="text-amber-400 font-semibold mb-4">
            æ“ä½œéœ€è¦å®¡æ‰¹
          </h3>

          {hitlRequest.actionRequests.map((action, idx) => (
            <div
              key={idx}
              className="bg-neutral-900 rounded-lg p-4 mb-4 last:mb-0"
            >
              <div className="flex items-center gap-2 mb-2">
                <span className="text-sm font-mono text-white">
                  {action.name}
                </span>
              </div>

              <pre className="text-xs bg-black rounded p-2 mb-3 overflow-x-auto">
                {JSON.stringify(action.args, null, 2)}
              </pre>

              <div className="flex gap-2">
                <button
                  onClick={() => handleApprove(idx)}
                  disabled={isProcessing}
                  className="px-3 py-1.5 bg-green-600 hover:bg-green-700 text-white text-sm rounded disabled:opacity-50"
                >
                  æ‰¹å‡†
                </button>
                <button
                  onClick={() => handleReject(idx, "User rejected")}
                  disabled={isProcessing}
                  className="px-3 py-1.5 bg-red-600 hover:bg-red-700 text-white text-sm rounded disabled:opacity-50"
                >
                  æ‹’ç»
                </button>
              </div>
            </div>
          ))}
        </div>
      )}
    </div>
  );
}
```

```typescript agent.ts
import { createAgent, tool, humanInTheLoopMiddleware } from "langchain";
import { ChatOpenAI } from "@langchain/openai";
import { MemorySaver } from "@langchain/langgraph";
import { z } from "zod";

const model = new ChatOpenAI({ model: "gpt-4o-mini" });

// éœ€è¦äººå·¥æ‰¹å‡†çš„å·¥å…·
const sendEmail = tool(
  async ({ to, subject, body }) => {
    return {
      status: "success",
      content: `Email sent to ${to} with subject "${subject}"`,
    };
  },
  {
    name: "send_email",
    description: "å‘é€ç”µå­é‚®ä»¶ã€‚éœ€è¦äººå·¥æ‰¹å‡†ã€‚",
    schema: z.object({
      to: z.string().describe("æ”¶ä»¶äººé‚®ç®±åœ°å€"),
      subject: z.string().describe("é‚®ä»¶ä¸»é¢˜"),
      body: z.string().describe("é‚®ä»¶æ­£æ–‡"),
    }),
  }
);

// éœ€è¦æ‰¹å‡†ä¸”é€‰é¡¹æœ‰é™çš„å·¥å…·
const deleteFile = tool(
  async ({ path }) => {
    return { status: "success", content: `File "${path}" deleted` };
  },
  {
    name: "delete_file",
    description: "åˆ é™¤æ–‡ä»¶ã€‚éœ€è¦äººå·¥æ‰¹å‡†ã€‚",
    schema: z.object({
      path: z.string().describe("è¦åˆ é™¤çš„æ–‡ä»¶è·¯å¾„"),
    }),
  }
);

// å®‰å…¨å·¥å…· - æ— éœ€æ‰¹å‡†
const readFile = tool(
  async ({ path }) => {
    return { status: "success", content: `Contents of ${path}...` };
  },
  {
    name: "read_file",
    description: "è¯»å–æ–‡ä»¶å†…å®¹ã€‚æ— éœ€æ‰¹å‡†ã€‚",
    schema: z.object({
      path: z.string().describe("è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„"),
    }),
  }
);

// åˆ›å»ºå¸¦æœ‰äººæœºååŒï¼ˆhuman-in-the-loopï¼‰ä¸­é—´ä»¶çš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰
export const agent = createAgent({
  model,
  tools: [sendEmail, deleteFile, readFile],
  middleware: [
    humanInTheLoopMiddleware({
      interruptOn: {
        // ç”µå­é‚®ä»¶éœ€è¦æ‰€æœ‰å†³ç­–ç±»å‹
        send_email: {
          allowedDecisions: ["approve", "edit", "reject"],
          description: "ğŸ“§ å‘é€å‰å®¡æ ¸é‚®ä»¶",
        },
        // åˆ é™¤æ“ä½œä»…å…è®¸æ‰¹å‡†/æ‹’ç»
        delete_file: {
          allowedDecisions: ["approve", "reject"],
          description: "ğŸ—‘ï¸ ç¡®è®¤æ–‡ä»¶åˆ é™¤",
        },
        // è¯»å–æ“ä½œæ˜¯å®‰å…¨çš„ - è‡ªåŠ¨æ‰¹å‡†
        read_file: false,
      },
    }),
  ],
  // äººæœºååŒï¼ˆhuman-in-the-loopï¼‰å¿…éœ€ - åœ¨ä¸­æ–­æœŸé—´æŒä¹…åŒ–çŠ¶æ€
  checkpointer: new MemorySaver(),
});
```

</CodeGroup>
:::

<Card title="å°è¯•äººæœºååŒï¼ˆhuman-in-the-loopï¼‰ç¤ºä¾‹" icon="hand" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/human-in-the-loop">
  åœ¨ `human-in-the-loop` ç¤ºä¾‹ä¸­æŸ¥çœ‹åŒ…å«æ‰¹å‡†ã€æ‹’ç»å’Œç¼–è¾‘æ“ä½œçš„å®Œæ•´å®¡æ‰¹å·¥ä½œæµå®ç°ã€‚
</Card>

## æ¨ç†æ¨¡å‹

<Warning>
æ‰©å±•æ¨ç†/æ€è€ƒæ”¯æŒç›®å‰å¤„äºå®éªŒé˜¶æ®µã€‚æ¨ç†ä»¤ç‰Œï¼ˆreasoning tokensï¼‰çš„æµå¼æ¥å£å› æä¾›å•†ï¼ˆOpenAI ä¸ Anthropicï¼‰è€Œå¼‚ï¼Œå¹¶å¯èƒ½éšç€æŠ½è±¡å±‚çš„å¼€å‘è€Œæ”¹å˜ã€‚
</Warning>

å½“ä½¿ç”¨å…·æœ‰æ‰©å±•æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼ˆå¦‚ OpenAI çš„æ¨ç†æ¨¡å‹æˆ– Anthropic çš„æ‰©å±•æ€è€ƒï¼‰æ—¶ï¼Œæ€è€ƒè¿‡ç¨‹ä¼šåµŒå…¥åˆ°æ¶ˆæ¯å†…å®¹ä¸­ã€‚æ‚¨éœ€è¦å•ç‹¬æå–å¹¶æ˜¾ç¤ºå®ƒã€‚

:::python
<CodeGroup>

```python agent.py
from langchain import create_agent
from langchain_openai import ChatOpenAI

# ä½¿ç”¨å…·å¤‡æ¨ç†èƒ½åŠ›çš„æ¨¡å‹
# OpenAI: o1, o1-mini, o1-preview
# Anthropic: å¯ç”¨æ‰©å±•æ€è€ƒçš„ claude-sonnet-4-20250514
model = ChatOpenAI(model="o1-mini")

agent = create_agent(
    model=model,
    tools=[],  # æ¨ç†æ¨¡å‹æœ€é€‚åˆå¤æ‚çš„æ¨ç†ä»»åŠ¡
)
```

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { AgentState } from "./types";
import { getReasoningFromMessage, getTextContent } from "./utils";
import { MessageBubble } from "./MessageBubble";

function ReasoningChat() {
  const stream = useStream<AgentState>({
    assistantId: "reasoning-agent",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type === "ai") {
          const reasoning = getReasoningFromMessage(message);
          const textContent = getTextContent(message);

return (
            <div key={message.id ?? idx}>
              {reasoning && (
                <div className="mb-4">
                  <div className="text-xs font-medium text-amber-400/80 mb-2">
                    æ¨ç†è¿‡ç¨‹
                  </div>
                  <div className="bg-amber-950/50 border border-amber-500/20 rounded-2xl px-4 py-3">
                    <div className="text-sm text-amber-100/90 whitespace-pre-wrap">
                      {reasoning}
                    </div>
                  </div>
                </div>
              )}

              {textContent && (
                <div className="text-neutral-100 whitespace-pre-wrap">
                  {textContent}
                </div>
              )}
            </div>
          );
        }

        return <MessageBubble key={message.id ?? idx} message={message} />;
      })}

      {stream.isLoading && (
        <div className="flex items-center gap-2 text-amber-400/70">
          <span className="text-sm">æ€è€ƒä¸­...</span>
        </div>
      )}
    </div>
  );
}
```

```typescript types.ts
import type { Message } from "@langchain/langgraph-sdk";

export interface AgentState {
  messages: Message[];
}
```

```typescript utils.ts
import type { Message, AIMessage } from "@langchain/langgraph-sdk";

/**
 * ä» AI æ¶ˆæ¯ä¸­æå–æ¨ç†/æ€è€ƒå†…å®¹ã€‚
 * åŒæ—¶æ”¯æŒ OpenAI æ¨ç†å’Œ Anthropic æ‰©å±•æ€è€ƒã€‚
 */
export function getReasoningFromMessage(message: Message): string | undefined {
  type MessageWithExtras = AIMessage & {
    additional_kwargs?: {
      reasoning?: {
        summary?: Array<{ type: string; text: string }>;
      };
    };
    contentBlocks?: Array<{ type: string; thinking?: string }>;
  };

  const msg = message as MessageWithExtras;

  // æ£€æŸ¥ additional_kwargs ä¸­æ˜¯å¦å­˜åœ¨ OpenAI æ¨ç†
  if (msg.additional_kwargs?.reasoning?.summary) {
    const content = msg.additional_kwargs.reasoning.summary
      .filter((item) => item.type === "summary_text")
      .map((item) => item.text)
      .join("");
    if (content.trim()) return content;
  }

  // æ£€æŸ¥ contentBlocks ä¸­æ˜¯å¦å­˜åœ¨ Anthropic æ€è€ƒ
  if (msg.contentBlocks?.length) {
    const thinking = msg.contentBlocks
      .filter((b) => b.type === "thinking" && b.thinking)
      .map((b) => b.thinking)
      .join("\n");
    if (thinking) return thinking;
  }

  // æ£€æŸ¥ message.content æ•°ç»„ä¸­æ˜¯å¦å­˜åœ¨æ€è€ƒå†…å®¹
  if (Array.isArray(msg.content)) {
    const thinking = msg.content
      .filter((b): b is { type: "thinking"; thinking: string } =>
        typeof b === "object" && b?.type === "thinking" && "thinking" in b
      )
      .map((b) => b.thinking)
      .join("\n");
    if (thinking) return thinking;
  }

  return undefined;
}

/**
 * ä»æ¶ˆæ¯ä¸­æå–æ–‡æœ¬å†…å®¹ã€‚
 */
export function getTextContent(message: Message): string {
  if (typeof message.content === "string") return message.content;
  if (Array.isArray(message.content)) {
    return message.content
      .filter((c): c is { type: "text"; text: string } => c.type === "text")
      .map((c) => c.text)
      .join("");
  }
  return "";
}
```

</CodeGroup>
:::

:::js
<CodeGroup>

```tsx Chat.tsx
import { useStream } from "@langchain/langgraph-sdk/react";
import type { Message } from "@langchain/langgraph-sdk";
import type { agent } from "./agent";
import { getReasoningFromMessage, getTextContent } from "./utils";

function ReasoningChat() {
  const stream = useStream<typeof agent>({
    assistantId: "reasoning-agent",
    apiUrl: "http://localhost:2024",
  });

  return (
    <div className="flex flex-col gap-4">
      {stream.messages.map((message, idx) => {
        if (message.type === "ai") {
          const reasoning = getReasoningFromMessage(message);
          const textContent = getTextContent(message);

return (
  <div key={message.id ?? idx}>
    {/* å¦‚æœå­˜åœ¨æ¨ç†å†…å®¹åˆ™æ¸²æŸ“æ¨ç†æ°”æ³¡ */}
    {reasoning && (
      <div className="mb-4">
        <div className="text-xs font-medium text-amber-400/80 mb-2">
          æ¨ç†
        </div>
        <div className="bg-amber-950/50 border border-amber-500/20 rounded-2xl px-4 py-3">
          <div className="text-sm text-amber-100/90 whitespace-pre-wrap">
            {reasoning}
          </div>
        </div>
      </div>
    )}

    {/* æ¸²æŸ“æ–‡æœ¬å†…å®¹ */}
    {textContent && (
      <div className="text-neutral-100 whitespace-pre-wrap">
        {textContent}
      </div>
    )}
  </div>
);
}

return <MessageBubble key={message.id ?? idx} message={message} />;
})}

{stream.isLoading && (
<div className="flex items-center gap-2 text-amber-400/70">
  <span className="text-sm">æ€è€ƒä¸­...</span>
</div>
)}
</div>
);
}
```

```typescript utils.ts
import type { Message, AIMessage } from "@langchain/langgraph-sdk";

/**
 * ä» AI æ¶ˆæ¯ä¸­æå–æ¨ç†/æ€è€ƒå†…å®¹ã€‚
 * åŒæ—¶æ”¯æŒ OpenAI æ¨ç† (additional_kwargs.reasoning.summary)
 * å’Œ Anthropic æ‰©å±•æ€è€ƒ (ç±»å‹ä¸º "thinking" çš„å†…å®¹å—)ã€‚
 */
export function getReasoningFromMessage(message: Message): string | undefined {
  type MessageWithExtras = AIMessage & {
    additional_kwargs?: {
      reasoning?: {
        summary?: Array<{ type: string; text: string }>;
      };
    };
    contentBlocks?: Array<{ type: string; thinking?: string }>;
  };

  const msg = message as MessageWithExtras;

  // æ£€æŸ¥ additional_kwargs ä¸­æ˜¯å¦å­˜åœ¨ OpenAI æ¨ç†
  if (msg.additional_kwargs?.reasoning?.summary) {
    const content = msg.additional_kwargs.reasoning.summary
      .filter((item) => item.type === "summary_text")
      .map((item) => item.text)
      .join("");

    if (content.trim()) return content;
  }

  // æ£€æŸ¥ contentBlocks ä¸­æ˜¯å¦å­˜åœ¨ Anthropic æ€è€ƒ
  if (msg.contentBlocks?.length) {
    const thinking = msg.contentBlocks
      .filter((b) => b.type === "thinking" && b.thinking)
      .map((b) => b.thinking)
      .join("\n");

    if (thinking) return thinking;
  }

  // æ£€æŸ¥ message.content æ•°ç»„ä¸­æ˜¯å¦å­˜åœ¨æ€è€ƒå†…å®¹
  if (Array.isArray(msg.content)) {
    const thinking = msg.content
      .filter((b): b is { type: "thinking"; thinking: string } =>
        typeof b === "object" && b?.type === "thinking" && "thinking" in b
      )
      .map((b) => b.thinking)
      .join("\n");

    if (thinking) return thinking;
  }

  return undefined;
}

/**
 * ä»æ¶ˆæ¯ä¸­æå–æ–‡æœ¬å†…å®¹ã€‚
 */
export function getTextContent(message: Message): string {
  if (typeof message.content === "string") return message.content;

  if (Array.isArray(message.content)) {
    return message.content
      .filter((c): c is { type: "text"; text: string } => c.type === "text")
      .map((c) => c.text)
      .join("");
  }

  return "";
}
```

</CodeGroup>
:::

<Card title="å°è¯•æ¨ç†ç¤ºä¾‹" icon="brain" href="https://github.com/langchain-ai/langgraphjs/tree/main/examples/ui-react/src/examples/reasoning-agent">
  åœ¨ `reasoning-agent` ç¤ºä¾‹ä¸­æŸ¥çœ‹ä½¿ç”¨ OpenAI å’Œ Anthropic æ¨¡å‹å±•ç¤ºæ¨ç†ä»¤ç‰Œçš„å®Œæ•´å®ç°ã€‚
</Card>

## è‡ªå®šä¹‰çŠ¶æ€ç±»å‹

å¯¹äºè‡ªå®šä¹‰çš„ LangGraph åº”ç”¨ç¨‹åºï¼Œè¯·å°†æ‚¨çš„å·¥å…·è°ƒç”¨ç±»å‹åµŒå…¥åˆ°çŠ¶æ€çš„ messages å±æ€§ä¸­ã€‚

:::js
```tsx
import { Message } from "@langchain/langgraph-sdk";
import { useStream } from "@langchain/langgraph-sdk/react";

// å°†æ‚¨çš„å·¥å…·è°ƒç”¨ç±»å‹å®šä¹‰ä¸ºå¯è¾¨è¯†è”åˆç±»å‹
type MyToolCalls =
  | { name: "search"; args: { query: string }; id?: string }
  | { name: "calculate"; args: { expression: string }; id?: string };

// åœ¨çŠ¶æ€æ¶ˆæ¯ä¸­åµŒå…¥å·¥å…·è°ƒç”¨ç±»å‹
interface MyGraphState {
  messages: Message<MyToolCalls>[];
  context?: string;
}

function CustomGraphChat() {
  const stream = useStream<MyGraphState>({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.values è¢«ç±»å‹åŒ–ä¸º MyGraphState
  // stream.toolCalls[0].call.name è¢«ç±»å‹åŒ–ä¸º "search" | "calculate"
}
```

ä½ ä¹Ÿå¯ä»¥ä¸ºä¸­æ–­ï¼ˆinterruptsï¼‰å’Œå¯é…ç½®é€‰é¡¹æŒ‡å®šé¢å¤–çš„ç±»å‹é…ç½®ï¼š

```tsx
interface MyGraphState {
  messages: Message<MyToolCalls>[];
}

function CustomGraphChat() {
  const stream = useStream<
    MyGraphState,
    {
      InterruptType: { question: string };
      ConfigurableType: { userId: string };
    }
  >({
    assistantId: "my-graph",
    apiUrl: "http://localhost:2024",
  });

  // stream.interrupt è¢«ç±»å‹åŒ–ä¸º { question: string } | undefined
}
```
:::

## è‡ªå®šä¹‰ä¼ è¾“

å¯¹äºè‡ªå®šä¹‰ API ç«¯ç‚¹æˆ–éæ ‡å‡†éƒ¨ç½²ï¼Œå¯ä»¥ä½¿ç”¨ `transport` é€‰é¡¹é…åˆ `FetchStreamTransport` æ¥è¿æ¥åˆ°ä»»ä½•æµå¼ APIã€‚

:::js
```tsx
import { useMemo } from "react";
import { useStream, FetchStreamTransport } from "@langchain/langgraph-sdk/react";

function CustomAPIChat({ apiKey }: { apiKey: string }) {
  // åˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰è¯·æ±‚å¤„ç†çš„ä¼ è¾“å™¨
  const transport = useMemo(() => {
    return new FetchStreamTransport({
      apiUrl: "/api/my-agent",
      onRequest: async (url: string, init: RequestInit) => {
        // å°† API å¯†é’¥æˆ–å…¶ä»–è‡ªå®šä¹‰æ•°æ®æ³¨å…¥è¯·æ±‚
        const customBody = JSON.stringify({
          ...(JSON.parse(init.body as string) || {}),
          apiKey,
        });

        return {
          ...init,
          body: customBody,
          headers: {
            ...init.headers,
            "X-Custom-Header": "value",
          },
        };
      },
    });
  }, [apiKey]);

  const stream = useStream({
    transport,
  });

  // æ­£å¸¸ä½¿ç”¨ stream
  return (
    <div>
      {stream.messages.map((message, idx) => (
        <MessageBubble key={message.id ?? idx} message={message} />
      ))}
    </div>
  );
}
```
:::

## ç›¸å…³

- [æµå¼å¤„ç†æ¦‚è¿°](/oss/langchain/streaming/overview) â€” ä½¿ç”¨ LangChain æ™ºèƒ½ä½“è¿›è¡ŒæœåŠ¡å™¨ç«¯æµå¼å¤„ç†
- [useStream API å‚è€ƒ](https://reference.langchain.com/javascript/functions/_langchain_langgraph-sdk.react.useStream.html) â€” å®Œæ•´çš„ API æ–‡æ¡£
- [æ™ºèƒ½ä½“èŠå¤©ç•Œé¢](/oss/langchain/ui) â€” LangGraph æ™ºèƒ½ä½“çš„é¢„æ„å»ºèŠå¤©ç•Œé¢
- [äººæœºååŒ](/oss/langchain/human-in-the-loop) â€” é…ç½®äººå·¥å®¡æ ¸çš„ä¸­æ–­
- [å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ](/oss/langchain/multi-agent) â€” æ„å»ºä½¿ç”¨å¤šä¸ª LLM çš„æ™ºèƒ½ä½“
