---
title: LangChain è£…é¥°å™¨
---
~~~
å…è´£å£°æ˜ï¼š`LangChain decorators` å¹¶éç”± LangChain å›¢é˜Ÿåˆ›å»ºï¼Œä¹Ÿä¸å—å…¶æ”¯æŒã€‚
~~~

>`LangChain decorators` æ˜¯æ„å»ºåœ¨ LangChain ä¹‹ä¸Šçš„ä¸€ä¸ªå±‚ï¼Œå®ƒä¸ºç¼–å†™è‡ªå®šä¹‰çš„ langchain æç¤ºè¯ï¼ˆpromptsï¼‰å’Œé“¾ï¼ˆchainsï¼‰æä¾›äº†è¯­æ³•ç³– ğŸ­ã€‚
>
>å¦‚éœ€åé¦ˆã€æŠ¥å‘Šé—®é¢˜æˆ–è´¡çŒ®ä»£ç ï¼Œè¯·åœ¨æ­¤å¤„æäº¤ issueï¼š
>[ju-bezdek/langchain-decorators](https://github.com/ju-bezdek/langchain-decorators)

ä¸»è¦åŸåˆ™å’Œä¼˜åŠ¿ï¼š

- æ›´ `pythonic` çš„ä»£ç ç¼–å†™æ–¹å¼
- ç¼–å†™å¤šè¡Œæç¤ºè¯ï¼Œä¸ä¼šå› ç¼©è¿›è€Œç ´åä»£ç æµç¨‹
- åˆ©ç”¨ IDE å†…ç½®çš„**æç¤º**ã€**ç±»å‹æ£€æŸ¥**å’Œ**æ–‡æ¡£å¼¹çª—**æ”¯æŒï¼Œå¿«é€ŸæŸ¥çœ‹å‡½æ•°å†…éƒ¨çš„æç¤ºè¯ã€æ¶ˆè€—çš„å‚æ•°ç­‰
- å……åˆ†åˆ©ç”¨ ğŸ¦œğŸ”— LangChain ç”Ÿæ€ç³»ç»Ÿçš„æ‰€æœ‰åŠŸèƒ½
- å¢åŠ å¯¹**å¯é€‰å‚æ•°**çš„æ”¯æŒ
- é€šè¿‡å°†å‚æ•°ç»‘å®šåˆ°ä¸€ä¸ªç±»ï¼Œè½»æ¾åœ°åœ¨æç¤ºè¯ä¹‹é—´å…±äº«å‚æ•°

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ **LangChain Decorators âœ¨** ç¼–å†™çš„ç®€å•ä»£ç ç¤ºä¾‹ï¼š

``` python
@llm_prompt
def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers")->str:
    """
    Write me a short header for my post about {topic} for {platform} platform.
    It should be for {audience} audience.
    (Max 15 words)
    """
    return

# run it naturally
write_me_short_post(topic="starwars")
# or
write_me_short_post(topic="starwars", platform="redit")
```

# å¿«é€Ÿå¼€å§‹

## å®‰è£…

<CodeGroup>
```bash
pip install langchain_decorators
```

```bash uv
uv add langchain_decorators
```
</CodeGroup>

## ç¤ºä¾‹

äº†è§£å¦‚ä½•å¼€å§‹çš„ä¸€ä¸ªå¥½æ–¹æ³•æ˜¯æŸ¥çœ‹è¿™é‡Œçš„ç¤ºä¾‹ï¼š
    - [jupyter notebook](https://github.com/ju-bezdek/langchain-decorators/blob/main/example_notebook.ipynb)
    - [colab notebook](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=N4cf__D0E2Yk)

# å®šä¹‰å…¶ä»–å‚æ•°
åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªæ˜¯ç”¨ `llm_prompt` è£…é¥°å™¨å°†ä¸€ä¸ªå‡½æ•°æ ‡è®°ä¸ºæç¤ºè¯ï¼Œä»è€Œæœ‰æ•ˆåœ°å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª LLMChainã€‚è€Œä¸æ˜¯ç›´æ¥è¿è¡Œå®ƒã€‚

æ ‡å‡†çš„ LLMchain æ¥å—çš„åˆå§‹åŒ–å‚æ•°è¿œä¸æ­¢ `inputs_variables` å’Œ `prompt`... è¿™äº›å®ç°ç»†èŠ‚è¢«éšè—åœ¨è£…é¥°å™¨ä¸­ã€‚
å…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š

1. ä½¿ç”¨**å…¨å±€è®¾ç½®**ï¼š

``` python
# ä¸ºæ‰€æœ‰æç¤ºè¯å®šä¹‰å…¨å±€è®¾ç½®ï¼ˆå¦‚æœæœªè®¾ç½®ï¼ŒchatGPT æ˜¯å½“å‰çš„é»˜è®¤å€¼ï¼‰
from langchain_decorators import GlobalSettings

GlobalSettings.define_settings(
    default_llm=ChatOpenAI(temperature=0.0), # è¿™æ˜¯é»˜è®¤å€¼... å¯ä»¥åœ¨è¿™é‡Œå…¨å±€æ›´æ”¹
    default_streaming_llm=ChatOpenAI(temperature=0.0,streaming=True), # è¿™æ˜¯é»˜è®¤å€¼... å¯ä»¥åœ¨è¿™é‡Œä¸ºæ‰€æœ‰...æ›´æ”¹ï¼Œå°†ç”¨äºæµå¼å¤„ç†
)
```
2. ä½¿ç”¨é¢„å®šä¹‰çš„**æç¤ºè¯ç±»å‹**

``` python
# ä½ å¯ä»¥æ›´æ”¹é»˜è®¤çš„æç¤ºè¯ç±»å‹
from langchain_decorators import PromptTypes, PromptTypeSettings

PromptTypes.AGENT_REASONING.llm = ChatOpenAI()

# æˆ–è€…ä½ å¯ä»¥ç›´æ¥å®šä¹‰è‡ªå·±çš„ç±»å‹ï¼š
class MyCustomPromptTypes(PromptTypes):
    GPT4=PromptTypeSettings(llm=ChatOpenAI(model="gpt-4"))

@llm_prompt(prompt_type=MyCustomPromptTypes.GPT4)
def write_a_complicated_code(app_idea:str)->str:
    ...

```
3.  ç›´æ¥åœ¨è£…é¥°å™¨ä¸­å®šä¹‰è®¾ç½®

``` python
from langchain_openai import OpenAI

@llm_prompt(
    llm=OpenAI(temperature=0.7),
    stop_tokens=["\nObservation"],
    ...
    )
def creative_writer(book_title:str)->str:
    ...
```
## ä¼ é€’è®°å¿†ï¼ˆmemoryï¼‰å’Œ/æˆ–å›è°ƒï¼ˆcallbacksï¼‰ï¼š

è¦ä¼ é€’è¿™äº›å‚æ•°ä¸­çš„ä»»ä½•ä¸€ä¸ªï¼Œåªéœ€åœ¨å‡½æ•°ä¸­å£°æ˜å®ƒä»¬ï¼ˆæˆ–ä½¿ç”¨ kwargs ä¼ é€’ä»»ä½•å†…å®¹ï¼‰

```python

@llm_prompt()
async def write_me_short_post(topic:str, platform:str="twitter", memory:SimpleMemory = None):
    """
    {history_key}
    Write me a short header for my post about {topic} for {platform} platform.
    It should be for {audience} audience.
    (Max 15 words)
    """
    pass

await write_me_short_post(topic="old movies")

```
# ç®€åŒ–çš„æµå¼å¤„ç†

å¦‚æœæˆ‘ä»¬æƒ³åˆ©ç”¨æµå¼å¤„ç†ï¼š
 - éœ€è¦å°†æç¤ºè¯å‡½æ•°å®šä¹‰ä¸ºå¼‚æ­¥å‡½æ•°
 - åœ¨è£…é¥°å™¨ä¸Šå¼€å¯æµå¼å¤„ç†ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå¼€å¯æµå¼å¤„ç†çš„ PromptType
 - ä½¿ç”¨ StreamingContext æ•è·æµ

è¿™æ ·ï¼Œæˆ‘ä»¬åªéœ€æ ‡è®°å“ªäº›æç¤ºè¯åº”è¯¥è¢«æµå¼å¤„ç†ï¼Œè€Œä¸éœ€è¦è°ƒæ•´åº”è¯¥ä½¿ç”¨å“ªä¸ª LLMï¼Œä¹Ÿä¸éœ€è¦å°†åˆ›å»ºå’Œåˆ†å‘æµå¼å¤„ç†ç¨‹åºä¼ é€’åˆ°é“¾çš„ç‰¹å®šéƒ¨åˆ†... åªéœ€åœ¨æç¤ºè¯/æç¤ºè¯ç±»å‹ä¸Šå¼€å¯/å…³é—­æµå¼å¤„ç†...

æµå¼å¤„ç†åªä¼šåœ¨æˆ‘ä»¬äºæµå¼ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨å®ƒæ—¶å‘ç”Ÿ... åœ¨é‚£é‡Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥å¤„ç†æµ

``` python
# æ­¤ä»£ç ç¤ºä¾‹æ˜¯å®Œæ•´çš„ï¼Œåº”è¯¥å¯ä»¥ç›´æ¥è¿è¡Œ

from langchain_decorators import StreamingContext, llm_prompt

# è¿™å°†æ ‡è®°è¯¥æç¤ºè¯ç”¨äºæµå¼å¤„ç†ï¼ˆå¦‚æœæˆ‘ä»¬åªæƒ³åœ¨åº”ç”¨ä¸­æµå¼å¤„ç†æŸäº›æç¤ºè¯... ä½†åˆä¸æƒ³ä¼ é€’åˆ†å‘å›è°ƒå¤„ç†ç¨‹åºæ—¶å¾ˆæœ‰ç”¨ï¼‰
# æ³¨æ„åªæœ‰å¼‚æ­¥å‡½æ•°å¯ä»¥è¢«æµå¼å¤„ç†ï¼ˆå¦‚æœä¸æ˜¯å¼‚æ­¥å‡½æ•°ä¼šå‡ºé”™ï¼‰
@llm_prompt(capture_stream=True)
async def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers"):
    """
    Write me a short header for my post about {topic} for {platform} platform.
    It should be for {audience} audience.
    (Max 15 words)
    """
    pass



# åªæ˜¯ä¸€ä¸ªç”¨äºæ¼”ç¤ºæµå¼å¤„ç†çš„ä»»æ„å‡½æ•°... åœ¨çœŸå®åœºæ™¯ä¸­ä¼šæ˜¯æŸäº› websockets ä»£ç 
tokens=[]
def capture_stream_func(new_token:str):
    tokens.append(new_token)

# å¦‚æœæˆ‘ä»¬æƒ³æ•è·æµï¼Œéœ€è¦å°†æ‰§è¡ŒåŒ…è£…åœ¨ StreamingContext ä¸­...
# è¿™æ ·å³ä½¿æç¤ºè¯è°ƒç”¨éšè—åœ¨æ›´é«˜çº§çš„æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½æ•è·åˆ°æµ
# åªæœ‰æ ‡è®°äº† capture_stream çš„æç¤ºè¯æ‰ä¼šåœ¨è¿™é‡Œè¢«æ•è·
with StreamingContext(stream_to_stdout=True, callback=capture_stream_func):
    result = await run_prompt()
    print("Stream finished ... we can distinguish tokens thanks to alternating colors")


print("\nWe've captured",len(tokens),"tokensğŸ‰\n")
print("Here is the result:")
print(result)
```
# æç¤ºè¯å£°æ˜
é»˜è®¤æƒ…å†µä¸‹ï¼Œæ•´ä¸ªå‡½æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²å°±æ˜¯æç¤ºè¯ï¼Œé™¤éä½ æ ‡è®°äº†ä½ çš„æç¤ºè¯ã€‚

## ä¸ºä½ çš„æç¤ºè¯æ·»åŠ æ–‡æ¡£

æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šä¸€ä¸ªå¸¦æœ‰ `<prompt>` è¯­è¨€æ ‡ç­¾çš„ä»£ç å—ï¼Œæ¥æŒ‡å®šæ–‡æ¡£å­—ç¬¦ä¸²çš„å“ªä¸€éƒ¨åˆ†æ˜¯æç¤ºè¯å®šä¹‰ã€‚

``` python
@llm_prompt
def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers"):
    """
    è¿™æ˜¯ä¸€ç§å°†æç¤ºè¯ä½œä¸ºå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ä¸€éƒ¨åˆ†çš„å¥½æ–¹æ³•ï¼ŒåŒæ—¶ä¸ºå¼€å‘è€…æä¾›é¢å¤–çš„æ–‡æ¡£ã€‚

    å®ƒéœ€è¦æ˜¯ä¸€ä¸ªä»£ç å—ï¼Œæ ‡è®°ä¸º `<prompt>` è¯­è¨€
    ```<prompt>
    Write me a short header for my post about {topic} for {platform} platform.
    It should be for {audience} audience.
    (Max 15 words)
    ```
    ç°åœ¨åªæœ‰ä¸Šé¢çš„ä»£ç å—ä¼šè¢«ç”¨ä½œæç¤ºè¯ï¼Œæ–‡æ¡£å­—ç¬¦ä¸²çš„å…¶ä½™éƒ¨åˆ†å°†ç”¨ä½œå¼€å‘è€…çš„æè¿°ã€‚
    ï¼ˆå®ƒè¿˜æœ‰ä¸€ä¸ªå¥½å¤„æ˜¯ï¼ŒIDEï¼ˆå¦‚ VS codeï¼‰ä¼šæ­£ç¡®æ˜¾ç¤ºæç¤ºè¯ï¼ˆä¸ä¼šå°è¯•å°†å…¶è§£æä¸º markdownï¼Œä»è€Œä¸ä¼šæ­£ç¡®æ˜¾ç¤ºæ¢è¡Œç¬¦ï¼‰ï¼‰
    """
    return
```

## èŠå¤©æ¶ˆæ¯æç¤ºè¯

å¯¹äºèŠå¤©æ¨¡å‹ï¼Œå°†æç¤ºè¯å®šä¹‰ä¸ºä¸€ç»„æ¶ˆæ¯æ¨¡æ¿éå¸¸æœ‰ç”¨... å…·ä½“åšæ³•å¦‚ä¸‹ï¼š

``` python
@llm_prompt
def simulate_conversation(human_input:str, agent_role:str="a pirate"):
    """
    ## ç³»ç»Ÿæ¶ˆæ¯
     - æ³¨æ„ `<prompt:_role_>` æ ‡ç­¾å†…çš„ `:system` åç¼€


    ```<prompt:system>
    You are a {agent_role} hacker. You mus act like one.
    You reply always in code, using python or javascript code block...
    for example:

    ... do not reply with anything else.. just with code - respecting your role.
    ```
    # äººç±»æ¶ˆæ¯
    ï¼ˆæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ LLM å¼ºåˆ¶æ‰§è¡Œçš„çœŸå®è§’è‰² - GPT æ”¯æŒ systemã€assistantã€userï¼‰
    ``` <prompt:user>
    Helo, who are you
    ```
    ä¸€ä¸ªå›å¤ï¼š


    ``` <prompt:assistant>
    \``` python <<- ä½¿ç”¨ \ è½¬ä¹‰å†…éƒ¨ä»£ç å—ï¼Œè¯¥ä»£ç å—åº”ä½œä¸ºæç¤ºè¯çš„ä¸€éƒ¨åˆ†
    def hello():
        print("Argh... hello you pesky pirate")
    \```
    ```

    æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨å ä½ç¬¦æ·»åŠ ä¸€äº›å†å²è®°å½•
    ```<prompt:placeholder>
    {history}
    ```
    ```<prompt:user>
    {human_input}
    ```

    ç°åœ¨åªæœ‰ä¸Šé¢çš„ä»£ç å—ä¼šè¢«ç”¨ä½œæç¤ºè¯ï¼Œæ–‡æ¡£å­—ç¬¦ä¸²çš„å…¶ä½™éƒ¨åˆ†å°†ç”¨ä½œå¼€å‘è€…çš„æè¿°ã€‚
    ï¼ˆå®ƒè¿˜æœ‰ä¸€ä¸ªå¥½å¤„æ˜¯ï¼ŒIDEï¼ˆå¦‚ VS codeï¼‰ä¼šæ­£ç¡®æ˜¾ç¤ºæç¤ºè¯ï¼ˆä¸ä¼šå°è¯•å°†å…¶è§£æä¸º markdownï¼Œä»è€Œä¸ä¼šæ­£ç¡®æ˜¾ç¤ºæ¢è¡Œç¬¦ï¼‰ï¼‰
    """
    pass

```

è¿™é‡Œçš„è§’è‰²æ˜¯æ¨¡å‹åŸç”Ÿè§’è‰²ï¼ˆå¯¹äº chatGPT æ˜¯ assistantã€userã€systemï¼‰



# å¯é€‰éƒ¨åˆ†
- ä½ å¯ä»¥å®šä¹‰æç¤ºè¯ä¸­æ•´ä¸ªåº”è¯¥å¯é€‰çš„éƒ¨åˆ†
- å¦‚æœè¯¥éƒ¨åˆ†ä¸­çš„ä»»ä½•è¾“å…¥ç¼ºå¤±ï¼Œæ•´ä¸ªéƒ¨åˆ†å°†ä¸ä¼šè¢«æ¸²æŸ“

è¯­æ³•å¦‚ä¸‹ï¼š

``` python
@llm_prompt
def prompt_with_optional_partials():
    """
    this text will be rendered always, but

    {? anything inside this block will be rendered only if all the {value}s parameters are not empty (None | "")   ?}

    you can also place it in between the words
    this too will be rendered{? , but
        this  block will be rendered only if {this_value} and {this_value}
        is not empty?} !
    """
```
# è¾“å‡ºè§£æå™¨

- `llm_prompt` è£…é¥°å™¨åŸç”Ÿåœ°å°è¯•æ ¹æ®è¾“å‡ºç±»å‹æ£€æµ‹æœ€ä½³çš„è¾“å‡ºè§£æå™¨ã€‚ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œåˆ™è¿”å›åŸå§‹å­—ç¬¦ä¸²ï¼‰
- åˆ—è¡¨ã€å­—å…¸å’Œ pydantic è¾“å‡ºä¹Ÿå¾—åˆ°åŸç”Ÿæ”¯æŒï¼ˆè‡ªåŠ¨ï¼‰

``` python
# æ­¤ä»£ç ç¤ºä¾‹æ˜¯å®Œæ•´çš„ï¼Œåº”è¯¥å¯ä»¥ç›´æ¥è¿è¡Œ

from langchain_decorators import llm_prompt

@llm_prompt
def write_name_suggestions(company_business:str, count:int)->list:
    """ Write me {count} good name suggestions for company that {company_business}
    """
    pass

write_name_suggestions(company_business="sells cookies", count=5)
```
## æ›´å¤æ‚çš„ç»“æ„

å¯¹äºå­—å…¸ / pydanticï¼Œä½ éœ€è¦æŒ‡å®šæ ¼å¼åŒ–æŒ‡ä»¤...
è¿™å¯èƒ½å¾ˆç¹çï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ å¯ä»¥è®©è¾“å‡ºè§£æå™¨æ ¹æ®æ¨¡å‹ï¼ˆpydanticï¼‰ä¸ºä½ ç”ŸæˆæŒ‡ä»¤ã€‚

``` python
from langchain_decorators import llm_prompt
from pydantic import BaseModel, Field


class TheOutputStructureWeExpect(BaseModel):
    name:str = Field (description="The name of the company")
    headline:str = Field( description="The description of the company (for landing page)")
    employees:list[str] = Field(description="5-8 fake employee names with their positions")

@llm_prompt()
def fake_company_generator(company_business:str)->TheOutputStructureWeExpect:
    """ Generate a fake company that {company_business}
    {FORMAT_INSTRUCTIONS}
    """
    return

company = fake_company_generator(company_business="sells cookies")

# print the result nicely formatted
print("Company name: ",company.name)
print("company headline: ",company.headline)
print("company employees: ",company.employees)

```
# å°†æç¤ºè¯ç»‘å®šåˆ°å¯¹è±¡

``` python
from pydantic import BaseModel
from langchain_decorators import llm_prompt

class AssistantPersonality(BaseModel):
    assistant_name:str
    assistant_role:str
    field:str

    @property
    def a_property(self):
        return "whatever"

    def hello_world(self, function_kwarg:str=None):
        """
        We can reference any {field} or {a_property} inside our prompt... and combine it with {function_kwarg} in the method
        """


    @llm_prompt
    def introduce_your_self(self)->str:
        """
        ```Â <prompt:system>
        You are an assistant named {assistant_name}.
        Your role is to act as {assistant_role}
        ```
        ```<prompt:user>
        Introduce your self (in less than 20 words)
        ```
        """



personality = AssistantPersonality(assistant_name="John", assistant_role="a pirate")

print(personality.introduce_your_self(personality))
```


# æ›´å¤šç¤ºä¾‹ï¼š

- è¿™äº›ä»¥åŠæ›´å¤šç¤ºä¾‹ä¹Ÿå¯ä»¥åœ¨ [colab notebook è¿™é‡Œ](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=N4cf__D0E2Yk) æ‰¾åˆ°
- åŒ…æ‹¬ä½¿ç”¨çº¯ langchain decorators å®ç°çš„ [ReAct Agent é‡æ–°å®ç°](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=3bID5fryE2Yp)
