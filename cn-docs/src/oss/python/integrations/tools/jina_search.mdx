---
title: Jina 搜索
---
本指南提供了快速入门 Jina [工具](/oss/integrations/tools/) 的概述。有关 Jina 所有功能和配置的详细文档，请参阅 [API 参考](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html)。

## 概述

### 集成详情

| 类 | 包 | 可序列化 | JS 支持 | 版本 |
| :--- | :--- | :---: | :---: | :---: |
| [JinaSearch](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html) | [langchain-community](https://python.langchain.com/api_reference/community/) | ❌ | ❌ |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |

### 工具特性

| [返回产物](/oss/langchain/tools) | 原生异步 | 返回数据 | 定价 |
| :---: | :---: | :---: | :---: |
| ❌ | ❌ | URL、摘要、标题、页面内容 | 前 100 万响应 token 免费 |

## 设置

该集成位于 `langchain-community` 包中，并在版本 `0.2.16` 中添加：

```python
pip install --quiet -U "langchain-community>=0.2.16"
```

### 凭证

```python
import getpass
import os

if not os.environ.get("JINA_API_KEY"):
    os.environ["JINA_API_KEY"] = getpass.getpass("Jina API key:\n")
```

设置 [LangSmith](https://smith.langchain.com/) 以获得一流的可观测性也很有帮助（但不是必需的）：

```python
os.environ["LANGSMITH_TRACING"] = "true"
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass()
```

## 实例化

- TODO: 填写实例化参数

这里我们展示如何实例化一个 Jina 工具，使用

```python
from langchain_community.tools import JinaSearch

tool = JinaSearch()
```

## 调用

### [直接使用参数调用](/oss/langchain/tools)

```python
print(tool.invoke({"query": "what is langgraph"})[:1000])
```

```json
[{"title": "LangGraph", "link": "https://www.langchain.com/langgraph", "snippet": "<strong>LangGraph</strong> helps teams of all sizes, across all industries, from ambitious startups to established enterprises. \u201cLangChain is streets ahead with what they&#x27;ve put forward with <strong>LangGraph</strong>.", "content": "![Image 1](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b080e4b3ca12dc5d5d439_Langgraph%20UI-2.webp)\n\nControllable cognitive architecture for any task\n------------------------------------------------\n\nLangGraph's flexible API supports diverse control flows \u2013 single agent, multi-agent, hierarchical, sequential \u2013 and robustly handles realistic, complex scenarios.\n\nEnsure reliability with easy-to-add moderation and quality loops that prevent agents from veering off course.\n\n[See the docs](https://langchain-ai.github.io/langgraph/)\n\nDesigned for human-agent collaboration\n--------------------------------------\n\nWith built-in stat
```

### [使用 ToolCall 调用](/oss/langchain/tools)

我们也可以使用模型生成的 ToolCall 来调用该工具，在这种情况下将返回一个 ToolMessage：

```python
# 这通常由模型生成，但为了演示目的，我们将直接创建一个工具调用。
model_generated_tool_call = {
    "args": {"query": "what is langgraph"},
    "id": "1",
    "name": tool.name,
    "type": "tool_call",
}
tool_msg = tool.invoke(model_generated_tool_call)
print(tool_msg.content[:1000])
```

```json
[{"title": "LangGraph Tutorial: What Is LangGraph and How to Use It?", "link": "https://www.datacamp.com/tutorial/langgraph-tutorial", "snippet": "<strong>LangGraph</strong> <strong>is</strong> a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.", "content": "Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\n\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\n\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for de
```

## 链式调用

我们可以通过先将工具绑定到一个 [工具调用模型](/oss/langchain/tools/)，然后调用它来在链中使用我们的工具：

<ChatModelTabs customVarName="llm" />

```python
# | output: false
# | echo: false

# !pip install -qU langchain langchain-openai
from langchain.chat_models import init_chat_model

model = init_chat_model(model="gpt-4o", model_provider="openai")
```

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig, chain

prompt = ChatPromptTemplate(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{user_input}"),
        ("placeholder", "{messages}"),
    ]
)


model_with_tools = model.bind_tools([tool])
model_chain = prompt | model_with_tools


@chain
def tool_chain(user_input: str, config: RunnableConfig):
    input_ = {"user_input": user_input}
    ai_msg = model_chain.invoke(input_, config=config)
    tool_msgs = tool.batch(ai_msg.tool_calls, config=config)
    return model_chain.invoke({**input_, "messages": [ai_msg, *tool_msgs]}, config=config)


tool_chain.invoke("what's langgraph")
```

```text
AIMessage(content="LangGraph is a library designed for building stateful, multi-actor applications with language models (LLMs). It is particularly useful for creating agent and multi-agent workflows. Compared to other LLM frameworks, LangGraph offers unique benefits such as cycles, controllability, and persistence. Here are some key points:\n\n1. **Stateful and Multi-Actor Applications**: LangGraph allows for the definition of flows involving cycles, essential for most agentic architectures. This is a significant differentiation from Directed Acyclic Graph (DAG)-based solutions.\n\n2. **Controllability**: The framework offers fine-grained control over both the flow and state of applications, which is crucial for creating reliable agents.\n\n3. **Persistence**: Built-in persistence is available, enabling advanced features like human-in-the-loop workflows and memory.\n\n4. **Human-in-the-Loop**: LangGraph supports interrupting graph execution for human approval or editing of the agent's next planned action.\n\n5. **Streaming Support**: The library can stream outputs as they are produced by each node, including token streaming.\n\n6. **Integration with LangChain**: While it integrates seamlessly with LangChain and LangSmith, LangGraph can also be used independently.\n\n7. **Inspiration and Interface**: LangGraph is inspired by systems like Pregel and Apache Beam, with its public interface drawing inspiration from NetworkX.\n\nLangGraph is designed to handle more complex agent applications that require cycles and state management, making it an ideal choice for developers seeking to build sophisticated LLM-driven applications. For more detailed information, you can visit their [official documentation](https://langchain-ai.github.io/langgraph/).", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 14774, 'total_tokens': 15112}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'stop', 'logprobs': None}, id='run-420d16ed-535c-41c6-8814-2186b42be0f8-0', usage_metadata={'input_tokens': 14774, 'output_tokens': 338, 'total_tokens': 15112})
```

---

## API 参考

有关 Jina 所有功能和配置的详细文档，请参阅 API 参考：[python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html)
