---
title: Agent Server ä¸­çš„ A2A ç«¯ç‚¹
sidebarTitle: A2A endpoint in Agent Server
---
[Agent2Agent (A2A)](https://a2a-protocol.org/latest/) æ˜¯ Google åˆ¶å®šçš„ç”¨äºå®ç°å¯¹è¯å¼ AI æ™ºèƒ½ä½“é—´é€šä¿¡çš„åè®®ã€‚[LangSmith å®ç°äº†å¯¹ A2A çš„æ”¯æŒ](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html#tag/a2a/post/a2a/{assistant_id})ï¼Œå…è®¸æ‚¨çš„æ™ºèƒ½ä½“é€šè¿‡æ ‡å‡†åŒ–åè®®ä¸å…¶ä»–å…¼å®¹ A2A çš„æ™ºèƒ½ä½“è¿›è¡Œé€šä¿¡ã€‚

A2A ç«¯ç‚¹å¯åœ¨ [Agent Server](/langsmith/agent-server) çš„ `/a2a/{assistant_id}` è·¯å¾„ä¸‹ä½¿ç”¨ã€‚

## æ”¯æŒçš„æ–¹æ³•

Agent Server æ”¯æŒä»¥ä¸‹ A2A RPC æ–¹æ³•ï¼š

- **message/send**ï¼šå‘åŠ©æ‰‹å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶å®Œæ•´å“åº”
- **message/stream**ï¼šå‘é€æ¶ˆæ¯å¹¶ä½¿ç”¨æœåŠ¡å™¨å‘é€äº‹ä»¶ (SSE) å®æ—¶æµå¼ä¼ è¾“å“åº”
- **tasks/get**ï¼šæ£€ç´¢å…ˆå‰åˆ›å»ºä»»åŠ¡çš„çŠ¶æ€å’Œç»“æœ

## æ™ºèƒ½ä½“å¡ç‰‡å‘ç°

æ¯ä¸ªåŠ©æ‰‹ä¼šè‡ªåŠ¨å…¬å¼€ä¸€ä¸ª A2A æ™ºèƒ½ä½“å¡ç‰‡ï¼Œè¯¥å¡ç‰‡æè¿°äº†å…¶èƒ½åŠ›ï¼Œå¹¶æä¾›äº†å…¶ä»–æ™ºèƒ½ä½“è¿æ¥æ‰€éœ€çš„ä¿¡æ¯ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼æ£€ç´¢ä»»ä½•åŠ©æ‰‹çš„æ™ºèƒ½ä½“å¡ç‰‡ï¼š

```
GET /.well-known/agent-card.json?assistant_id={assistant_id}
```

æ™ºèƒ½ä½“å¡ç‰‡åŒ…å«åŠ©æ‰‹çš„åç§°ã€æè¿°ã€å¯ç”¨æŠ€èƒ½ã€æ”¯æŒçš„è¾“å…¥/è¾“å‡ºæ¨¡å¼ä»¥åŠç”¨äºé€šä¿¡çš„ A2A ç«¯ç‚¹ URLã€‚

## è¦æ±‚

è¦ä½¿ç”¨ A2Aï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–é¡¹ï¼š

* `langgraph-api >= 0.4.21`

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

```bash
pip install "langgraph-api>=0.4.21"
```

## ä½¿ç”¨æ¦‚è¿°

è¦å¯ç”¨ A2Aï¼š

* å‡çº§åˆ°ä½¿ç”¨ langgraph-api>=0.4.21ã€‚
* éƒ¨ç½²ä½¿ç”¨åŸºäºæ¶ˆæ¯çš„çŠ¶æ€ç»“æ„çš„æ™ºèƒ½ä½“ã€‚
* ä½¿ç”¨ç«¯ç‚¹ä¸å…¶ä»–å…¼å®¹ A2A çš„æ™ºèƒ½ä½“è¿æ¥ã€‚

## åˆ›å»ºå…¼å®¹ A2A çš„æ™ºèƒ½ä½“

æ­¤ç¤ºä¾‹åˆ›å»ºä¸€ä¸ªå…¼å®¹ A2A çš„æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“ä½¿ç”¨ OpenAI çš„ API å¤„ç†ä¼ å…¥æ¶ˆæ¯å¹¶ç»´æŠ¤å¯¹è¯çŠ¶æ€ã€‚è¯¥æ™ºèƒ½ä½“å®šä¹‰äº†åŸºäºæ¶ˆæ¯çš„çŠ¶æ€ç»“æ„ï¼Œå¹¶å¤„ç† A2A åè®®çš„æ¶ˆæ¯æ ¼å¼ã€‚

ä¸ºäº†å…¼å®¹ [A2A "text" éƒ¨åˆ†](https://a2a-protocol.org/dev/specification/#651-textpart-object)ï¼Œæ™ºèƒ½ä½“çš„çŠ¶æ€ä¸­å¿…é¡»æœ‰ä¸€ä¸ª `messages` é”®ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
"""LangGraph A2A å¯¹è¯æ™ºèƒ½ä½“ã€‚

æ”¯æŒ A2A åè®®ï¼Œç”¨äºå¯¹è¯äº¤äº’çš„æ¶ˆæ¯è¾“å…¥ã€‚
"""

from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Any, Dict, List, TypedDict

from langgraph.graph import StateGraph
from langgraph.runtime import Runtime
from openai import AsyncOpenAI

class Context(TypedDict):
    """æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å‚æ•°ã€‚"""
    my_configurable_param: str

@dataclass
class State:
    """æ™ºèƒ½ä½“çš„è¾“å…¥çŠ¶æ€ã€‚

    ä¸º A2A å¯¹è¯æ¶ˆæ¯å®šä¹‰åˆå§‹ç»“æ„ã€‚
    """
    messages: List[Dict[str, Any]]

async def call_model(state: State, runtime: Runtime[Context]) -> Dict[str, Any]:
    """å¤„ç†å¯¹è¯æ¶ˆæ¯å¹¶ä½¿ç”¨ OpenAI è¿”å›è¾“å‡ºã€‚"""
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # å¤„ç†ä¼ å…¥æ¶ˆæ¯
    latest_message = state.messages[-1] if state.messages else {}
    user_content = latest_message.get("content", "No message content")

    # ä¸º OpenAI API åˆ›å»ºæ¶ˆæ¯
    openai_messages = [
        {
            "role": "system",
            "content": "You are a helpful conversational agent. Keep responses brief and engaging."
        },
        {
            "role": "user",
            "content": user_content
        }
    ]

    try:
        # è°ƒç”¨ OpenAI API
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=openai_messages,
            max_tokens=100,
            temperature=0.7
        )

        ai_response = response.choices[0].message.content

    except Exception as e:
        ai_response = f"I received your message but had trouble processing it. Error: {str(e)[:50]}..."

    # åˆ›å»ºå“åº”æ¶ˆæ¯
    response_message = {
        "role": "assistant",
        "content": ai_response
    }

    return {
        "messages": state.messages + [response_message]
    }

# å®šä¹‰å›¾
graph = (
    StateGraph(State, context_schema=Context)
    .add_node(call_model)
    .add_edge("__start__", "call_model")
    .compile()
)
```

## æ™ºèƒ½ä½“é—´é€šä¿¡

ä¸€æ—¦æ‚¨çš„æ™ºèƒ½ä½“é€šè¿‡ `langgraph dev` åœ¨æœ¬åœ°è¿è¡Œæˆ–[éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ](/langsmith/deployments)ï¼Œæ‚¨å°±å¯ä»¥ä½¿ç”¨ A2A åè®®ä¿ƒè¿›å®ƒä»¬ä¹‹é—´çš„é€šä¿¡ã€‚

æ­¤ç¤ºä¾‹æ¼”ç¤ºäº†ä¸¤ä¸ªæ™ºèƒ½ä½“å¦‚ä½•é€šè¿‡å‘å½¼æ­¤çš„ A2A ç«¯ç‚¹å‘é€ JSON-RPC æ¶ˆæ¯è¿›è¡Œé€šä¿¡ã€‚è¯¥è„šæœ¬æ¨¡æ‹Ÿäº†ä¸€ä¸ªå¤šè½®å¯¹è¯ï¼Œå…¶ä¸­æ¯ä¸ªæ™ºèƒ½ä½“å¤„ç†å¯¹æ–¹çš„å“åº”å¹¶ç»§ç»­å¯¹è¯ã€‚

```python
#!/usr/bin/env python3
"""ä½¿ç”¨ LangGraph A2A åè®®çš„æ™ºèƒ½ä½“é—´å¯¹è¯æ¨¡æ‹Ÿã€‚"""

import asyncio
import aiohttp
import os

async def send_message(session, port, assistant_id, text):
    """å‘æ™ºèƒ½ä½“å‘é€æ¶ˆæ¯å¹¶è¿”å›å“åº”æ–‡æœ¬ã€‚"""
    url = f"http://127.0.0.1:{port}/a2a/{assistant_id}"
    payload = {
        "jsonrpc": "2.0",
        "id": "",
        "method": "message/send",
        "params": {
            "message": {
                "role": "user",
                "parts": [{"kind": "text", "text": text}]
            },
            "messageId": "",
            "thread": {"threadId": ""}
        }
    }

    headers = {"Accept": "application/json"}
    async with session.post(url, json=payload, headers=headers) as response:
        try:
            result = await response.json()
            return result["result"]["artifacts"][0]["parts"][0]["text"]
        except Exception as e:
            text = await response.text()
            print(f"Response error from port {port}: {response.status} - {text}")
            return f"Error from port {port}: {response.status}"

async def simulate_conversation():
    """æ¨¡æ‹Ÿä¸¤ä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„å¯¹è¯ã€‚"""
    agent_a_id = os.getenv("AGENT_A_ID")
    agent_b_id = os.getenv("AGENT_B_ID")

    if not agent_a_id or not agent_b_id:
        print("Set AGENT_A_ID and AGENT_B_ID environment variables")
        return

    message = "Hello! Let's have a conversation."

    async with aiohttp.ClientSession() as session:
        for i in range(3):
            print(f"--- Round {i + 1} ---")

            # æ™ºèƒ½ä½“ A å“åº”
            message = await send_message(session, 2024, agent_a_id, message)
            print(f"ğŸ”µ Agent A: {message}")

            # æ™ºèƒ½ä½“ B å“åº”
            message = await send_message(session, 2025, agent_b_id, message)
            print(f"ğŸ”´ Agent B: {message}")
            print()

if __name__ == "__main__":
    asyncio.run(simulate_conversation())
```

## ç¦ç”¨ A2A

è¦ç¦ç”¨ A2A ç«¯ç‚¹ï¼Œè¯·åœ¨æ‚¨çš„ `langgraph.json` é…ç½®æ–‡ä»¶ä¸­å°† `disable_a2a` è®¾ç½®ä¸º `true`ï¼š

```json
{
  "$schema": "https://langgra.ph/schema.json",
  "http": {
    "disable_a2a": true
  }
}
```
