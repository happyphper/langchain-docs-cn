---
title: MistralAI
---

<Warning>

您当前正在查阅的是关于将 Mistral 模型用作文本补全模型的文档。Mistral 上提供的许多流行模型是[聊天补全模型](/oss/javascript/langchain/models)。

您可能正在寻找[这个页面](/oss/javascript/integrations/chat/mistral/)。

</Warning>

<Tip>

<strong>想在本地运行 Mistral 的模型？查看我们的 [Ollama 集成](/oss/javascript/integrations/chat/ollama)。</strong>

</Tip>

[Mistral AI](https://mistral.ai/) 是一个为其强大的[开源模型](https://docs.mistral.ai/getting-started/models/)提供托管服务的平台。

本文将帮助您开始使用 LangChain 的 MistralAI 补全模型（LLMs）。关于 `MistralAI` 功能和配置选项的详细文档，请参阅 [API 参考](https://api.js.langchain.com/classes/langchain_mistralai.MistralAI.html)。

## 概述

### 集成详情

| 类 | 包 | 本地 | 可序列化 | PY 支持 | 下载量 | 版本 |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [MistralAI](https://api.js.langchain.com/classes/langchain_mistralai.MistralAI.html) | [`@langchain/mistralai`](https://www.npmjs.com/package/@langchain/mistralai) | ❌ | ✅ | ❌ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/mistralai?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/mistralai?style=flat-square&label=%20&) |

## 设置

要访问 MistralAI 模型，您需要创建一个 MistralAI 账户，获取一个 API 密钥，并安装 `@langchain/mistralai` 集成包。

### 凭证

前往 [console.mistral.ai](https://console.mistral.ai/) 注册 MistralAI 并生成一个 API 密钥。完成后，设置 `MISTRAL_API_KEY` 环境变量：

```bash
export MISTRAL_API_KEY="your-api-key"
```

如果您希望自动追踪模型调用，也可以通过取消注释以下行来设置您的 [LangSmith](https://docs.langchain.com/langsmith/home) API 密钥：

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### 安装

LangChain 的 MistralAI 集成位于 `@langchain/mistralai` 包中：

::: code-group

```bash [npm]
npm install @langchain/mistralai @langchain/core
```

```bash [yarn]
yarn add @langchain/mistralai @langchain/core
```

```bash [pnpm]
pnpm add @langchain/mistralai @langchain/core
```

:::

## 实例化

现在我们可以实例化我们的模型对象并生成补全结果：

```typescript
import { MistralAI } from "@langchain/mistralai"

const llm = new MistralAI({
  model: "codestral-latest",
  temperature: 0,
  maxTokens: undefined,
  maxRetries: 2,
  // other params...
})
```

## 调用

```typescript
const inputText = "MistralAI is an AI company that "

const completion = await llm.invoke(inputText)
completion
```

```text
 has developed Mistral 7B, a large language model (LLM) that is open-source and available for commercial use. Mistral 7B is a 7 billion parameter model that is trained on a diverse and high-quality dataset, and it has been fine-tuned to perform well on a variety of tasks, including text generation, question answering, and code interpretation.

MistralAI has made Mistral 7B available under a permissive license, allowing anyone to use the model for commercial purposes without having to pay any fees. This has made Mistral 7B a popular choice for businesses and organizations that want to leverage the power of large language models without incurring high costs.

Mistral 7B has been trained on a diverse and high-quality dataset, which has enabled it to perform well on a variety of tasks. It has been fine-tuned to generate coherent and contextually relevant text, and it has been shown to be capable of answering complex questions and interpreting code.

Mistral 7B is also a highly efficient model, capable of processing text at a fast pace. This makes it well-suited for applications that require real-time responses, such as chatbots and virtual assistants.

Overall, Mistral 7B is a powerful and versatile large language model that is open-source and available for commercial use. Its ability to perform well on a variety of tasks, its efficiency, and its permissive license make it a popular choice for businesses and organizations that want to leverage the power of large language models.
```

## 钩子 (Hooks)

Mistral AI 支持针对三个事件的自定义钩子：`beforeRequest`、`requestError` 和 `response`。每种钩子类型的函数签名示例如下：

```typescript
const beforeRequestHook = (req: Request): Request | void | Promise<Request | void> => {
    // 在 Mistral 处理请求之前运行的代码
};

const requestErrorHook = (err: unknown, req: Request): void | Promise<void> => {
    // 当 Mistral 处理请求过程中发生错误时运行的代码
};

const responseHook = (res: Response, req: Request): void | Promise<void> => {
    // 在 Mistral 发送成功响应之前运行的代码
};
```

要将这些钩子添加到聊天模型中，可以将它们作为参数传递，它们会自动被添加：

```typescript
import { ChatMistralAI } from "@langchain/mistralai"

const modelWithHooks = new ChatMistralAI({
    model: "mistral-large-latest",
    temperature: 0,
    maxRetries: 2,
    beforeRequestHooks: [ beforeRequestHook ],
    requestErrorHooks: [ requestErrorHook ],
    responseHooks: [ responseHook ],
    // other params...
});
```

或者在实例化后手动分配和添加它们：

```typescript
import { ChatMistralAI } from "@langchain/mistralai"

const model = new ChatMistralAI({
    model: "mistral-large-latest",
    temperature: 0,
    maxRetries: 2,
    // other params...
});

model.beforeRequestHooks = [ ...model.beforeRequestHooks, beforeRequestHook ];
model.requestErrorHooks = [ ...model.requestErrorHooks, requestErrorHook ];
model.responseHooks = [ ...model.responseHooks, responseHook ];

model.addAllHooksToHttpClient();
```

`addAllHooksToHttpClient` 方法会先清除所有当前已添加的钩子，然后再分配整个更新后的钩子列表，以避免钩子重复。

可以一次移除一个钩子，也可以一次性清除模型中的所有钩子。

```typescript
model.removeHookFromHttpClient(beforeRequestHook);

model.removeAllHooksFromHttpClient();
```

---

## API 参考

关于所有 MistralAI 功能和配置的详细文档，请前往 [API 参考](https://api.js.langchain.com/classes/langchain_mistralai.MistralAI.html)。
