---
title: Helicone
---
本页介绍如何在 LangChain 中使用 [Helicone](https://helicone.ai) 生态系统。

## 什么是 Helicone？

Helicone 是一个[开源](https://github.com/Helicone/helicone)的可观测性平台，它代理您的 OpenAI 流量，并为您提供关于支出、延迟和使用情况的关键洞察。

## 快速开始

在您的 LangChain 环境中，只需添加以下参数。

```bash
export OPENAI_API_BASE="https://oai.hconeai.com/v1"
```

现在前往 [helicone.ai](https://www.helicone.ai/signup) 创建您的账户，并在我们的仪表板中添加您的 OpenAI API 密钥以查看您的日志。

## 如何启用 Helicone 缓存

```python
from langchain_openai import OpenAI
import openai
openai.api_base = "https://oai.hconeai.com/v1"

llm = OpenAI(temperature=0.9, headers={"Helicone-Cache-Enabled": "true"})
text = "What is a helicone?"
print(llm.invoke(text))
```

[Helicone 缓存文档](https://docs.helicone.ai/advanced-usage/caching)

## 如何使用 Helicone 自定义属性

```python
from langchain_openai import OpenAI
import openai
openai.api_base = "https://oai.hconeai.com/v1"

llm = OpenAI(temperature=0.9, headers={
        "Helicone-Property-Session": "24",
        "Helicone-Property-Conversation": "support_issue_2",
        "Helicone-Property-App": "mobile",
      })
text = "What is a helicone?"
print(llm.invoke(text))
```

[Helicone 属性文档](https://docs.helicone.ai/advanced-usage/custom-properties)
