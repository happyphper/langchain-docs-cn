---
title: ModelScopeChatEndpoint
---
ModelScope（[官网](https://www.modelscope.cn/) | [GitHub](https://github.com/modelscope/modelscope)）建立在“模型即服务”（Model-as-a-Service，MaaS）的理念之上。它致力于汇集来自 AI 社区最先进的机器学习模型，并简化在实际应用中利用 AI 模型的过程。本仓库开源的 ModelScope 核心库提供了接口和实现，使开发者能够执行模型推理、训练和评估。

本文将帮助您开始使用 ModelScope 聊天端点。

## 概述

### 集成详情

|提供商| 类 | 包 | 可序列化 | 下载量 | 版本 |
|:---:|:---:|:---:|:---:|:---:|:---:|
|[ModelScope](/oss/python/integrations/providers/modelscope/)| ModelScopeChatEndpoint | [langchain-modelscope-integration](https://pypi.org/project/langchain-modelscope-integration/) | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-modelscope-integration?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-modelscope-integration?style=flat-square&label=%20) |

## 设置

要访问 ModelScope 聊天端点，您需要创建一个 ModelScope 账户，获取一个 SDK 令牌，并安装 `langchain-modelscope-integration` 集成包。

### 凭证

前往 [ModelScope](https://modelscope.cn/) 注册 ModelScope 账户并生成一个 [SDK 令牌](https://modelscope.cn/my/myaccesstoken)。完成后，设置 `MODELSCOPE_SDK_TOKEN` 环境变量：

```python
import getpass
import os

if not os.getenv("MODELSCOPE_SDK_TOKEN"):
    os.environ["MODELSCOPE_SDK_TOKEN"] = getpass.getpass(
        "Enter your ModelScope SDK token: "
    )
```

### 安装

LangChain ModelScope 集成位于 `langchain-modelscope-integration` 包中：

```python
pip install -qU langchain-modelscope-integration
```

## 实例化

现在我们可以实例化我们的模型对象并生成聊天补全：

```python
from langchain_modelscope import ModelScopeChatEndpoint

llm = ModelScopeChatEndpoint(
    model="Qwen/Qwen2.5-Coder-32B-Instruct",
    temperature=0,
    max_tokens=1024,
    timeout=60,
    max_retries=2,
    # other params...
)
```

## 调用

```python
messages = [
    (
        "system",
        "You are a helpful assistant that translates English to Chinese. Translate the user sentence.",
    ),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```text
AIMessage(content='我喜欢编程。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 33, 'total_tokens': 36, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen2.5-coder-32b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-60bb3461-60ae-4c0b-8997-ab55ef77fcd6-0', usage_metadata={'input_tokens': 33, 'output_tokens': 3, 'total_tokens': 36, 'input_token_details': {}, 'output_token_details': {}})
```

```python
print(ai_msg.content)
```

```text
我喜欢编程。
```

---

## API 参考

有关 ModelScopeChatEndpoint 所有功能和配置的详细文档，请参阅参考文档：[modelscope.cn/docs/model-service/API-Inference/intro](https://modelscope.cn/docs/model-service/API-Inference/intro)
