---
title: Lindorm
---
本文将帮助您开始使用 LangChain 集成 Lindorm 嵌入模型。

## 概述

### 集成详情

| 提供商 |              包              |
|:------:|:----------------------------:|
| [Lindorm](/oss/integrations/providers/lindorm/) | [langchain-lindorm-integration](https://pypi.org/project/langchain-lindorm-integration/) |

## 设置

要访问 Lindorm 嵌入模型，您需要创建一个 Lindorm 账户，获取 AK&SK，并安装 `langchain-lindorm-integration` 集成包。

### 凭证

您可以在 [控制台](https://lindorm.console.aliyun.com/cn-hangzhou/clusterhou/cluster?spm=a2c4g.11186623.0.0.466534e93Xj6tt) 获取您的凭证。

```python
import os

class Config:
    AI_LLM_ENDPOINT = os.environ.get("AI_ENDPOINT", "<AI_ENDPOINT>")
    AI_USERNAME = os.environ.get("AI_USERNAME", "root")
    AI_PWD = os.environ.get("AI_PASSWORD", "<PASSWORD>")

    AI_DEFAULT_EMBEDDING_MODEL = "bge_m3_model"  # 设置为您部署的模型
```

### 安装

LangChain Lindorm 集成包位于 `langchain-lindorm-integration` 中：

```python
pip install -qU langchain-lindorm-integration
```

## 实例化

现在我们可以实例化模型对象并生成嵌入向量：

```python
from langchain_lindorm_integration import LindormAIEmbeddings

embeddings = LindormAIEmbeddings(
    endpoint=Config.AI_LLM_ENDPOINT,
    username=Config.AI_USERNAME,
    password=Config.AI_PWD,
    model_name=Config.AI_DEFAULT_EMBEDDING_MODEL,
)
```

## 索引与检索

嵌入模型通常用于检索增强生成（RAG）流程中，既作为索引数据的一部分，也用于后续检索。更详细的说明，请参阅我们的 [RAG 教程](/oss/langchain/rag)。

下面展示了如何使用上面初始化的 `embeddings` 对象来索引和检索数据。在本示例中，我们将在 `InMemoryVectorStore` 中索引和检索一个示例文档。

```python
# 使用示例文本创建向量存储
from langchain_core.vectorstores import InMemoryVectorStore

text = "LangChain is the framework for building context-aware reasoning applications"

vectorstore = InMemoryVectorStore.from_texts(
    [text],
    embedding=embeddings,
)

# 将向量存储用作检索器
retriever = vectorstore.as_retriever()

# 检索最相似的文本
retrieved_documents = retriever.invoke("What is LangChain?")

# 显示检索到的文档内容
retrieved_documents[0].page_content
```

```text
'LangChain is the framework for building context-aware reasoning applications'
```

## 直接使用

在底层，向量存储和检索器的实现分别调用了 `embeddings.embed_documents(...)` 和 `embeddings.embed_query(...)` 来为 `from_texts` 中使用的文本和检索 `invoke` 操作创建嵌入向量。

您可以直接调用这些方法来获取嵌入向量，以满足您自己的用例。

### 嵌入单个文本

您可以使用 `embed_query` 嵌入单个文本或文档：

```python
single_vector = embeddings.embed_query(text)
print(str(single_vector)[:100])  # 显示向量的前 100 个字符
```

```text
[-0.016254117712378502, -0.01154549140483141, 0.0042558759450912476, -0.011416379362344742, -0.01770
```

### 嵌入多个文本

您可以使用 `embed_documents` 嵌入多个文本：

```python
text2 = (
    "LangGraph is a library for building stateful, multi-actor applications with LLMs"
)
two_vectors = embeddings.embed_documents([text, text2])
for vector in two_vectors:
    print(str(vector)[:100])  # 显示向量的前 100 个字符
```

```text
[-0.016254086047410965, -0.011545476503670216, 0.0042558712884783745, -0.011416426859796047, -0.0177
[-0.07268096506595612, -3.236892371205613e-05, -0.0019329536007717252, -0.030644644051790237, -0.018
```

---

## API 参考

有关 `LindormEmbeddings` 功能和配置选项的详细文档，请参阅 [API 参考](https://pypi.org/project/langchain-lindorm-integration/)。
