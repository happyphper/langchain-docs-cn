---
title: Gradio
---
`Hugging Face Spaces` ä¸Šæœ‰æ•°åƒä¸ª `Gradio` åº”ç”¨ã€‚è¿™ä¸ªåº“è®©å®ƒä»¬è§¦æ‰‹å¯åŠï¼Œæˆä¸ºæ‚¨å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„å¾—åŠ›å·¥å…· ðŸ¦¾

å…·ä½“æ¥è¯´ï¼Œ`gradio-tools` æ˜¯ä¸€ä¸ª Python åº“ï¼Œç”¨äºŽå°† `Gradio` åº”ç”¨è½¬æ¢ä¸ºå·¥å…·ï¼Œä¾›åŸºäºŽå¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰ä½¿ç”¨ï¼Œä»¥å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼ŒLLM å¯ä»¥ä½¿ç”¨ä¸€ä¸ª `Gradio` å·¥å…·è½¬å½•å®ƒåœ¨ç½‘ä¸Šæ‰¾åˆ°çš„è¯­éŸ³è®°å½•ï¼Œç„¶åŽä¸ºæ‚¨æ€»ç»“ã€‚æˆ–è€…ï¼Œå®ƒå¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ª `Gradio` å·¥å…·å¯¹æ‚¨ Google Drive ä¸Šçš„æ–‡æ¡£è¿›è¡Œ OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰ï¼Œç„¶åŽå›žç­”ç›¸å…³é—®é¢˜ã€‚

å¦‚æžœæ‚¨æƒ³ä½¿ç”¨çš„ç©ºé—´ä¸æ˜¯é¢„æž„å»ºå·¥å…·ä¹‹ä¸€ï¼Œåˆ›å»ºè‡ªå·±çš„å·¥å…·ä¹Ÿéžå¸¸ç®€å•ã€‚è¯·å‚é˜… gradio-tools æ–‡æ¡£çš„ç›¸å…³éƒ¨åˆ†ä»¥äº†è§£å¦‚ä½•æ“ä½œã€‚æ¬¢è¿Žæ‰€æœ‰è´¡çŒ®ï¼

```python
pip install -qU  gradio_tools langchain-community
```

## ä½¿ç”¨å·¥å…·

```python
from gradio_tools.tools import StableDiffusionTool
```

```python
local_file_path = StableDiffusionTool().langchain.run(
    "Please create a photo of a dog riding a skateboard"
)
local_file_path
```

```text
Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”

Job Status: Status.STARTING eta: None
```

```text
'/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'
```

```python
from PIL import Image
```

```python
im = Image.open(local_file_path)
```

```python
from IPython.display import display

display(im)
```

## åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨

```python
from gradio_tools.tools import (
    ImageCaptioningTool,
    StableDiffusionPromptGeneratorTool,
    StableDiffusionTool,
    TextToVideoTool,
)
from langchain.agents import initialize_agent
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAI

llm = OpenAI(temperature=0)
memory = ConversationBufferMemory(memory_key="chat_history")
tools = [
    StableDiffusionTool().langchain,
    ImageCaptioningTool().langchain,
    StableDiffusionPromptGeneratorTool().langchain,
    TextToVideoTool().langchain,
]

agent = initialize_agent(
    tools, llm, memory=memory, agent="conversational-react-description", verbose=True
)
output = agent.run(
    input=(
        "Please create a photo of a dog riding a skateboard "
        "but improve my prompt prior to using an image generator."
        "Please caption the generated image and create a video for it using the improved prompt."
    )
)
```

```text
Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”
Loaded as API: https://taesiri-blip-2.hf.space âœ”
Loaded as API: https://microsoft-promptist.hf.space âœ”
Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”

> Entering new AgentExecutor chain...

Thought: Do I need to use a tool? Yes
Action: StableDiffusionPromptGenerator
Action Input: A dog riding a skateboard
Job Status: Status.STARTING eta: None

Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha
Thought: Do I need to use a tool? Yes
Action: StableDiffusion
Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha
Job Status: Status.STARTING eta: None

Job Status: Status.PROCESSING eta: None

Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg
Thought: Do I need to use a tool? Yes
Action: ImageCaptioner
Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg
Job Status: Status.STARTING eta: None

Observation: a painting of a dog sitting on a skateboard
Thought: Do I need to use a tool? Yes
Action: TextToVideo
Action Input: a painting of a dog sitting on a skateboard
Job Status: Status.STARTING eta: None
Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)

Job Status: Status.IN_QUEUE eta: 73.89824726581574
Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)

Job Status: Status.IN_QUEUE eta: 42.49370198879602

Job Status: Status.IN_QUEUE eta: 21.314297944849187

Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4
Thought: Do I need to use a tool? No
AI: Here is a video of a painting of a dog sitting on a skateboard.

> Finished chain.
```

```python

```
