---
title: å‘é‡å­˜å‚¨
---
## æ¦‚è¿°

å‘é‡å­˜å‚¨ï¼ˆvector storeï¼‰ç”¨äºå­˜å‚¨[åµŒå…¥](/oss/python/integrations/text_embedding)æ•°æ®å¹¶æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚

```mermaid
flowchart LR

    subgraph "ğŸ“¥ ç´¢å¼•é˜¶æ®µï¼ˆå­˜å‚¨ï¼‰"
        A[ğŸ“„ æ–‡æ¡£] --> B[ğŸ”¢ åµŒå…¥æ¨¡å‹]
        B --> C[ğŸ”˜ åµŒå…¥å‘é‡]
        C --> D[(å‘é‡å­˜å‚¨)]
    end

    subgraph "ğŸ“¤ æŸ¥è¯¢é˜¶æ®µï¼ˆæ£€ç´¢ï¼‰"
        E[â“ æŸ¥è¯¢æ–‡æœ¬] --> F[ğŸ”¢ åµŒå…¥æ¨¡å‹]
        F --> G[ğŸ”˜ æŸ¥è¯¢å‘é‡]
        G --> H[ğŸ” ç›¸ä¼¼æ€§æœç´¢]
        H --> D
        D --> I[ğŸ“„ Top-k ç»“æœ]
    end
```

### æ¥å£

LangChain ä¸ºå‘é‡å­˜å‚¨æä¾›äº†ç»Ÿä¸€çš„æ¥å£ï¼Œå…è®¸æ‚¨ï¼š

- `add_documents` - å‘å­˜å‚¨ä¸­æ·»åŠ æ–‡æ¡£ã€‚
- `delete` - æ ¹æ® ID åˆ é™¤å­˜å‚¨çš„æ–‡æ¡£ã€‚
- `similarity_search` - æŸ¥è¯¢è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æ¡£ã€‚

è¿™ç§æŠ½è±¡è®©æ‚¨å¯ä»¥åœ¨ä¸åŒçš„å®ç°ä¹‹é—´åˆ‡æ¢ï¼Œè€Œæ— éœ€æ›´æ”¹åº”ç”¨ç¨‹åºé€»è¾‘ã€‚

### åˆå§‹åŒ–

è¦åˆå§‹åŒ–ä¸€ä¸ªå‘é‡å­˜å‚¨ï¼Œéœ€è¦ä¸ºå…¶æä¾›ä¸€ä¸ªåµŒå…¥æ¨¡å‹ï¼š

```python
from langchain_core.vectorstores import InMemoryVectorStore
vector_store = InMemoryVectorStore(embedding=SomeEmbeddingModel())
```

### æ·»åŠ æ–‡æ¡£

æ·»åŠ  <a href="https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document" target="_blank" rel="noreferrer" class="link"><code>Document</code></a> å¯¹è±¡ï¼ˆåŒ…å« `page_content` å’Œå¯é€‰çš„å…ƒæ•°æ®ï¼‰çš„æ–¹æ³•å¦‚ä¸‹ï¼š

```python
vector_store.add_documents(documents=[doc1, doc2], ids=["id1", "id2"])
```

### åˆ é™¤æ–‡æ¡£

é€šè¿‡æŒ‡å®š ID è¿›è¡Œåˆ é™¤ï¼š

```python
vector_store.delete(ids=["id1"])
```

### ç›¸ä¼¼æ€§æœç´¢

ä½¿ç”¨ `similarity_search` å‘å‡ºè¯­ä¹‰æŸ¥è¯¢ï¼Œå®ƒå°†è¿”å›æœ€æ¥è¿‘çš„åµŒå…¥æ–‡æ¡£ï¼š

```python
similar_docs = vector_store.similarity_search("your query here")
```

è®¸å¤šå‘é‡å­˜å‚¨æ”¯æŒä»¥ä¸‹å‚æ•°ï¼š

* `k` â€” è¦è¿”å›çš„ç»“æœæ•°é‡
* `filter` â€” åŸºäºå…ƒæ•°æ®çš„æ¡ä»¶è¿‡æ»¤

### ç›¸ä¼¼æ€§åº¦é‡ä¸ç´¢å¼•

åµŒå…¥ç›¸ä¼¼æ€§å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•è®¡ç®—ï¼š

* **ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine similarityï¼‰**
* **æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆEuclidean distanceï¼‰**
* **ç‚¹ç§¯ï¼ˆDot productï¼‰**

é«˜æ•ˆçš„æœç´¢é€šå¸¸ä½¿ç”¨ç´¢å¼•æ–¹æ³•ï¼Œä¾‹å¦‚ HNSWï¼ˆåˆ†å±‚å¯å¯¼èˆªå°ä¸–ç•Œï¼‰ï¼Œä½†å…·ä½“ç»†èŠ‚å–å†³äºå‘é‡å­˜å‚¨ã€‚

### å…ƒæ•°æ®è¿‡æ»¤

é€šè¿‡å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ¥æºã€æ—¥æœŸï¼‰è¿›è¡Œè¿‡æ»¤å¯ä»¥ä¼˜åŒ–æœç´¢ç»“æœï¼š

```python
vector_store.similarity_search(
  "query",
  k=3,
  filter={"source": "tweets"}
)
```

<important>
åŸºäºå…ƒæ•°æ®çš„è¿‡æ»¤æ”¯æŒå› å®ç°è€Œå¼‚ã€‚
è¯·æŸ¥é˜…æ‚¨æ‰€é€‰å‘é‡å­˜å‚¨çš„æ–‡æ¡£ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚
</important>

## ä¸»è¦é›†æˆ

**é€‰æ‹©åµŒå…¥æ¨¡å‹ï¼š**

:::: details OpenAI

::: code-group

```bash [pip]
pip install -qU langchain-openai
```

```bash [uv]
uv add langchain-openai
```

:::

```python
import getpass
import os

if not os.environ.get("OPENAI_API_KEY"):
  os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter API key for OpenAI: ")

from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
```

::::

:::: details Azure

```bash
pip install -qU langchain-azure-ai
```

```python
import getpass
import os

if not os.environ.get("AZURE_OPENAI_API_KEY"):
  os.environ["AZURE_OPENAI_API_KEY"] = getpass.getpass("Enter API key for Azure: ")

from langchain_openai import AzureOpenAIEmbeddings

embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    azure_deployment=os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"],
    openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"],
)
```

::::

:::: details Google Gemini

```bash
pip install -qU langchain-google-genai
```

```python
import getpass
import os

if not os.environ.get("GOOGLE_API_KEY"):
  os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter API key for Google Gemini: ")

from langchain_google_genai import GoogleGenerativeAIEmbeddings

embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
```

::::

:::: details Google Vertex

```bash
pip install -qU langchain-google-vertexai
```

```python
from langchain_google_vertexai import VertexAIEmbeddings

embeddings = VertexAIEmbeddings(model="text-embedding-005")
```

::::

:::: details AWS

```bash
pip install -qU langchain-aws
```

```python
from langchain_aws import BedrockEmbeddings

embeddings = BedrockEmbeddings(model_id="amazon.titan-embed-text-v2:0")
```

::::

:::: details HuggingFace

```bash
pip install -qU langchain-huggingface
```

```python
from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
```

::::

:::: details Ollama

```bash
pip install -qU langchain-ollama
```

```python
from langchain_ollama import OllamaEmbeddings

embeddings = OllamaEmbeddings(model="llama3")
```

::::

:::: details Cohere

```bash
pip install -qU langchain-cohere
```

```python
import getpass
import os

if not os.environ.get("COHERE_API_KEY"):
  os.environ["COHERE_API_KEY"] = getpass.getpass("Enter API key for Cohere: ")

from langchain_cohere import CohereEmbeddings

embeddings = CohereEmbeddings(model="embed-english-v3.0")
```

::::

:::: details Mistral AI

```bash
pip install -qU langchain-mistralai
```

```python
import getpass
import os

if not os.environ.get("MISTRALAI_API_KEY"):
  os.environ["MISTRALAI_API_KEY"] = getpass.getpass("Enter API key for MistralAI: ")

from langchain_mistralai import MistralAIEmbeddings

embeddings = MistralAIEmbeddings(model="mistral-embed")
```

::::

:::: details Nomic

```bash
pip install -qU langchain-nomic
```

```python
import getpass
import os

if not os.environ.get("NOMIC_API_KEY"):
  os.environ["NOMIC_API_KEY"] = getpass.getpass("Enter API key for Nomic: ")

from langchain_nomic import NomicEmbeddings

embeddings = NomicEmbeddings(model="nomic-embed-text-v1.5")
```

::::

:::: details NVIDIA

```bash
pip install -qU langchain-nvidia-ai-endpoints
```

```python
import getpass
import os

if not os.environ.get("NVIDIA_API_KEY"):
  os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter API key for NVIDIA: ")

from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings

embeddings = NVIDIAEmbeddings(model="NV-Embed-QA")
```

::::

:::: details Voyage AI

```bash
pip install -qU langchain-voyageai
```

```python
import getpass
import os

if not os.environ.get("VOYAGE_API_KEY"):
  os.environ["VOYAGE_API_KEY"] = getpass.getpass("Enter API key for Voyage AI: ")

from langchain-voyageai import VoyageAIEmbeddings

embeddings = VoyageAIEmbeddings(model="voyage-3")
```

::::

:::: details IBM watsonx

```bash
pip install -qU langchain-ibm
```

```python
import getpass
import os

if not os.environ.get("WATSONX_APIKEY"):
  os.environ["WATSONX_APIKEY"] = getpass.getpass("Enter API key for IBM watsonx: ")

from langchain_ibm import WatsonxEmbeddings

embeddings = WatsonxEmbeddings(
    model_id="ibm/slate-125m-english-rtrvr",
    url="https://us-south.ml.cloud.ibm.com",
    project_id="<WATSONX PROJECT_ID>",
)
```

::::

:::: details Fake

```bash
pip install -qU langchain-core
```

```python
from langchain_core.embeddings import DeterministicFakeEmbedding

embeddings = DeterministicFakeEmbedding(size=4096)
```

::::

:::: details xAI

```bash
pip install -qU langchain-xai
```

```python
import getpass
import os

if not os.environ.get("XAI_API_KEY"):
  os.environ["XAI_API_KEY"] = getpass.getpass("Enter API key for xAI: ")

from langchain.chat_models import init_chat_model

model = init_chat_model("grok-2", model_provider="xai")
```

::::

:::: details Perplexity

```bash
pip install -qU langchain-perplexity
```

```python
import getpass
import os

if not os.environ.get("PPLX_API_KEY"):
  os.environ["PPLX_API_KEY"] = getpass.getpass("Enter API key for Perplexity: ")

from langchain.chat_models import init_chat_model

model = init_chat_model("llama-3.1-sonar-small-128k-online", model_provider="perplexity")
```

::::

:::: details DeepSeek

```bash
pip install -qU langchain-deepseek
```

```python
import getpass
import os

if not os.environ.get("DEEPSEEK_API_KEY"):
  os.environ["DEEPSEEK_API_KEY"] = getpass.getpass("Enter API key for DeepSeek: ")

from langchain.chat_models import init_chat_model

model = init_chat_model("deepseek-chat", model_provider="deepseek")
```

::::

**é€‰æ‹©å‘é‡å­˜å‚¨ï¼š**

:::: details å†…å­˜å­˜å‚¨

::: code-group

```bash [pip]
pip install -qU langchain-core
```

```bash [uv]
uv add langchain-core
```

:::

```python
from langchain_core.vectorstores import InMemoryVectorStore

vector_store = InMemoryVectorStore(embeddings)
```

::::

:::: details Amazon OpenSearch

```bash [pip]
pip install -qU boto3
```

```python
from opensearchpy import RequestsHttpConnection

service = "es"  # must set the service as 'es'
region = "us-east-2"
credentials = boto3.Session(
    aws_access_key_id="xxxxxx", aws_secret_access_key="xxxxx"
).get_credentials()
awsauth = AWS4Auth("xxxxx", "xxxxxx", region, service, session_token=credentials.token)

vector_store = OpenSearchVectorSearch.from_documents(
    docs,
    embeddings,
    opensearch_url="host url",
    http_auth=awsauth,
    timeout=300,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection,
    index_name="test-index",
)
```

::::

:::: details Astra DB

::: code-group

```bash [pip]
pip install -qU langchain-astradb
```

```bash [uv]
uv add langchain-astradb
```

:::

```python
from langchain_astradb import AstraDBVectorStore

vector_store = AstraDBVectorStore(
    embedding=embeddings,
    api_endpoint=ASTRA_DB_API_ENDPOINT,
    collection_name="astra_vector_langchain",
    token=ASTRA_DB_APPLICATION_TOKEN,
    namespace=ASTRA_DB_NAMESPACE,
)
```

::::

:::: details Azure Cosmos DB NoSQL

::: code-group

```bash [pip]
pip install -qU langchain-azure-ai azure-cosmos
```

```bash [uv]
uv add langchain-azure-ai
```

:::

```python
from langchain_azure_ai.vectorstores.azure_cosmos_db_no_sql import (
    AzureCosmosDBNoSqlVectorSearch,
)
vector_search = AzureCosmosDBNoSqlVectorSearch.from_documents(
    documents=docs,
    embedding=openai_embeddings,
    cosmos_client=cosmos_client,
    database_name=database_name,
    container_name=container_name,
    vector_embedding_policy=vector_embedding_policy,
    full_text_policy=full_text_policy,
    indexing_policy=indexing_policy,
    cosmos_container_properties=cosmos_container_properties,
    cosmos_database_properties={},
    full_text_search_enabled=True,
)
```

::::

:::: details Azure Cosmos DB Mongo vCore

::: code-group

```bash [pip]
pip install -qU langchain-azure-ai pymongo
```

```bash [uv]
uv add pymongo
```

:::

```python
from langchain_azure_ai.vectorstores.azure_cosmos_db_mongo_vcore import (
    AzureCosmosDBMongoVCoreVectorSearch,
)

vectorstore = AzureCosmosDBMongoVCoreVectorSearch.from_documents(
    docs,
    openai_embeddings,
    collection=collection,
    index_name=INDEX_NAME,
)
```

::::

:::: details Chroma

::: code-group

```bash [pip]
pip install -qU langchain-chroma
```

```bash [uv]
uv add langchain-chroma
```

:::

```python
from langchain_chroma import Chroma

vector_store = Chroma(
    collection_name="example_collection",
    embedding_function=embeddings,
    persist_directory="./chroma_langchain_db",  # Where to save data locally, remove if not necessary
)
```

::::

:::: details FAISS

```bash
pip install -qU langchain-community
```

```python
import faiss
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS

embedding_dim = len(embeddings.embed_query("hello world"))
index = faiss.IndexFlatL2(embedding_dim)

vector_store = FAISS(
    embedding_function=embeddings,
    index=index,
    docstore=InMemoryDocstore(),
    index_to_docstore_id={},
)
```

::::

:::: details Milvus

::: code-group

```bash [pip]
pip install -qU langchain-milvus
```

```bash [uv]
uv add langchain-milvus
```

:::

```python
from langchain_milvus import Milvus

URI = "./milvus_example.db"

vector_store = Milvus(
    embedding_function=embeddings,
    connection_args={"uri": URI},
    index_params={"index_type": "FLAT", "metric_type": "L2"},
)
```

::::

:::: details MongoDB

```bash
pip install -qU langchain-mongodb
```

```python
from langchain_mongodb import MongoDBAtlasVectorSearch

vector_store = MongoDBAtlasVectorSearch(
    embedding=embeddings,
    collection=MONGODB_COLLECTION,
    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,
    relevance_score_fn="cosine",
)
```

::::

:::: details PGVector

::: code-group

```bash [pip]
pip install -qU langchain-postgres
```

```bash [uv]
uv add langchain-postgres
```

:::

```python
from langchain_postgres import PGVector

vector_store = PGVector(
    embeddings=embeddings,
    collection_name="my_docs",
    connection="postgresql+psycopg://..."
)
```

::::

:::: details PGVectorStore

::: code-group

```bash [pip]
pip install -qU langchain-postgres
```

```bash [uv]
uv add langchain-postgres
```

:::

```python
from langchain_postgres import PGEngine, PGVectorStore

$engine = PGEngine.from_connection_string(
    url="postgresql+psycopg://..."
)

vector_store = PGVectorStore.create_sync(
    engine=pg_engine,
    table_name='test_table',
    embedding_service=embedding
)
```

::::

:::: details Pinecone

::: code-group

```bash [pip]
pip install -qU langchain-pinecone
```

```bash [uv]
uv add langchain-pinecone
```

:::

```python
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

pc = Pinecone(api_key=...)
index = pc.Index(index_name)

vector_store = PineconeVectorStore(embedding=embeddings, index=index)
```

::::

::: code-group

```bash [pip]
pip install -qU langchain-qdrant
```

```bash [uv]
uv add langchain-qdrant
```

:::

```python
from qdrant_client.models import Distance, VectorParams
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient

client = QdrantClient(":memory:")

vector_size = len(embeddings.embed_query("sample text"))

if not client.collection_exists("test"):
client.create_collection(
collection
